{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Densenet210-unet-ACL5.ipynb",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.4.1\n",
        "!pip install keras==2.4.3"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "PNfpi6Q0jXrM",
        "execution": {
          "iopub.status.busy": "2021-09-16T09:36:33.117987Z",
          "iopub.execute_input": "2021-09-16T09:36:33.119031Z",
          "iopub.status.idle": "2021-09-16T09:36:48.142025Z",
          "shell.execute_reply.started": "2021-09-16T09:36:33.118919Z",
          "shell.execute_reply": "2021-09-16T09:36:48.141181Z"
        },
        "trusted": true,
        "outputId": "f75f4041-6a82-48f7-9c17-b998c09729cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: tensorflow==2.4.1 in /opt/conda/lib/python3.7/site-packages (2.4.1)\nRequirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (2.4.0)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (3.17.3)\nRequirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (3.3.0)\nRequirement already satisfied: numpy~=1.19.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.19.5)\nRequirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.37.0)\nRequirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.6.3)\nRequirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.12)\nRequirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.1.0)\nRequirement already satisfied: grpcio~=1.32.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.32.0)\nRequirement already satisfied: h5py~=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (2.10.0)\nRequirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.2.0)\nRequirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.12.0)\nRequirement already satisfied: six~=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.15.0)\nRequirement already satisfied: tensorboard~=2.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (2.6.0)\nRequirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.3.3)\nRequirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.1.2)\nRequirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (3.7.4.3)\nRequirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.12.1)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.4)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (57.4.0)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.5)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.34.0)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.25.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.0)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.0.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.7.2)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.7)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.4.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (4.0.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2021.5.30)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.26.6)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.5.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting keras==2.4.3\n  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras==2.4.3) (2.10.0)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras==2.4.3) (1.7.1)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras==2.4.3) (5.4.1)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras==2.4.3) (1.19.5)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras==2.4.3) (1.15.0)\nInstalling collected packages: keras\nSuccessfully installed keras-2.4.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Reshape, Permute, Activation, Input, \\\n",
        "    add, multiply\n",
        "from keras.layers import concatenate, core, Dropout\n",
        "from keras.models import Model\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.core import Lambda\n",
        "#import keras.backend as K\n",
        "\n",
        "#%tensorflow_version 1.x\n",
        "import os\n",
        "import keras\n",
        "from keras.callbacks import TensorBoard\n",
        "import tensorflow as tf\n",
        "#import keras.backend.tensorflow_backend as K\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import CSVLogger\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-16T09:36:48.145296Z",
          "iopub.execute_input": "2021-09-16T09:36:48.145522Z",
          "iopub.status.idle": "2021-09-16T09:36:52.395842Z",
          "shell.execute_reply.started": "2021-09-16T09:36:48.145495Z",
          "shell.execute_reply": "2021-09-16T09:36:52.395059Z"
        },
        "trusted": true,
        "id": "8CDOA7TzUqre",
        "outputId": "7be8e3ed-e351-48de-92f6-a8d162c168c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "2021-09-16 09:36:48.688263: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2"
      ],
      "metadata": {
        "id": "2a8AfzPOjXrQ",
        "execution": {
          "iopub.status.busy": "2021-09-16T09:36:52.397093Z",
          "iopub.execute_input": "2021-09-16T09:36:52.397361Z",
          "iopub.status.idle": "2021-09-16T09:36:53.056963Z",
          "shell.execute_reply.started": "2021-09-16T09:36:52.397328Z",
          "shell.execute_reply": "2021-09-16T09:36:53.056239Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "import numpy as np\n",
        "import os\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import cv2\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "BackGround = [255, 255, 255]\n",
        "road = [0, 0, 0]\n",
        "# COLOR_DICT = np.array([BackGround, road])\n",
        "one = [128, 128, 128]\n",
        "two = [128, 0, 0]\n",
        "three = [192, 192, 128]\n",
        "four = [255, 69, 0]\n",
        "five = [128, 64, 128]\n",
        "six = [60, 40, 222]\n",
        "seven = [128, 128, 0]\n",
        "eight = [192, 128, 128]\n",
        "nine = [64, 64, 128]\n",
        "ten = [64, 0, 128]\n",
        "eleven = [64, 64, 0]\n",
        "twelve = [0, 128, 192]\n",
        "COLOR_DICT = np.array([one, two,three,four,five,six,seven,eight,nine,ten,eleven,twelve])\n",
        "\n",
        "\n",
        "class data_preprocess:\n",
        "    def __init__(self, train_path=None, image_folder=None, label_folder=None,\n",
        "                 valid_path=None,valid_image_folder =None,valid_label_folder = None,\n",
        "                 test_path=None, save_path=None,\n",
        "                 img_rows=256, img_cols=256,\n",
        "                 flag_multi_class=False,\n",
        "                 num_classes = 2):\n",
        "        self.img_rows = img_rows\n",
        "        self.img_cols = img_cols\n",
        "        self.train_path = train_path\n",
        "        self.image_folder = image_folder\n",
        "        self.label_folder = label_folder\n",
        "        self.valid_path = valid_path\n",
        "        self.valid_image_folder = valid_image_folder\n",
        "        self.valid_label_folder = valid_label_folder\n",
        "        self.test_path = test_path\n",
        "        self.save_path = save_path\n",
        "        self.data_gen_args = dict(rotation_range=20,\n",
        "                                  width_shift_range=0.002,\n",
        "                                  shear_range=0.03,\n",
        "                                  zoom_range=0.005,\n",
        "                                  vertical_flip=True,\n",
        "                                  horizontal_flip=True,\n",
        "                                  fill_mode='nearest')\n",
        "        self.image_color_mode = \"rgb\"\n",
        "        self.label_color_mode = \"grayscale\"\n",
        "\n",
        "        self.flag_multi_class = flag_multi_class\n",
        "        self.num_class = num_classes\n",
        "        self.target_size = (256, 256)\n",
        "        self.img_type = 'png'\n",
        "\n",
        "    def adjustData(self, img, label):\n",
        "        if (self.flag_multi_class):\n",
        "            img = img / 255.\n",
        "            label = label[:, :, :, 0] if (len(label.shape) == 4) else label[:, :, 0]\n",
        "            new_label = np.zeros(label.shape + (self.num_class,))\n",
        "            for i in range(self.num_class):\n",
        "                new_label[label == i, i] = 1\n",
        "            label = new_label\n",
        "        elif (np.max(img) > 1):\n",
        "            #img = img / 255.\n",
        "            #label = label / 255.\n",
        "            #label[label >= 0.5] = 1\n",
        "            #label[label < 0.5] = 0\n",
        "            img2 =np.asarray(img)\n",
        "            label2 =np.asarray(label)\n",
        "            img2 =img2.astype('float32')\n",
        "            label2 =label2.astype('float32')\n",
        "            img2 /= 255.0\n",
        "            label2 /= 255.0\n",
        "            label2[label2 >= 0.5] = 1\n",
        "            label2[label2 < 0.5] = 0\n",
        "        return (img2, label2)\n",
        "\n",
        "    def trainGenerator(self, batch_size, image_save_prefix=\"image\", label_save_prefix=\"label\",\n",
        "                       save_to_dir=None, seed=7):\n",
        "        '''\n",
        "        can generate image and label at the same time\n",
        "        use the same seed for image_datagen and label_datagen to ensure the transformation for image and label is the same\n",
        "        if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
        "        '''\n",
        "        image_datagen = ImageDataGenerator(**self.data_gen_args)\n",
        "        label_datagen = ImageDataGenerator(**self.data_gen_args)\n",
        "        image_generator = image_datagen.flow_from_directory(\n",
        "            self.train_path,\n",
        "            classes=[self.image_folder],\n",
        "            class_mode=None,\n",
        "            color_mode=self.image_color_mode,\n",
        "            target_size=self.target_size,\n",
        "            batch_size=batch_size,\n",
        "            save_to_dir=save_to_dir,\n",
        "            save_prefix=image_save_prefix,\n",
        "            seed=seed)\n",
        "        label_generator = label_datagen.flow_from_directory(\n",
        "            self.train_path,\n",
        "            classes=[self.label_folder],\n",
        "            class_mode=None,\n",
        "            color_mode=self.label_color_mode,\n",
        "            target_size=self.target_size,\n",
        "            batch_size=batch_size,\n",
        "            save_to_dir=save_to_dir,\n",
        "            save_prefix=label_save_prefix,\n",
        "            seed=seed)\n",
        "        train_generator = zip(image_generator, label_generator)\n",
        "        for (img, label) in train_generator:\n",
        "            img, label = self.adjustData(img, label)\n",
        "            yield (img, label)\n",
        "\n",
        "    def testGenerator(self):\n",
        "        filenames = os.listdir(self.test_path)\n",
        "        for filename in filenames:\n",
        "            img = io.imread(os.path.join(self.test_path, filename), as_gray=False)\n",
        "            img = img / 255.\n",
        "            img = trans.resize(img, self.target_size, mode='constant')\n",
        "            img = np.reshape(img, img.shape + (1,)) if (not self.flag_multi_class) else img\n",
        "            img = np.reshape(img, (1,) + img.shape)\n",
        "            yield img\n",
        "\n",
        "    def validLoad(self, batch_size,seed=7):\n",
        "        image_datagen = ImageDataGenerator(rescale=0)\n",
        "        label_datagen = ImageDataGenerator(rescale=0)\n",
        "        image_generator = image_datagen.flow_from_directory(\n",
        "            self.valid_path,\n",
        "            classes=[self.valid_image_folder],\n",
        "            class_mode=None,\n",
        "            color_mode=self.image_color_mode,\n",
        "            target_size=self.target_size,\n",
        "            batch_size=batch_size,\n",
        "            seed=seed)\n",
        "        label_generator = label_datagen.flow_from_directory(\n",
        "            self.valid_path,\n",
        "            classes=[self.valid_label_folder],\n",
        "            class_mode=None,\n",
        "            color_mode=self.label_color_mode,\n",
        "            target_size=self.target_size,\n",
        "            batch_size=batch_size,\n",
        "            seed=seed)\n",
        "        train_generator = zip(image_generator, label_generator)\n",
        "        for (img, label) in train_generator:\n",
        "            img, label = self.adjustData(img, label)\n",
        "            yield (img, label)\n",
        "        # return imgs,labels\n",
        "\n",
        "    def saveResult(self, npyfile, size, name,threshold=80):\n",
        "        for i, item in enumerate(npyfile):\n",
        "            img = item\n",
        "            img_std = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
        "            if self.flag_multi_class:\n",
        "                for row in range(len(img)):\n",
        "                    for col in range(len(img[row])):\n",
        "                        num = np.argmax(img[row][col])\n",
        "                        img_std[row][col] = COLOR_DICT[num]\n",
        "            else:\n",
        "                for k in range(len(img)):\n",
        "                    for j in range(len(img[k])):\n",
        "                        num = img[k][j]\n",
        "                        if num < (threshold/255.0):\n",
        "                            img_std[k][j] = road\n",
        "                        else:\n",
        "                            img_std[k][j] = BackGround\n",
        "            img_std = cv2.resize(img_std, size, interpolation=cv2.INTER_CUBIC)\n",
        "            cv2.imwrite(os.path.join(self.save_path, (\"%s_predict.\" + self.img_type) % (name)), img_std)"
      ],
      "metadata": {
        "id": "iTf8lIwLjXrS",
        "execution": {
          "iopub.status.busy": "2021-09-16T09:36:53.059039Z",
          "iopub.execute_input": "2021-09-16T09:36:53.059282Z",
          "iopub.status.idle": "2021-09-16T09:36:53.530892Z",
          "shell.execute_reply.started": "2021-09-16T09:36:53.059251Z",
          "shell.execute_reply": "2021-09-16T09:36:53.530164Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####  Metrics\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.losses import binary_crossentropy\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "def dice_coeff(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return score\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dice_coeff(y_true, y_pred)\n",
        "    return loss\n",
        "def iou_coeff(y_true, y_pred):\n",
        "    smooth=1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    union=K.sum(y_true_f) + K.sum(y_pred_f)-intersection\n",
        "    mvalue=(intersection+smooth)/(union+smooth)\n",
        "    return mvalue\n",
        "def precision(y_true, y_pred):\n",
        "    \"\"\"Precision metric.\n",
        "\n",
        "    Only computes a batch-wise average of precision.\n",
        "\n",
        "    Computes the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "def ACL5(y_true, y_pred): \n",
        "\n",
        "\t#y_pred = K.cast(y_pred, dtype = 'float64')\n",
        "\n",
        "\tprint(K.int_shape(y_pred))\n",
        "\n",
        "\tx = y_pred[:,1:,:,:] - y_pred[:,:-1,:,:] # horizontal and vertical directions \n",
        "\ty = y_pred[:,:,1:,:] - y_pred[:,:,:-1,:]\n",
        "\n",
        "\tdelta_x = x[:,1:,:-2,:]**2\n",
        "\tdelta_y = y[:,:-2,1:,:]**2\n",
        "\tdelta_u = K.abs(delta_x + delta_y) \n",
        "\n",
        "\tepsilon = 0.00000001 # where is a parameter to avoid square root is zero in practice.\n",
        "\tw = 1####\n",
        "\tlenth = w * K.sum(K.sqrt(delta_u + epsilon)) # equ.(11) in the paper\n",
        "\n",
        "\n",
        "\tC_1 = np.ones((256, 256))\n",
        "\tC_2 = np.zeros((256, 256))\n",
        "\n",
        "\tregion_in = K.abs(K.sum( y_pred[:,:,:,0] * ((y_true[:,:,:,0] - C_1)**2) ) ) # equ.(12) in the paper\n",
        "\tregion_out = K.abs(K.sum( (1-y_pred[:,:,:,0]) * ((y_true[:,:,:,0] - C_2)**2) )) # equ.(12) in the paper\n",
        "\n",
        "\tlambdaP = 5 # lambda parameter could be various.\n",
        "\t\n",
        "\tloss =  lenth + lambdaP * ((region_in) + (region_out)) \n",
        "\n",
        "\treturn loss\n",
        "def ACL5_mod(y_true, y_pred): \n",
        "\n",
        "\t#y_pred = K.cast(y_pred, dtype = 'float64')\n",
        "\n",
        "\tprint(K.int_shape(y_pred))\n",
        "\n",
        "\tx = y_pred[:,1:,:,:] - y_pred[:,:-1,:,:] # horizontal and vertical directions \n",
        "\ty = y_pred[:,:,1:,:] - y_pred[:,:,:-1,:]\n",
        "\n",
        "\tdelta_x = x[:,1:,:-2,:]**2\n",
        "\tdelta_y = y[:,:-2,1:,:]**2\n",
        "\tdelta_u = K.abs(delta_x + delta_y) \n",
        "\n",
        "\tepsilon = 0.00000001 # where is a parameter to avoid square root is zero in practice.\n",
        "\tw = 1####\n",
        "\tlenth = w * K.sum(K.sqrt(delta_u + epsilon)) # equ.(11) in the paper\n",
        "\n",
        "\n",
        "\tC_1 = np.ones((256, 256))\n",
        "\tC_2 = np.zeros((256, 256))\n",
        "\n",
        "\tregion_in = K.abs(K.sum( y_pred[:,:,:,0] * ((y_true[:,:,:,0] - C_1)**2) ) ) # equ.(12) in the paper\n",
        "\tregion_out = K.abs(K.sum( (1-y_pred[:,:,:,0]) * ((y_true[:,:,:,0] - C_2)**2) )) # equ.(12) in the paper\n",
        "\n",
        "\tlambdaP = 5 # lambda parameter could be various.\n",
        "\t\n",
        "\tloss =  lenth + lambdaP * ((region_in) + (region_out*1.4)) \n",
        "\n",
        "\treturn loss"
      ],
      "metadata": {
        "id": "VVdzJaSWjXra",
        "execution": {
          "iopub.status.busy": "2021-09-16T09:36:53.534087Z",
          "iopub.execute_input": "2021-09-16T09:36:53.534304Z",
          "iopub.status.idle": "2021-09-16T09:36:53.555784Z",
          "shell.execute_reply.started": "2021-09-16T09:36:53.534281Z",
          "shell.execute_reply": "2021-09-16T09:36:53.555122Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iwu9rjDFjXrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta = 0.25\n",
        "alpha = 0.25\n",
        "gamma = 2\n",
        "epsilon = 1e-5\n",
        "smooth = 1\n",
        "\n",
        "def tversky_index( y_true, y_pred):\n",
        "    y_true_pos = K.flatten(y_true)\n",
        "    y_pred_pos = K.flatten(y_pred)\n",
        "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
        "    false_neg = K.sum(y_true_pos * (1 - y_pred_pos))\n",
        "    false_pos = K.sum((1 - y_true_pos) * y_pred_pos)\n",
        "    alpha = 0.7\n",
        "    return (true_pos + smooth) / (true_pos + alpha * false_neg + (\n",
        "                1 - alpha) * false_pos + smooth)\n",
        "\n",
        "def tversky_loss( y_true, y_pred):\n",
        "    return 1 - tversky_index(y_true, y_pred)\n",
        "\n",
        "def focal_tversky( y_true, y_pred):\n",
        "    pt_1 = tversky_index(y_true, y_pred)\n",
        "    gamma = 0.75\n",
        "    return K.pow((1 - pt_1), gamma)\n",
        "\n",
        "def dsc(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return score\n",
        "\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "  intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
        "  union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
        "  dice = K.mean((2. * intersection + smooth)/(union + smooth), axis=0)\n",
        "  return dice\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dsc(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "-YuW43lejXrd",
        "execution": {
          "iopub.status.busy": "2021-09-16T09:36:53.556772Z",
          "iopub.execute_input": "2021-09-16T09:36:53.557743Z",
          "iopub.status.idle": "2021-09-16T09:36:53.572817Z",
          "shell.execute_reply.started": "2021-09-16T09:36:53.557519Z",
          "shell.execute_reply": "2021-09-16T09:36:53.572103Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env SM_FRAMEWORK=tf.keras"
      ],
      "metadata": {
        "id": "kr5nP8ItjXre",
        "outputId": "48e77d7c-c144-4f17-e726-e4b36dce7171",
        "execution": {
          "iopub.status.busy": "2021-09-16T09:36:53.575324Z",
          "iopub.execute_input": "2021-09-16T09:36:53.575844Z",
          "iopub.status.idle": "2021-09-16T09:36:53.584944Z",
          "shell.execute_reply.started": "2021-09-16T09:36:53.575817Z",
          "shell.execute_reply": "2021-09-16T09:36:53.584103Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "env: SM_FRAMEWORK=tf.keras\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation_models\n",
        "import segmentation_models\n",
        "from segmentation_models.losses import bce_jaccard_loss"
      ],
      "metadata": {
        "id": "KMTFbTKtjXrf",
        "outputId": "2bd1e0fe-2f4f-479d-e8e6-b255673c5ad3",
        "execution": {
          "iopub.status.busy": "2021-09-16T09:36:53.586008Z",
          "iopub.execute_input": "2021-09-16T09:36:53.586376Z",
          "iopub.status.idle": "2021-09-16T09:37:00.943486Z",
          "shell.execute_reply.started": "2021-09-16T09:36:53.586343Z",
          "shell.execute_reply": "2021-09-16T09:37:00.942760Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting segmentation_models\n  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\nCollecting efficientnet==1.0.0\n  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\nCollecting keras-applications<=1.0.8,>=1.0.7\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[K     |████████████████████████████████| 50 kB 5.3 MB/s  eta 0:00:01\n\u001b[?25hCollecting image-classifiers==1.0.0\n  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.0.0->segmentation_models) (0.18.3)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.19.5)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (2.10.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.15.0)\nRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.4.3)\nRequirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.7.1)\nRequirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.5)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2021.8.30)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.1.1)\nRequirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (8.3.1)\nRequirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.9.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.8.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (0.10.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.7)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.3.1)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation_models) (5.0.9)\nInstalling collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models\nSuccessfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nSegmentation Models: using `tf.keras` framework.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ACL5_bce_jaccard_loss(y_true, y_pred):\n",
        "    loss = ACL5(y_true, y_pred) + bce_jaccard_loss(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def focal_tversky_bce_jaccard_loss(y_true, y_pred):\n",
        "    loss = focal_tversky(y_true, y_pred) + 2*bce_jaccard_loss(y_true, y_pred)\n",
        "    return loss\n",
        "\n"
      ],
      "metadata": {
        "id": "IVcpwi4hjXrg",
        "execution": {
          "iopub.status.busy": "2021-09-16T09:37:00.947583Z",
          "iopub.execute_input": "2021-09-16T09:37:00.949535Z",
          "iopub.status.idle": "2021-09-16T09:37:00.957094Z",
          "shell.execute_reply.started": "2021-09-16T09:37:00.949481Z",
          "shell.execute_reply": "2021-09-16T09:37:00.956339Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "from tensorflow.keras.layers import Conv2D , BatchNormalization , Activation , MaxPool2D , Input , Dropout , ZeroPadding2D , Conv2DTranspose , Concatenate\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras.applications import InceptionResNetV2"
      ],
      "metadata": {
        "id": "eDJ9CtzQjXrh",
        "execution": {
          "iopub.status.busy": "2021-09-16T09:37:00.963759Z",
          "iopub.execute_input": "2021-09-16T09:37:00.965617Z",
          "iopub.status.idle": "2021-09-16T09:37:00.972551Z",
          "shell.execute_reply.started": "2021-09-16T09:37:00.965568Z",
          "shell.execute_reply": "2021-09-16T09:37:00.971881Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  DenseNet201_UNet"
      ],
      "metadata": {
        "id": "ccYNxPZwjXri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "from tensorflow.keras.layers import Conv2D , BatchNormalization , Activation , MaxPool2D , Input , Dropout , ZeroPadding2D , Conv2DTranspose , Concatenate\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "def conv_block(inputs , num_filters):\n",
        "  x = Conv2D(num_filters , 3 , padding= \"same\" )(inputs)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(\"relu\")(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "\n",
        "  x = Conv2D(num_filters , 3 , padding= \"same\" )(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(\"relu\")(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "\n",
        "def decoder_block(inputs , skip_features , num_filters):\n",
        "\n",
        "  x = Conv2DTranspose(num_filters , (2, 2) , strides = 2 , padding = \"same\")(inputs)\n",
        "  x = Concatenate()([x , skip_features ])\n",
        "  x = conv_block(x , num_filters)\n",
        "\n",
        "  return x\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "\n",
        "def build_DenseNet210_Unet(input_shape):\n",
        "\n",
        "  ##Input\n",
        "  inputs = Input(input_shape)\n",
        "\n",
        "  ## Pre-Trained Encoder\n",
        "\n",
        "  encoder = DenseNet201(include_top = False , weights = \"imagenet\" , input_tensor = inputs)\n",
        "\n",
        "  # Skip Connections which are the Features and we will access these Features and Feed it in the Decoder\n",
        "  #First Feature is the input shaped image\n",
        "  s1 = encoder.get_layer(\"input_1\").output                         # 256 * 256\n",
        "\n",
        "  s2 = encoder.get_layer(\"conv1/relu\").output                       # 128 * 128 \n",
        "\n",
        "  s3 = encoder.get_layer(\"pool2_relu\").output       # 64 * 64 \n",
        "\n",
        "  s4 = encoder.get_layer(\"pool3_relu\").output       # 32 * 32\n",
        "\n",
        "  ## BottleNeck or bridge \n",
        "  b1 = encoder.get_layer(\"pool4_relu\").output       # 16 * 16\n",
        "\n",
        "  ## Decoder\n",
        "  d1 = decoder_block(b1 , s4 , 512)                                # 32 * 32 * 512 where 512 is the number of Features we extracted \n",
        "\n",
        "  d2 = decoder_block(d1 , s3 , 256)                                # 64 * 64\n",
        "\n",
        "  d3 = decoder_block(d2 , s2 , 128)                                # 128 * 128\n",
        "\n",
        "  d4 = decoder_block(d3 , s1 , 64)                                # 128 * 128\n",
        "\n",
        "  ## OUTPUT \n",
        "  x = Conv2D( 2 ,  1  ,  padding = \"same\" ,  activation = \"relu\")(d4)\n",
        "  outputs = Conv2D( 1 ,  1  ,  padding = \"same\" ,  activation = \"sigmoid\")(x)\n",
        "\n",
        "  ## MODEL \n",
        "\n",
        "  model = Model(inputs , outputs ,  name = \"DenseNet210\")\n",
        "\n",
        "  return model\n",
        "  #encoder.summary()"
      ],
      "metadata": {
        "id": "SU-bbp33jXrj",
        "execution": {
          "iopub.status.busy": "2021-09-16T09:37:00.977277Z",
          "iopub.execute_input": "2021-09-16T09:37:00.979653Z",
          "iopub.status.idle": "2021-09-16T09:37:00.998459Z",
          "shell.execute_reply.started": "2021-09-16T09:37:00.979587Z",
          "shell.execute_reply": "2021-09-16T09:37:00.997667Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lrate = 7.00E-05 \n",
        "\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    input_shape = (256, 256, 3)\n",
        "    model = build_DenseNet210_Unet(input_shape)\n",
        "    model.summary()\n",
        "    model_checkpoint1 = keras.callbacks.ModelCheckpoint('att_r2_unet.hdf5', monitor='val_dice_loss',verbose=1,mode='min',save_best_only=True)\n",
        "    csv_logger = CSVLogger('trainingRes2Net.log', append=True, separator=';')\n",
        "    model.compile(optimizer=Adam(lr=lrate), loss=ACL5 , metrics=[ACL5 ,bce_jaccard_loss , dice_coef , dsc,  dice_loss,iou_coeff,precision,recall])"
      ],
      "metadata": {
        "id": "kFchkooujXrk",
        "outputId": "cc29d1b8-4e58-475a-baab-26468e90c067",
        "execution": {
          "iopub.status.busy": "2021-09-16T09:37:01.003088Z",
          "iopub.execute_input": "2021-09-16T09:37:01.005450Z",
          "iopub.status.idle": "2021-09-16T09:37:08.040095Z",
          "shell.execute_reply.started": "2021-09-16T09:37:01.005350Z",
          "shell.execute_reply": "2021-09-16T09:37:08.039388Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "2021-09-16 09:37:01.061922: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-09-16 09:37:01.065844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n2021-09-16 09:37:01.118692: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-16 09:37:01.119669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\ncoreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n2021-09-16 09:37:01.119749: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-16 09:37:01.145670: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-16 09:37:01.145771: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-16 09:37:01.163408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-09-16 09:37:01.189702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-09-16 09:37:01.217498: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-09-16 09:37:01.225114: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-09-16 09:37:01.227745: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-09-16 09:37:01.227952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-16 09:37:01.228928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-16 09:37:01.230692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-09-16 09:37:01.232405: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2021-09-16 09:37:01.232647: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-09-16 09:37:01.232819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-16 09:37:01.233643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\ncoreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n2021-09-16 09:37:01.233691: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-16 09:37:01.233731: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-16 09:37:01.233758: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-16 09:37:01.233784: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-09-16 09:37:01.233809: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-09-16 09:37:01.233835: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-09-16 09:37:01.233860: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-09-16 09:37:01.233886: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-09-16 09:37:01.233995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-16 09:37:01.234903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-16 09:37:01.235702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-09-16 09:37:01.236762: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-16 09:37:02.692801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n2021-09-16 09:37:02.692854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n2021-09-16 09:37:02.692866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n2021-09-16 09:37:02.695473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-16 09:37:02.696283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-16 09:37:02.696944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-16 09:37:02.697516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n74842112/74836368 [==============================] - 1s 0us/step\nModel: \"DenseNet210\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n__________________________________________________________________________________________________\nzero_padding2d (ZeroPadding2D)  (None, 262, 262, 3)  0           input_1[0][0]                    \n__________________________________________________________________________________________________\nconv1/conv (Conv2D)             (None, 128, 128, 64) 9408        zero_padding2d[0][0]             \n__________________________________________________________________________________________________\nconv1/bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1/conv[0][0]                 \n__________________________________________________________________________________________________\nconv1/relu (Activation)         (None, 128, 128, 64) 0           conv1/bn[0][0]                   \n__________________________________________________________________________________________________\nzero_padding2d_1 (ZeroPadding2D (None, 130, 130, 64) 0           conv1/relu[0][0]                 \n__________________________________________________________________________________________________\npool1 (MaxPooling2D)            (None, 64, 64, 64)   0           zero_padding2d_1[0][0]           \n__________________________________________________________________________________________________\nconv2_block1_0_bn (BatchNormali (None, 64, 64, 64)   256         pool1[0][0]                      \n__________________________________________________________________________________________________\nconv2_block1_0_relu (Activation (None, 64, 64, 64)   0           conv2_block1_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_1_conv (Conv2D)    (None, 64, 64, 128)  8192        conv2_block1_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_1_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_1_relu (Activation (None, 64, 64, 128)  0           conv2_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv2_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_concat (Concatenat (None, 64, 64, 96)   0           pool1[0][0]                      \n                                                                 conv2_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_0_bn (BatchNormali (None, 64, 64, 96)   384         conv2_block1_concat[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_0_relu (Activation (None, 64, 64, 96)   0           conv2_block2_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_1_conv (Conv2D)    (None, 64, 64, 128)  12288       conv2_block2_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_1_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_1_relu (Activation (None, 64, 64, 128)  0           conv2_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv2_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_concat (Concatenat (None, 64, 64, 128)  0           conv2_block1_concat[0][0]        \n                                                                 conv2_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_0_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block2_concat[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_0_relu (Activation (None, 64, 64, 128)  0           conv2_block3_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_1_conv (Conv2D)    (None, 64, 64, 128)  16384       conv2_block3_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_1_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_1_relu (Activation (None, 64, 64, 128)  0           conv2_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv2_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_concat (Concatenat (None, 64, 64, 160)  0           conv2_block2_concat[0][0]        \n                                                                 conv2_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block4_0_bn (BatchNormali (None, 64, 64, 160)  640         conv2_block3_concat[0][0]        \n__________________________________________________________________________________________________\nconv2_block4_0_relu (Activation (None, 64, 64, 160)  0           conv2_block4_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block4_1_conv (Conv2D)    (None, 64, 64, 128)  20480       conv2_block4_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block4_1_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block4_1_relu (Activation (None, 64, 64, 128)  0           conv2_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block4_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv2_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block4_concat (Concatenat (None, 64, 64, 192)  0           conv2_block3_concat[0][0]        \n                                                                 conv2_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block5_0_bn (BatchNormali (None, 64, 64, 192)  768         conv2_block4_concat[0][0]        \n__________________________________________________________________________________________________\nconv2_block5_0_relu (Activation (None, 64, 64, 192)  0           conv2_block5_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block5_1_conv (Conv2D)    (None, 64, 64, 128)  24576       conv2_block5_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block5_1_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block5_1_relu (Activation (None, 64, 64, 128)  0           conv2_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block5_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv2_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block5_concat (Concatenat (None, 64, 64, 224)  0           conv2_block4_concat[0][0]        \n                                                                 conv2_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block6_0_bn (BatchNormali (None, 64, 64, 224)  896         conv2_block5_concat[0][0]        \n__________________________________________________________________________________________________\nconv2_block6_0_relu (Activation (None, 64, 64, 224)  0           conv2_block6_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block6_1_conv (Conv2D)    (None, 64, 64, 128)  28672       conv2_block6_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block6_1_bn (BatchNormali (None, 64, 64, 128)  512         conv2_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block6_1_relu (Activation (None, 64, 64, 128)  0           conv2_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block6_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv2_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block6_concat (Concatenat (None, 64, 64, 256)  0           conv2_block5_concat[0][0]        \n                                                                 conv2_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\npool2_bn (BatchNormalization)   (None, 64, 64, 256)  1024        conv2_block6_concat[0][0]        \n__________________________________________________________________________________________________\npool2_relu (Activation)         (None, 64, 64, 256)  0           pool2_bn[0][0]                   \n__________________________________________________________________________________________________\npool2_conv (Conv2D)             (None, 64, 64, 128)  32768       pool2_relu[0][0]                 \n__________________________________________________________________________________________________\npool2_pool (AveragePooling2D)   (None, 32, 32, 128)  0           pool2_conv[0][0]                 \n__________________________________________________________________________________________________\nconv3_block1_0_bn (BatchNormali (None, 32, 32, 128)  512         pool2_pool[0][0]                 \n__________________________________________________________________________________________________\nconv3_block1_0_relu (Activation (None, 32, 32, 128)  0           conv3_block1_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  16384       conv3_block1_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_concat (Concatenat (None, 32, 32, 160)  0           pool2_pool[0][0]                 \n                                                                 conv3_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_0_bn (BatchNormali (None, 32, 32, 160)  640         conv3_block1_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_0_relu (Activation (None, 32, 32, 160)  0           conv3_block2_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  20480       conv3_block2_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_concat (Concatenat (None, 32, 32, 192)  0           conv3_block1_concat[0][0]        \n                                                                 conv3_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_0_bn (BatchNormali (None, 32, 32, 192)  768         conv3_block2_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_0_relu (Activation (None, 32, 32, 192)  0           conv3_block3_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  24576       conv3_block3_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_concat (Concatenat (None, 32, 32, 224)  0           conv3_block2_concat[0][0]        \n                                                                 conv3_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_0_bn (BatchNormali (None, 32, 32, 224)  896         conv3_block3_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_0_relu (Activation (None, 32, 32, 224)  0           conv3_block4_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  28672       conv3_block4_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_concat (Concatenat (None, 32, 32, 256)  0           conv3_block3_concat[0][0]        \n                                                                 conv3_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_0_bn (BatchNormali (None, 32, 32, 256)  1024        conv3_block4_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_0_relu (Activation (None, 32, 32, 256)  0           conv3_block5_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block5_1_conv (Conv2D)    (None, 32, 32, 128)  32768       conv3_block5_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_1_relu (Activation (None, 32, 32, 128)  0           conv3_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block5_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_concat (Concatenat (None, 32, 32, 288)  0           conv3_block4_concat[0][0]        \n                                                                 conv3_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_0_bn (BatchNormali (None, 32, 32, 288)  1152        conv3_block5_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_0_relu (Activation (None, 32, 32, 288)  0           conv3_block6_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block6_1_conv (Conv2D)    (None, 32, 32, 128)  36864       conv3_block6_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_1_relu (Activation (None, 32, 32, 128)  0           conv3_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block6_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_concat (Concatenat (None, 32, 32, 320)  0           conv3_block5_concat[0][0]        \n                                                                 conv3_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_0_bn (BatchNormali (None, 32, 32, 320)  1280        conv3_block6_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_0_relu (Activation (None, 32, 32, 320)  0           conv3_block7_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block7_1_conv (Conv2D)    (None, 32, 32, 128)  40960       conv3_block7_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block7_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_1_relu (Activation (None, 32, 32, 128)  0           conv3_block7_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block7_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block7_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_concat (Concatenat (None, 32, 32, 352)  0           conv3_block6_concat[0][0]        \n                                                                 conv3_block7_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_0_bn (BatchNormali (None, 32, 32, 352)  1408        conv3_block7_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_0_relu (Activation (None, 32, 32, 352)  0           conv3_block8_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block8_1_conv (Conv2D)    (None, 32, 32, 128)  45056       conv3_block8_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block8_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_1_relu (Activation (None, 32, 32, 128)  0           conv3_block8_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block8_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block8_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_concat (Concatenat (None, 32, 32, 384)  0           conv3_block7_concat[0][0]        \n                                                                 conv3_block8_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block9_0_bn (BatchNormali (None, 32, 32, 384)  1536        conv3_block8_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block9_0_relu (Activation (None, 32, 32, 384)  0           conv3_block9_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block9_1_conv (Conv2D)    (None, 32, 32, 128)  49152       conv3_block9_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block9_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block9_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block9_1_relu (Activation (None, 32, 32, 128)  0           conv3_block9_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block9_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv3_block9_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block9_concat (Concatenat (None, 32, 32, 416)  0           conv3_block8_concat[0][0]        \n                                                                 conv3_block9_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block10_0_bn (BatchNormal (None, 32, 32, 416)  1664        conv3_block9_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block10_0_relu (Activatio (None, 32, 32, 416)  0           conv3_block10_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv3_block10_1_conv (Conv2D)   (None, 32, 32, 128)  53248       conv3_block10_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv3_block10_1_bn (BatchNormal (None, 32, 32, 128)  512         conv3_block10_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv3_block10_1_relu (Activatio (None, 32, 32, 128)  0           conv3_block10_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv3_block10_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv3_block10_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv3_block10_concat (Concatena (None, 32, 32, 448)  0           conv3_block9_concat[0][0]        \n                                                                 conv3_block10_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv3_block11_0_bn (BatchNormal (None, 32, 32, 448)  1792        conv3_block10_concat[0][0]       \n__________________________________________________________________________________________________\nconv3_block11_0_relu (Activatio (None, 32, 32, 448)  0           conv3_block11_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv3_block11_1_conv (Conv2D)   (None, 32, 32, 128)  57344       conv3_block11_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv3_block11_1_bn (BatchNormal (None, 32, 32, 128)  512         conv3_block11_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv3_block11_1_relu (Activatio (None, 32, 32, 128)  0           conv3_block11_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv3_block11_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv3_block11_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv3_block11_concat (Concatena (None, 32, 32, 480)  0           conv3_block10_concat[0][0]       \n                                                                 conv3_block11_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv3_block12_0_bn (BatchNormal (None, 32, 32, 480)  1920        conv3_block11_concat[0][0]       \n__________________________________________________________________________________________________\nconv3_block12_0_relu (Activatio (None, 32, 32, 480)  0           conv3_block12_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv3_block12_1_conv (Conv2D)   (None, 32, 32, 128)  61440       conv3_block12_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv3_block12_1_bn (BatchNormal (None, 32, 32, 128)  512         conv3_block12_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv3_block12_1_relu (Activatio (None, 32, 32, 128)  0           conv3_block12_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv3_block12_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv3_block12_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv3_block12_concat (Concatena (None, 32, 32, 512)  0           conv3_block11_concat[0][0]       \n                                                                 conv3_block12_2_conv[0][0]       \n__________________________________________________________________________________________________\npool3_bn (BatchNormalization)   (None, 32, 32, 512)  2048        conv3_block12_concat[0][0]       \n__________________________________________________________________________________________________\npool3_relu (Activation)         (None, 32, 32, 512)  0           pool3_bn[0][0]                   \n__________________________________________________________________________________________________\npool3_conv (Conv2D)             (None, 32, 32, 256)  131072      pool3_relu[0][0]                 \n__________________________________________________________________________________________________\npool3_pool (AveragePooling2D)   (None, 16, 16, 256)  0           pool3_conv[0][0]                 \n__________________________________________________________________________________________________\nconv4_block1_0_bn (BatchNormali (None, 16, 16, 256)  1024        pool3_pool[0][0]                 \n__________________________________________________________________________________________________\nconv4_block1_0_relu (Activation (None, 16, 16, 256)  0           conv4_block1_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_1_conv (Conv2D)    (None, 16, 16, 128)  32768       conv4_block1_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_1_relu (Activation (None, 16, 16, 128)  0           conv4_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_concat (Concatenat (None, 16, 16, 288)  0           pool3_pool[0][0]                 \n                                                                 conv4_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_0_bn (BatchNormali (None, 16, 16, 288)  1152        conv4_block1_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_0_relu (Activation (None, 16, 16, 288)  0           conv4_block2_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_1_conv (Conv2D)    (None, 16, 16, 128)  36864       conv4_block2_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_1_relu (Activation (None, 16, 16, 128)  0           conv4_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_concat (Concatenat (None, 16, 16, 320)  0           conv4_block1_concat[0][0]        \n                                                                 conv4_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_0_bn (BatchNormali (None, 16, 16, 320)  1280        conv4_block2_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_0_relu (Activation (None, 16, 16, 320)  0           conv4_block3_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_1_conv (Conv2D)    (None, 16, 16, 128)  40960       conv4_block3_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_1_relu (Activation (None, 16, 16, 128)  0           conv4_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_concat (Concatenat (None, 16, 16, 352)  0           conv4_block2_concat[0][0]        \n                                                                 conv4_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_0_bn (BatchNormali (None, 16, 16, 352)  1408        conv4_block3_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_0_relu (Activation (None, 16, 16, 352)  0           conv4_block4_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_1_conv (Conv2D)    (None, 16, 16, 128)  45056       conv4_block4_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_1_relu (Activation (None, 16, 16, 128)  0           conv4_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_concat (Concatenat (None, 16, 16, 384)  0           conv4_block3_concat[0][0]        \n                                                                 conv4_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_0_bn (BatchNormali (None, 16, 16, 384)  1536        conv4_block4_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_0_relu (Activation (None, 16, 16, 384)  0           conv4_block5_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_1_conv (Conv2D)    (None, 16, 16, 128)  49152       conv4_block5_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_1_relu (Activation (None, 16, 16, 128)  0           conv4_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_concat (Concatenat (None, 16, 16, 416)  0           conv4_block4_concat[0][0]        \n                                                                 conv4_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_0_bn (BatchNormali (None, 16, 16, 416)  1664        conv4_block5_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_0_relu (Activation (None, 16, 16, 416)  0           conv4_block6_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_1_conv (Conv2D)    (None, 16, 16, 128)  53248       conv4_block6_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_1_relu (Activation (None, 16, 16, 128)  0           conv4_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_concat (Concatenat (None, 16, 16, 448)  0           conv4_block5_concat[0][0]        \n                                                                 conv4_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_0_bn (BatchNormali (None, 16, 16, 448)  1792        conv4_block6_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_0_relu (Activation (None, 16, 16, 448)  0           conv4_block7_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block7_1_conv (Conv2D)    (None, 16, 16, 128)  57344       conv4_block7_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block7_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_1_relu (Activation (None, 16, 16, 128)  0           conv4_block7_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block7_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block7_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_concat (Concatenat (None, 16, 16, 480)  0           conv4_block6_concat[0][0]        \n                                                                 conv4_block7_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_0_bn (BatchNormali (None, 16, 16, 480)  1920        conv4_block7_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_0_relu (Activation (None, 16, 16, 480)  0           conv4_block8_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block8_1_conv (Conv2D)    (None, 16, 16, 128)  61440       conv4_block8_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block8_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_1_relu (Activation (None, 16, 16, 128)  0           conv4_block8_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block8_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block8_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_concat (Concatenat (None, 16, 16, 512)  0           conv4_block7_concat[0][0]        \n                                                                 conv4_block8_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_0_bn (BatchNormali (None, 16, 16, 512)  2048        conv4_block8_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_0_relu (Activation (None, 16, 16, 512)  0           conv4_block9_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block9_1_conv (Conv2D)    (None, 16, 16, 128)  65536       conv4_block9_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_1_bn (BatchNormali (None, 16, 16, 128)  512         conv4_block9_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_1_relu (Activation (None, 16, 16, 128)  0           conv4_block9_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block9_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv4_block9_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_concat (Concatenat (None, 16, 16, 544)  0           conv4_block8_concat[0][0]        \n                                                                 conv4_block9_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block10_0_bn (BatchNormal (None, 16, 16, 544)  2176        conv4_block9_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block10_0_relu (Activatio (None, 16, 16, 544)  0           conv4_block10_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block10_1_conv (Conv2D)   (None, 16, 16, 128)  69632       conv4_block10_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block10_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block10_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block10_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block10_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block10_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block10_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block10_concat (Concatena (None, 16, 16, 576)  0           conv4_block9_concat[0][0]        \n                                                                 conv4_block10_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_0_bn (BatchNormal (None, 16, 16, 576)  2304        conv4_block10_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_0_relu (Activatio (None, 16, 16, 576)  0           conv4_block11_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block11_1_conv (Conv2D)   (None, 16, 16, 128)  73728       conv4_block11_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block11_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block11_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block11_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block11_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_concat (Concatena (None, 16, 16, 608)  0           conv4_block10_concat[0][0]       \n                                                                 conv4_block11_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_0_bn (BatchNormal (None, 16, 16, 608)  2432        conv4_block11_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_0_relu (Activatio (None, 16, 16, 608)  0           conv4_block12_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block12_1_conv (Conv2D)   (None, 16, 16, 128)  77824       conv4_block12_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block12_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block12_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block12_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block12_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_concat (Concatena (None, 16, 16, 640)  0           conv4_block11_concat[0][0]       \n                                                                 conv4_block12_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_0_bn (BatchNormal (None, 16, 16, 640)  2560        conv4_block12_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_0_relu (Activatio (None, 16, 16, 640)  0           conv4_block13_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block13_1_conv (Conv2D)   (None, 16, 16, 128)  81920       conv4_block13_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block13_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block13_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block13_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block13_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_concat (Concatena (None, 16, 16, 672)  0           conv4_block12_concat[0][0]       \n                                                                 conv4_block13_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_0_bn (BatchNormal (None, 16, 16, 672)  2688        conv4_block13_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_0_relu (Activatio (None, 16, 16, 672)  0           conv4_block14_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block14_1_conv (Conv2D)   (None, 16, 16, 128)  86016       conv4_block14_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block14_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block14_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block14_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block14_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_concat (Concatena (None, 16, 16, 704)  0           conv4_block13_concat[0][0]       \n                                                                 conv4_block14_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_0_bn (BatchNormal (None, 16, 16, 704)  2816        conv4_block14_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_0_relu (Activatio (None, 16, 16, 704)  0           conv4_block15_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block15_1_conv (Conv2D)   (None, 16, 16, 128)  90112       conv4_block15_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block15_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block15_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block15_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block15_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_concat (Concatena (None, 16, 16, 736)  0           conv4_block14_concat[0][0]       \n                                                                 conv4_block15_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_0_bn (BatchNormal (None, 16, 16, 736)  2944        conv4_block15_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_0_relu (Activatio (None, 16, 16, 736)  0           conv4_block16_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block16_1_conv (Conv2D)   (None, 16, 16, 128)  94208       conv4_block16_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block16_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block16_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block16_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block16_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_concat (Concatena (None, 16, 16, 768)  0           conv4_block15_concat[0][0]       \n                                                                 conv4_block16_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_0_bn (BatchNormal (None, 16, 16, 768)  3072        conv4_block16_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_0_relu (Activatio (None, 16, 16, 768)  0           conv4_block17_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block17_1_conv (Conv2D)   (None, 16, 16, 128)  98304       conv4_block17_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block17_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block17_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block17_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block17_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_concat (Concatena (None, 16, 16, 800)  0           conv4_block16_concat[0][0]       \n                                                                 conv4_block17_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_0_bn (BatchNormal (None, 16, 16, 800)  3200        conv4_block17_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_0_relu (Activatio (None, 16, 16, 800)  0           conv4_block18_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block18_1_conv (Conv2D)   (None, 16, 16, 128)  102400      conv4_block18_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block18_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block18_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block18_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block18_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_concat (Concatena (None, 16, 16, 832)  0           conv4_block17_concat[0][0]       \n                                                                 conv4_block18_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_0_bn (BatchNormal (None, 16, 16, 832)  3328        conv4_block18_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_0_relu (Activatio (None, 16, 16, 832)  0           conv4_block19_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block19_1_conv (Conv2D)   (None, 16, 16, 128)  106496      conv4_block19_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block19_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block19_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block19_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block19_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_concat (Concatena (None, 16, 16, 864)  0           conv4_block18_concat[0][0]       \n                                                                 conv4_block19_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_0_bn (BatchNormal (None, 16, 16, 864)  3456        conv4_block19_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_0_relu (Activatio (None, 16, 16, 864)  0           conv4_block20_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block20_1_conv (Conv2D)   (None, 16, 16, 128)  110592      conv4_block20_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block20_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block20_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block20_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block20_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_concat (Concatena (None, 16, 16, 896)  0           conv4_block19_concat[0][0]       \n                                                                 conv4_block20_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_0_bn (BatchNormal (None, 16, 16, 896)  3584        conv4_block20_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_0_relu (Activatio (None, 16, 16, 896)  0           conv4_block21_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block21_1_conv (Conv2D)   (None, 16, 16, 128)  114688      conv4_block21_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block21_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block21_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block21_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block21_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_concat (Concatena (None, 16, 16, 928)  0           conv4_block20_concat[0][0]       \n                                                                 conv4_block21_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_0_bn (BatchNormal (None, 16, 16, 928)  3712        conv4_block21_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_0_relu (Activatio (None, 16, 16, 928)  0           conv4_block22_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block22_1_conv (Conv2D)   (None, 16, 16, 128)  118784      conv4_block22_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block22_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block22_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block22_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block22_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_concat (Concatena (None, 16, 16, 960)  0           conv4_block21_concat[0][0]       \n                                                                 conv4_block22_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_0_bn (BatchNormal (None, 16, 16, 960)  3840        conv4_block22_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_0_relu (Activatio (None, 16, 16, 960)  0           conv4_block23_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block23_1_conv (Conv2D)   (None, 16, 16, 128)  122880      conv4_block23_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block23_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block23_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block23_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block23_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_concat (Concatena (None, 16, 16, 992)  0           conv4_block22_concat[0][0]       \n                                                                 conv4_block23_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_0_bn (BatchNormal (None, 16, 16, 992)  3968        conv4_block23_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_0_relu (Activatio (None, 16, 16, 992)  0           conv4_block24_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block24_1_conv (Conv2D)   (None, 16, 16, 128)  126976      conv4_block24_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block24_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block24_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block24_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block24_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_concat (Concatena (None, 16, 16, 1024) 0           conv4_block23_concat[0][0]       \n                                                                 conv4_block24_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block25_0_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block24_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block25_0_relu (Activatio (None, 16, 16, 1024) 0           conv4_block25_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block25_1_conv (Conv2D)   (None, 16, 16, 128)  131072      conv4_block25_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block25_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block25_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block25_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block25_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block25_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block25_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block25_concat (Concatena (None, 16, 16, 1056) 0           conv4_block24_concat[0][0]       \n                                                                 conv4_block25_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block26_0_bn (BatchNormal (None, 16, 16, 1056) 4224        conv4_block25_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block26_0_relu (Activatio (None, 16, 16, 1056) 0           conv4_block26_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block26_1_conv (Conv2D)   (None, 16, 16, 128)  135168      conv4_block26_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block26_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block26_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block26_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block26_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block26_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block26_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block26_concat (Concatena (None, 16, 16, 1088) 0           conv4_block25_concat[0][0]       \n                                                                 conv4_block26_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block27_0_bn (BatchNormal (None, 16, 16, 1088) 4352        conv4_block26_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block27_0_relu (Activatio (None, 16, 16, 1088) 0           conv4_block27_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block27_1_conv (Conv2D)   (None, 16, 16, 128)  139264      conv4_block27_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block27_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block27_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block27_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block27_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block27_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block27_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block27_concat (Concatena (None, 16, 16, 1120) 0           conv4_block26_concat[0][0]       \n                                                                 conv4_block27_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block28_0_bn (BatchNormal (None, 16, 16, 1120) 4480        conv4_block27_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block28_0_relu (Activatio (None, 16, 16, 1120) 0           conv4_block28_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block28_1_conv (Conv2D)   (None, 16, 16, 128)  143360      conv4_block28_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block28_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block28_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block28_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block28_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block28_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block28_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block28_concat (Concatena (None, 16, 16, 1152) 0           conv4_block27_concat[0][0]       \n                                                                 conv4_block28_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block29_0_bn (BatchNormal (None, 16, 16, 1152) 4608        conv4_block28_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block29_0_relu (Activatio (None, 16, 16, 1152) 0           conv4_block29_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block29_1_conv (Conv2D)   (None, 16, 16, 128)  147456      conv4_block29_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block29_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block29_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block29_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block29_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block29_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block29_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block29_concat (Concatena (None, 16, 16, 1184) 0           conv4_block28_concat[0][0]       \n                                                                 conv4_block29_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block30_0_bn (BatchNormal (None, 16, 16, 1184) 4736        conv4_block29_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block30_0_relu (Activatio (None, 16, 16, 1184) 0           conv4_block30_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block30_1_conv (Conv2D)   (None, 16, 16, 128)  151552      conv4_block30_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block30_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block30_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block30_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block30_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block30_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block30_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block30_concat (Concatena (None, 16, 16, 1216) 0           conv4_block29_concat[0][0]       \n                                                                 conv4_block30_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block31_0_bn (BatchNormal (None, 16, 16, 1216) 4864        conv4_block30_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block31_0_relu (Activatio (None, 16, 16, 1216) 0           conv4_block31_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block31_1_conv (Conv2D)   (None, 16, 16, 128)  155648      conv4_block31_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block31_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block31_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block31_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block31_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block31_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block31_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block31_concat (Concatena (None, 16, 16, 1248) 0           conv4_block30_concat[0][0]       \n                                                                 conv4_block31_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block32_0_bn (BatchNormal (None, 16, 16, 1248) 4992        conv4_block31_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block32_0_relu (Activatio (None, 16, 16, 1248) 0           conv4_block32_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block32_1_conv (Conv2D)   (None, 16, 16, 128)  159744      conv4_block32_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block32_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block32_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block32_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block32_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block32_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block32_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block32_concat (Concatena (None, 16, 16, 1280) 0           conv4_block31_concat[0][0]       \n                                                                 conv4_block32_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block33_0_bn (BatchNormal (None, 16, 16, 1280) 5120        conv4_block32_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block33_0_relu (Activatio (None, 16, 16, 1280) 0           conv4_block33_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block33_1_conv (Conv2D)   (None, 16, 16, 128)  163840      conv4_block33_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block33_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block33_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block33_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block33_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block33_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block33_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block33_concat (Concatena (None, 16, 16, 1312) 0           conv4_block32_concat[0][0]       \n                                                                 conv4_block33_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block34_0_bn (BatchNormal (None, 16, 16, 1312) 5248        conv4_block33_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block34_0_relu (Activatio (None, 16, 16, 1312) 0           conv4_block34_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block34_1_conv (Conv2D)   (None, 16, 16, 128)  167936      conv4_block34_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block34_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block34_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block34_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block34_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block34_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block34_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block34_concat (Concatena (None, 16, 16, 1344) 0           conv4_block33_concat[0][0]       \n                                                                 conv4_block34_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block35_0_bn (BatchNormal (None, 16, 16, 1344) 5376        conv4_block34_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block35_0_relu (Activatio (None, 16, 16, 1344) 0           conv4_block35_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block35_1_conv (Conv2D)   (None, 16, 16, 128)  172032      conv4_block35_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block35_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block35_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block35_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block35_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block35_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block35_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block35_concat (Concatena (None, 16, 16, 1376) 0           conv4_block34_concat[0][0]       \n                                                                 conv4_block35_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block36_0_bn (BatchNormal (None, 16, 16, 1376) 5504        conv4_block35_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block36_0_relu (Activatio (None, 16, 16, 1376) 0           conv4_block36_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block36_1_conv (Conv2D)   (None, 16, 16, 128)  176128      conv4_block36_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block36_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block36_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block36_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block36_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block36_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block36_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block36_concat (Concatena (None, 16, 16, 1408) 0           conv4_block35_concat[0][0]       \n                                                                 conv4_block36_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block37_0_bn (BatchNormal (None, 16, 16, 1408) 5632        conv4_block36_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block37_0_relu (Activatio (None, 16, 16, 1408) 0           conv4_block37_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block37_1_conv (Conv2D)   (None, 16, 16, 128)  180224      conv4_block37_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block37_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block37_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block37_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block37_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block37_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block37_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block37_concat (Concatena (None, 16, 16, 1440) 0           conv4_block36_concat[0][0]       \n                                                                 conv4_block37_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block38_0_bn (BatchNormal (None, 16, 16, 1440) 5760        conv4_block37_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block38_0_relu (Activatio (None, 16, 16, 1440) 0           conv4_block38_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block38_1_conv (Conv2D)   (None, 16, 16, 128)  184320      conv4_block38_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block38_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block38_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block38_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block38_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block38_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block38_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block38_concat (Concatena (None, 16, 16, 1472) 0           conv4_block37_concat[0][0]       \n                                                                 conv4_block38_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block39_0_bn (BatchNormal (None, 16, 16, 1472) 5888        conv4_block38_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block39_0_relu (Activatio (None, 16, 16, 1472) 0           conv4_block39_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block39_1_conv (Conv2D)   (None, 16, 16, 128)  188416      conv4_block39_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block39_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block39_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block39_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block39_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block39_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block39_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block39_concat (Concatena (None, 16, 16, 1504) 0           conv4_block38_concat[0][0]       \n                                                                 conv4_block39_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block40_0_bn (BatchNormal (None, 16, 16, 1504) 6016        conv4_block39_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block40_0_relu (Activatio (None, 16, 16, 1504) 0           conv4_block40_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block40_1_conv (Conv2D)   (None, 16, 16, 128)  192512      conv4_block40_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block40_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block40_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block40_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block40_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block40_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block40_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block40_concat (Concatena (None, 16, 16, 1536) 0           conv4_block39_concat[0][0]       \n                                                                 conv4_block40_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block41_0_bn (BatchNormal (None, 16, 16, 1536) 6144        conv4_block40_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block41_0_relu (Activatio (None, 16, 16, 1536) 0           conv4_block41_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block41_1_conv (Conv2D)   (None, 16, 16, 128)  196608      conv4_block41_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block41_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block41_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block41_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block41_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block41_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block41_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block41_concat (Concatena (None, 16, 16, 1568) 0           conv4_block40_concat[0][0]       \n                                                                 conv4_block41_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block42_0_bn (BatchNormal (None, 16, 16, 1568) 6272        conv4_block41_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block42_0_relu (Activatio (None, 16, 16, 1568) 0           conv4_block42_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block42_1_conv (Conv2D)   (None, 16, 16, 128)  200704      conv4_block42_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block42_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block42_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block42_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block42_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block42_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block42_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block42_concat (Concatena (None, 16, 16, 1600) 0           conv4_block41_concat[0][0]       \n                                                                 conv4_block42_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block43_0_bn (BatchNormal (None, 16, 16, 1600) 6400        conv4_block42_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block43_0_relu (Activatio (None, 16, 16, 1600) 0           conv4_block43_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block43_1_conv (Conv2D)   (None, 16, 16, 128)  204800      conv4_block43_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block43_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block43_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block43_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block43_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block43_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block43_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block43_concat (Concatena (None, 16, 16, 1632) 0           conv4_block42_concat[0][0]       \n                                                                 conv4_block43_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block44_0_bn (BatchNormal (None, 16, 16, 1632) 6528        conv4_block43_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block44_0_relu (Activatio (None, 16, 16, 1632) 0           conv4_block44_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block44_1_conv (Conv2D)   (None, 16, 16, 128)  208896      conv4_block44_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block44_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block44_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block44_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block44_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block44_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block44_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block44_concat (Concatena (None, 16, 16, 1664) 0           conv4_block43_concat[0][0]       \n                                                                 conv4_block44_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block45_0_bn (BatchNormal (None, 16, 16, 1664) 6656        conv4_block44_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block45_0_relu (Activatio (None, 16, 16, 1664) 0           conv4_block45_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block45_1_conv (Conv2D)   (None, 16, 16, 128)  212992      conv4_block45_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block45_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block45_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block45_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block45_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block45_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block45_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block45_concat (Concatena (None, 16, 16, 1696) 0           conv4_block44_concat[0][0]       \n                                                                 conv4_block45_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block46_0_bn (BatchNormal (None, 16, 16, 1696) 6784        conv4_block45_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block46_0_relu (Activatio (None, 16, 16, 1696) 0           conv4_block46_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block46_1_conv (Conv2D)   (None, 16, 16, 128)  217088      conv4_block46_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block46_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block46_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block46_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block46_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block46_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block46_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block46_concat (Concatena (None, 16, 16, 1728) 0           conv4_block45_concat[0][0]       \n                                                                 conv4_block46_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block47_0_bn (BatchNormal (None, 16, 16, 1728) 6912        conv4_block46_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block47_0_relu (Activatio (None, 16, 16, 1728) 0           conv4_block47_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block47_1_conv (Conv2D)   (None, 16, 16, 128)  221184      conv4_block47_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block47_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block47_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block47_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block47_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block47_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block47_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block47_concat (Concatena (None, 16, 16, 1760) 0           conv4_block46_concat[0][0]       \n                                                                 conv4_block47_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block48_0_bn (BatchNormal (None, 16, 16, 1760) 7040        conv4_block47_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block48_0_relu (Activatio (None, 16, 16, 1760) 0           conv4_block48_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block48_1_conv (Conv2D)   (None, 16, 16, 128)  225280      conv4_block48_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block48_1_bn (BatchNormal (None, 16, 16, 128)  512         conv4_block48_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block48_1_relu (Activatio (None, 16, 16, 128)  0           conv4_block48_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block48_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv4_block48_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block48_concat (Concatena (None, 16, 16, 1792) 0           conv4_block47_concat[0][0]       \n                                                                 conv4_block48_2_conv[0][0]       \n__________________________________________________________________________________________________\npool4_bn (BatchNormalization)   (None, 16, 16, 1792) 7168        conv4_block48_concat[0][0]       \n__________________________________________________________________________________________________\npool4_relu (Activation)         (None, 16, 16, 1792) 0           pool4_bn[0][0]                   \n__________________________________________________________________________________________________\nconv2d_transpose (Conv2DTranspo (None, 32, 32, 512)  3670528     pool4_relu[0][0]                 \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 32, 32, 1024) 0           conv2d_transpose[0][0]           \n                                                                 pool3_relu[0][0]                 \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 32, 32, 512)  4719104     concatenate[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 32, 32, 512)  2048        conv2d[0][0]                     \n__________________________________________________________________________________________________\nactivation (Activation)         (None, 32, 32, 512)  0           batch_normalization[0][0]        \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 32, 32, 512)  0           activation[0][0]                 \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 32, 32, 512)  2359808     dropout[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 32, 32, 512)  2048        conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 32, 32, 512)  0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 32, 32, 512)  0           activation_1[0][0]               \n__________________________________________________________________________________________________\nconv2d_transpose_1 (Conv2DTrans (None, 64, 64, 256)  524544      dropout_1[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 64, 64, 512)  0           conv2d_transpose_1[0][0]         \n                                                                 pool2_relu[0][0]                 \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 64, 64, 256)  1179904     concatenate_1[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 64, 64, 256)  1024        conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 64, 64, 256)  0           batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\ndropout_2 (Dropout)             (None, 64, 64, 256)  0           activation_2[0][0]               \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 64, 64, 256)  590080      dropout_2[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 64, 64, 256)  1024        conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 64, 64, 256)  0           batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\ndropout_3 (Dropout)             (None, 64, 64, 256)  0           activation_3[0][0]               \n__________________________________________________________________________________________________\nconv2d_transpose_2 (Conv2DTrans (None, 128, 128, 128 131200      dropout_3[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 128, 128, 192 0           conv2d_transpose_2[0][0]         \n                                                                 conv1/relu[0][0]                 \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 128, 128, 128 221312      concatenate_2[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 128, 128, 128 512         conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 128, 128, 128 0           batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\ndropout_4 (Dropout)             (None, 128, 128, 128 0           activation_4[0][0]               \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 128, 128, 128 147584      dropout_4[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_5 (BatchNor (None, 128, 128, 128 512         conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 128, 128, 128 0           batch_normalization_5[0][0]      \n__________________________________________________________________________________________________\ndropout_5 (Dropout)             (None, 128, 128, 128 0           activation_5[0][0]               \n__________________________________________________________________________________________________\nconv2d_transpose_3 (Conv2DTrans (None, 256, 256, 64) 32832       dropout_5[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_3 (Concatenate)     (None, 256, 256, 67) 0           conv2d_transpose_3[0][0]         \n                                                                 input_1[0][0]                    \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 256, 256, 64) 38656       concatenate_3[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_6 (BatchNor (None, 256, 256, 64) 256         conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nactivation_6 (Activation)       (None, 256, 256, 64) 0           batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\ndropout_6 (Dropout)             (None, 256, 256, 64) 0           activation_6[0][0]               \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 256, 256, 64) 36928       dropout_6[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_7 (BatchNor (None, 256, 256, 64) 256         conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nactivation_7 (Activation)       (None, 256, 256, 64) 0           batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\ndropout_7 (Dropout)             (None, 256, 256, 64) 0           activation_7[0][0]               \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 256, 256, 2)  130         dropout_7[0][0]                  \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 256, 256, 1)  3           conv2d_8[0][0]                   \n==================================================================================================\nTotal params: 23,293,125\nTrainable params: 23,161,349\nNon-trainable params: 131,776\n__________________________________________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "   \n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "\n",
        "#path to images\n",
        "train_path = \"../input/training/training\"\n",
        "image_folder = \"images\"\n",
        "label_folder = \"label\"\n",
        "valid_path =  \"../input/validation/Validation\"\n",
        "valid_image_folder =\"images\"\n",
        "valid_label_folder = \"label\"\n",
        "log_filepath = './log'\n",
        "flag_multi_class = False\n",
        "num_classes = 2\n",
        "dp = data_preprocess(train_path=train_path,image_folder=image_folder,label_folder=label_folder,\n",
        "                     valid_path=valid_path,valid_image_folder=valid_image_folder,valid_label_folder=valid_label_folder,\n",
        "                     flag_multi_class=flag_multi_class,\n",
        "                     num_classes=num_classes)\n",
        "\n",
        "train_data = dp.trainGenerator(batch_size=2)\n",
        "valid_data = dp.validLoad(batch_size=1)\n",
        "test_data = dp.testGenerator()\n",
        "lrate = 7.00E-05 \n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, Dense, Multiply, AveragePooling2D, UpSampling2D"
      ],
      "metadata": {
        "id": "z73b0ddqjXrl",
        "execution": {
          "iopub.status.busy": "2021-09-16T09:37:08.041293Z",
          "iopub.execute_input": "2021-09-16T09:37:08.041555Z",
          "iopub.status.idle": "2021-09-16T09:37:08.049750Z",
          "shell.execute_reply.started": "2021-09-16T09:37:08.041523Z",
          "shell.execute_reply": "2021-09-16T09:37:08.048823Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(train_data,\n",
        "                              steps_per_epoch=1912,epochs=40,\n",
        "                              validation_steps=207,\n",
        "                              validation_data=valid_data,\n",
        "                              callbacks=[model_checkpoint1,csv_logger])"
      ],
      "metadata": {
        "id": "DJLOnaYejXrm",
        "outputId": "deabad6b-2cf2-449a-8124-ea3bd1e2a072",
        "execution": {
          "iopub.status.busy": "2021-09-16T09:37:08.051161Z",
          "iopub.execute_input": "2021-09-16T09:37:08.051826Z",
          "iopub.status.idle": "2021-09-16T12:08:53.633607Z",
          "shell.execute_reply.started": "2021-09-16T09:37:08.051791Z",
          "shell.execute_reply": "2021-09-16T12:08:53.632630Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Found 600 images belonging to 1 classes.\nFound 600 images belonging to 1 classes.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2021-09-16 09:37:08.790458: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n2021-09-16 09:37:08.794516: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2000185000 Hz\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1/40\n(None, 256, 256, 1)\n(None, 256, 256, 1)\n(None, 256, 256, 1)\n(None, 256, 256, 1)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2021-09-16 09:37:22.870081: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-09-16 09:37:28.010056: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-16 09:37:28.707462: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "1912/1912 [==============================] - ETA: 0s - loss: 287033.6292 - ACL5: 287033.6292 - binary_crossentropy_plus_jaccard_loss: 1.5673 - dice_coef: 0.0283 - dsc: 0.0284 - dice_loss: 0.9716 - iou_coeff: 0.0144 - precision: 0.0172 - recall: 0.0385Found 200 images belonging to 1 classes.\nFound 200 images belonging to 1 classes.\n(None, 256, 256, 1)\n(None, 256, 256, 1)\n1912/1912 [==============================] - 259s 124ms/step - loss: 287007.4841 - ACL5: 287007.4841 - binary_crossentropy_plus_jaccard_loss: 1.5672 - dice_coef: 0.0283 - dsc: 0.0284 - dice_loss: 0.9716 - iou_coeff: 0.0144 - precision: 0.0172 - recall: 0.0385 - val_loss: 69509.2578 - val_ACL5: 69509.2578 - val_binary_crossentropy_plus_jaccard_loss: 1.2379 - val_dice_coef: 0.0484 - val_dsc: 0.0484 - val_dice_loss: 0.9516 - val_iou_coeff: 0.0250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n\nEpoch 00001: val_dice_loss improved from inf to 0.95161, saving model to att_r2_unet.hdf5\nEpoch 2/40\n1912/1912 [==============================] - 228s 119ms/step - loss: 114743.8999 - ACL5: 114743.8999 - binary_crossentropy_plus_jaccard_loss: 1.1761 - dice_coef: 0.0665 - dsc: 0.0671 - dice_loss: 0.9329 - iou_coeff: 0.0350 - precision: 0.1030 - recall: 5.8120e-04 - val_loss: 10738.9219 - val_ACL5: 10738.9219 - val_binary_crossentropy_plus_jaccard_loss: 0.9370 - val_dice_coef: 0.1923 - val_dsc: 0.1923 - val_dice_loss: 0.8077 - val_iou_coeff: 0.1088 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n\nEpoch 00002: val_dice_loss improved from 0.95161 to 0.80765, saving model to att_r2_unet.hdf5\nEpoch 3/40\n1912/1912 [==============================] - 227s 119ms/step - loss: 20164.9242 - ACL5: 20164.9242 - binary_crossentropy_plus_jaccard_loss: 0.8878 - dice_coef: 0.2494 - dsc: 0.2581 - dice_loss: 0.7419 - iou_coeff: 0.1500 - precision: 0.8943 - recall: 0.0121 - val_loss: 3462.2585 - val_ACL5: 3462.2585 - val_binary_crossentropy_plus_jaccard_loss: 0.6032 - val_dice_coef: 0.5535 - val_dsc: 0.5535 - val_dice_loss: 0.4465 - val_iou_coeff: 0.4229 - val_precision: 0.6986 - val_recall: 0.6381\n\nEpoch 00003: val_dice_loss improved from 0.80765 to 0.44647, saving model to att_r2_unet.hdf5\nEpoch 4/40\n1912/1912 [==============================] - 226s 118ms/step - loss: 6832.3883 - ACL5: 6832.3883 - binary_crossentropy_plus_jaccard_loss: 0.5040 - dice_coef: 0.6439 - dsc: 0.6781 - dice_loss: 0.3219 - iou_coeff: 0.5211 - precision: 0.8380 - recall: 0.7587 - val_loss: 2450.3025 - val_ACL5: 2450.3025 - val_binary_crossentropy_plus_jaccard_loss: 0.5521 - val_dice_coef: 0.5928 - val_dsc: 0.5928 - val_dice_loss: 0.4072 - val_iou_coeff: 0.4877 - val_precision: 0.7430 - val_recall: 0.5425\n\nEpoch 00004: val_dice_loss improved from 0.44647 to 0.40724, saving model to att_r2_unet.hdf5\nEpoch 5/40\n1912/1912 [==============================] - 226s 118ms/step - loss: 4412.9705 - ACL5: 4412.9705 - binary_crossentropy_plus_jaccard_loss: 0.3967 - dice_coef: 0.7222 - dsc: 0.7659 - dice_loss: 0.2341 - iou_coeff: 0.6321 - precision: 0.8506 - recall: 0.7660 - val_loss: 1826.3107 - val_ACL5: 1826.3107 - val_binary_crossentropy_plus_jaccard_loss: 0.4074 - val_dice_coef: 0.7380 - val_dsc: 0.7380 - val_dice_loss: 0.2620 - val_iou_coeff: 0.6279 - val_precision: 0.8155 - val_recall: 0.6933\n\nEpoch 00005: val_dice_loss improved from 0.40724 to 0.26200, saving model to att_r2_unet.hdf5\nEpoch 6/40\n1912/1912 [==============================] - 226s 118ms/step - loss: 3669.5607 - ACL5: 3669.5607 - binary_crossentropy_plus_jaccard_loss: 0.3493 - dice_coef: 0.7576 - dsc: 0.8037 - dice_loss: 0.1963 - iou_coeff: 0.6823 - precision: 0.8630 - recall: 0.7847 - val_loss: 1762.1924 - val_ACL5: 1762.1924 - val_binary_crossentropy_plus_jaccard_loss: 0.3943 - val_dice_coef: 0.7554 - val_dsc: 0.7554 - val_dice_loss: 0.2446 - val_iou_coeff: 0.6534 - val_precision: 0.7963 - val_recall: 0.7159\n\nEpoch 00006: val_dice_loss improved from 0.26200 to 0.24464, saving model to att_r2_unet.hdf5\nEpoch 7/40\n1912/1912 [==============================] - 226s 118ms/step - loss: 3375.0887 - ACL5: 3375.0887 - binary_crossentropy_plus_jaccard_loss: 0.3317 - dice_coef: 0.7775 - dsc: 0.8193 - dice_loss: 0.1807 - iou_coeff: 0.7028 - precision: 0.8636 - recall: 0.7978 - val_loss: 1753.2214 - val_ACL5: 1753.2214 - val_binary_crossentropy_plus_jaccard_loss: 0.4140 - val_dice_coef: 0.7543 - val_dsc: 0.7543 - val_dice_loss: 0.2457 - val_iou_coeff: 0.6579 - val_precision: 0.7580 - val_recall: 0.7192\n\nEpoch 00007: val_dice_loss did not improve from 0.24464\nEpoch 8/40\n1912/1912 [==============================] - 225s 118ms/step - loss: 3285.0307 - ACL5: 3285.0307 - binary_crossentropy_plus_jaccard_loss: 0.3311 - dice_coef: 0.7858 - dsc: 0.8221 - dice_loss: 0.1779 - iou_coeff: 0.7078 - precision: 0.8633 - recall: 0.7998 - val_loss: 1834.3304 - val_ACL5: 1834.3304 - val_binary_crossentropy_plus_jaccard_loss: 0.4006 - val_dice_coef: 0.7830 - val_dsc: 0.7830 - val_dice_loss: 0.2170 - val_iou_coeff: 0.6819 - val_precision: 0.7922 - val_recall: 0.7360\n\nEpoch 00008: val_dice_loss improved from 0.24464 to 0.21698, saving model to att_r2_unet.hdf5\nEpoch 9/40\n1912/1912 [==============================] - 226s 118ms/step - loss: 3147.6616 - ACL5: 3147.6616 - binary_crossentropy_plus_jaccard_loss: 0.3193 - dice_coef: 0.8068 - dsc: 0.8333 - dice_loss: 0.1667 - iou_coeff: 0.7218 - precision: 0.8711 - recall: 0.8087 - val_loss: 1932.1265 - val_ACL5: 1932.1265 - val_binary_crossentropy_plus_jaccard_loss: 0.4075 - val_dice_coef: 0.7861 - val_dsc: 0.7861 - val_dice_loss: 0.2139 - val_iou_coeff: 0.6809 - val_precision: 0.7514 - val_recall: 0.7834\n\nEpoch 00009: val_dice_loss improved from 0.21698 to 0.21394, saving model to att_r2_unet.hdf5\nEpoch 10/40\n1912/1912 [==============================] - 225s 118ms/step - loss: 3107.3004 - ACL5: 3107.3004 - binary_crossentropy_plus_jaccard_loss: 0.3215 - dice_coef: 0.8212 - dsc: 0.8342 - dice_loss: 0.1658 - iou_coeff: 0.7242 - precision: 0.8734 - recall: 0.8093 - val_loss: 1948.1746 - val_ACL5: 1948.1746 - val_binary_crossentropy_plus_jaccard_loss: 0.4726 - val_dice_coef: 0.7415 - val_dsc: 0.7415 - val_dice_loss: 0.2585 - val_iou_coeff: 0.6484 - val_precision: 0.7457 - val_recall: 0.6649\n\nEpoch 00010: val_dice_loss did not improve from 0.21394\nEpoch 11/40\n1912/1912 [==============================] - 226s 118ms/step - loss: 3105.5019 - ACL5: 3105.5019 - binary_crossentropy_plus_jaccard_loss: 0.3260 - dice_coef: 0.8272 - dsc: 0.8342 - dice_loss: 0.1658 - iou_coeff: 0.7250 - precision: 0.8679 - recall: 0.8095 - val_loss: 1736.3474 - val_ACL5: 1736.3474 - val_binary_crossentropy_plus_jaccard_loss: 0.4124 - val_dice_coef: 0.7872 - val_dsc: 0.7872 - val_dice_loss: 0.2128 - val_iou_coeff: 0.6919 - val_precision: 0.7753 - val_recall: 0.7299\n\nEpoch 00011: val_dice_loss improved from 0.21394 to 0.21282, saving model to att_r2_unet.hdf5\nEpoch 12/40\n1912/1912 [==============================] - 226s 118ms/step - loss: 3050.3645 - ACL5: 3050.3645 - binary_crossentropy_plus_jaccard_loss: 0.3220 - dice_coef: 0.8339 - dsc: 0.8390 - dice_loss: 0.1610 - iou_coeff: 0.7313 - precision: 0.8719 - recall: 0.8148 - val_loss: 1631.2979 - val_ACL5: 1631.2979 - val_binary_crossentropy_plus_jaccard_loss: 0.4297 - val_dice_coef: 0.7847 - val_dsc: 0.7847 - val_dice_loss: 0.2153 - val_iou_coeff: 0.6892 - val_precision: 0.7916 - val_recall: 0.6972\n\nEpoch 00012: val_dice_loss did not improve from 0.21282\nEpoch 13/40\n1912/1912 [==============================] - 225s 118ms/step - loss: 2981.0452 - ACL5: 2981.0452 - binary_crossentropy_plus_jaccard_loss: 0.3146 - dice_coef: 0.8438 - dsc: 0.8460 - dice_loss: 0.1540 - iou_coeff: 0.7388 - precision: 0.8783 - recall: 0.8232 - val_loss: 1842.7527 - val_ACL5: 1842.7527 - val_binary_crossentropy_plus_jaccard_loss: 0.4300 - val_dice_coef: 0.7863 - val_dsc: 0.7863 - val_dice_loss: 0.2137 - val_iou_coeff: 0.6758 - val_precision: 0.8483 - val_recall: 0.7007\n\nEpoch 00013: val_dice_loss did not improve from 0.21282\nEpoch 14/40\n1912/1912 [==============================] - 225s 118ms/step - loss: 2972.1625 - ACL5: 2972.1625 - binary_crossentropy_plus_jaccard_loss: 0.3188 - dice_coef: 0.8440 - dsc: 0.8433 - dice_loss: 0.1567 - iou_coeff: 0.7368 - precision: 0.8745 - recall: 0.8216 - val_loss: 2052.3938 - val_ACL5: 2052.3938 - val_binary_crossentropy_plus_jaccard_loss: 0.4250 - val_dice_coef: 0.7942 - val_dsc: 0.7942 - val_dice_loss: 0.2058 - val_iou_coeff: 0.6887 - val_precision: 0.7456 - val_recall: 0.7959\n\nEpoch 00014: val_dice_loss improved from 0.21282 to 0.20576, saving model to att_r2_unet.hdf5\nEpoch 15/40\n1912/1912 [==============================] - 225s 118ms/step - loss: 2913.4079 - ACL5: 2913.4079 - binary_crossentropy_plus_jaccard_loss: 0.3125 - dice_coef: 0.8486 - dsc: 0.8496 - dice_loss: 0.1504 - iou_coeff: 0.7447 - precision: 0.8808 - recall: 0.8251 - val_loss: 1807.6652 - val_ACL5: 1807.6652 - val_binary_crossentropy_plus_jaccard_loss: 0.4764 - val_dice_coef: 0.7718 - val_dsc: 0.7718 - val_dice_loss: 0.2282 - val_iou_coeff: 0.6740 - val_precision: 0.7858 - val_recall: 0.6667\n\nEpoch 00015: val_dice_loss did not improve from 0.20576\nEpoch 16/40\n1912/1912 [==============================] - 226s 118ms/step - loss: 2991.0968 - ACL5: 2991.0968 - binary_crossentropy_plus_jaccard_loss: 0.3244 - dice_coef: 0.8447 - dsc: 0.8424 - dice_loss: 0.1576 - iou_coeff: 0.7364 - precision: 0.8767 - recall: 0.8184 - val_loss: 1662.2450 - val_ACL5: 1662.2450 - val_binary_crossentropy_plus_jaccard_loss: 0.3886 - val_dice_coef: 0.8129 - val_dsc: 0.8129 - val_dice_loss: 0.1871 - val_iou_coeff: 0.7147 - val_precision: 0.8051 - val_recall: 0.7743\n\nEpoch 00016: val_dice_loss improved from 0.20576 to 0.18708, saving model to att_r2_unet.hdf5\nEpoch 17/40\n1912/1912 [==============================] - 225s 118ms/step - loss: 2818.3648 - ACL5: 2818.3648 - binary_crossentropy_plus_jaccard_loss: 0.3042 - dice_coef: 0.8579 - dsc: 0.8570 - dice_loss: 0.1430 - iou_coeff: 0.7550 - precision: 0.8818 - recall: 0.8341 - val_loss: 1950.1190 - val_ACL5: 1950.1190 - val_binary_crossentropy_plus_jaccard_loss: 0.4519 - val_dice_coef: 0.7802 - val_dsc: 0.7802 - val_dice_loss: 0.2198 - val_iou_coeff: 0.6764 - val_precision: 0.7775 - val_recall: 0.7245\n\nEpoch 00017: val_dice_loss did not improve from 0.18708\nEpoch 18/40\n1912/1912 [==============================] - 225s 118ms/step - loss: 2898.6506 - ACL5: 2898.6506 - binary_crossentropy_plus_jaccard_loss: 0.3128 - dice_coef: 0.8543 - dsc: 0.8527 - dice_loss: 0.1473 - iou_coeff: 0.7482 - precision: 0.8815 - recall: 0.8305 - val_loss: 1597.9158 - val_ACL5: 1597.9158 - val_binary_crossentropy_plus_jaccard_loss: 0.4159 - val_dice_coef: 0.7970 - val_dsc: 0.7970 - val_dice_loss: 0.2030 - val_iou_coeff: 0.6998 - val_precision: 0.7848 - val_recall: 0.7307\n\nEpoch 00018: val_dice_loss did not improve from 0.18708\nEpoch 19/40\n1912/1912 [==============================] - 227s 119ms/step - loss: 2804.6065 - ACL5: 2804.6065 - binary_crossentropy_plus_jaccard_loss: 0.3067 - dice_coef: 0.8563 - dsc: 0.8557 - dice_loss: 0.1443 - iou_coeff: 0.7537 - precision: 0.8819 - recall: 0.8324 - val_loss: 1790.5862 - val_ACL5: 1790.5862 - val_binary_crossentropy_plus_jaccard_loss: 0.4311 - val_dice_coef: 0.7988 - val_dsc: 0.7988 - val_dice_loss: 0.2012 - val_iou_coeff: 0.6955 - val_precision: 0.8084 - val_recall: 0.7229\n\nEpoch 00019: val_dice_loss did not improve from 0.18708\nEpoch 20/40\n1912/1912 [==============================] - 225s 118ms/step - loss: 2759.3637 - ACL5: 2759.3637 - binary_crossentropy_plus_jaccard_loss: 0.3008 - dice_coef: 0.8621 - dsc: 0.8599 - dice_loss: 0.1401 - iou_coeff: 0.7600 - precision: 0.8834 - recall: 0.8382 - val_loss: 1703.0820 - val_ACL5: 1703.0820 - val_binary_crossentropy_plus_jaccard_loss: 0.4196 - val_dice_coef: 0.7983 - val_dsc: 0.7983 - val_dice_loss: 0.2017 - val_iou_coeff: 0.6966 - val_precision: 0.8086 - val_recall: 0.7298\n\nEpoch 00020: val_dice_loss did not improve from 0.18708\nEpoch 21/40\n1912/1912 [==============================] - 224s 117ms/step - loss: 2773.2026 - ACL5: 2773.2026 - binary_crossentropy_plus_jaccard_loss: 0.3033 - dice_coef: 0.8645 - dsc: 0.8585 - dice_loss: 0.1415 - iou_coeff: 0.7585 - precision: 0.8821 - recall: 0.8367 - val_loss: 1688.5963 - val_ACL5: 1688.5963 - val_binary_crossentropy_plus_jaccard_loss: 0.4077 - val_dice_coef: 0.8168 - val_dsc: 0.8168 - val_dice_loss: 0.1832 - val_iou_coeff: 0.7160 - val_precision: 0.8035 - val_recall: 0.7603\n\nEpoch 00021: val_dice_loss improved from 0.18708 to 0.18318, saving model to att_r2_unet.hdf5\nEpoch 22/40\n1912/1912 [==============================] - 225s 118ms/step - loss: 2740.6168 - ACL5: 2740.6168 - binary_crossentropy_plus_jaccard_loss: 0.2961 - dice_coef: 0.8638 - dsc: 0.8633 - dice_loss: 0.1367 - iou_coeff: 0.7645 - precision: 0.8867 - recall: 0.8443 - val_loss: 1720.0050 - val_ACL5: 1720.0050 - val_binary_crossentropy_plus_jaccard_loss: 0.4113 - val_dice_coef: 0.7929 - val_dsc: 0.7929 - val_dice_loss: 0.2071 - val_iou_coeff: 0.6931 - val_precision: 0.7917 - val_recall: 0.7643\n\nEpoch 00022: val_dice_loss did not improve from 0.18318\nEpoch 23/40\n1912/1912 [==============================] - 227s 118ms/step - loss: 2664.7034 - ACL5: 2664.7034 - binary_crossentropy_plus_jaccard_loss: 0.2918 - dice_coef: 0.8696 - dsc: 0.8640 - dice_loss: 0.1360 - iou_coeff: 0.7666 - precision: 0.8888 - recall: 0.8444 - val_loss: 1692.4026 - val_ACL5: 1692.4026 - val_binary_crossentropy_plus_jaccard_loss: 0.4298 - val_dice_coef: 0.7875 - val_dsc: 0.7875 - val_dice_loss: 0.2125 - val_iou_coeff: 0.6921 - val_precision: 0.7882 - val_recall: 0.7204\n\nEpoch 00023: val_dice_loss did not improve from 0.18318\nEpoch 24/40\n1912/1912 [==============================] - 230s 120ms/step - loss: 2707.8540 - ACL5: 2707.8540 - binary_crossentropy_plus_jaccard_loss: 0.2960 - dice_coef: 0.8674 - dsc: 0.8650 - dice_loss: 0.1350 - iou_coeff: 0.7671 - precision: 0.8881 - recall: 0.8439 - val_loss: 1689.8201 - val_ACL5: 1689.8201 - val_binary_crossentropy_plus_jaccard_loss: 0.4201 - val_dice_coef: 0.8019 - val_dsc: 0.8019 - val_dice_loss: 0.1981 - val_iou_coeff: 0.7016 - val_precision: 0.8170 - val_recall: 0.7251\n\nEpoch 00024: val_dice_loss did not improve from 0.18318\nEpoch 25/40\n1912/1912 [==============================] - 229s 120ms/step - loss: 2600.2512 - ACL5: 2600.2512 - binary_crossentropy_plus_jaccard_loss: 0.2857 - dice_coef: 0.8732 - dsc: 0.8688 - dice_loss: 0.1312 - iou_coeff: 0.7731 - precision: 0.8931 - recall: 0.8476 - val_loss: 1614.1884 - val_ACL5: 1614.1884 - val_binary_crossentropy_plus_jaccard_loss: 0.3873 - val_dice_coef: 0.8289 - val_dsc: 0.8289 - val_dice_loss: 0.1711 - val_iou_coeff: 0.7284 - val_precision: 0.8114 - val_recall: 0.7758\n\nEpoch 00025: val_dice_loss improved from 0.18318 to 0.17105, saving model to att_r2_unet.hdf5\nEpoch 26/40\n1912/1912 [==============================] - 226s 118ms/step - loss: 2634.1421 - ACL5: 2634.1421 - binary_crossentropy_plus_jaccard_loss: 0.2877 - dice_coef: 0.8730 - dsc: 0.8699 - dice_loss: 0.1301 - iou_coeff: 0.7737 - precision: 0.8926 - recall: 0.8497 - val_loss: 1641.4829 - val_ACL5: 1641.4829 - val_binary_crossentropy_plus_jaccard_loss: 0.4052 - val_dice_coef: 0.8109 - val_dsc: 0.8109 - val_dice_loss: 0.1891 - val_iou_coeff: 0.7147 - val_precision: 0.7812 - val_recall: 0.7548\n\nEpoch 00026: val_dice_loss did not improve from 0.17105\nEpoch 27/40\n1912/1912 [==============================] - 225s 118ms/step - loss: 2554.9975 - ACL5: 2554.9975 - binary_crossentropy_plus_jaccard_loss: 0.2834 - dice_coef: 0.8755 - dsc: 0.8707 - dice_loss: 0.1293 - iou_coeff: 0.7753 - precision: 0.8964 - recall: 0.8511 - val_loss: 1704.6841 - val_ACL5: 1704.6841 - val_binary_crossentropy_plus_jaccard_loss: 0.4242 - val_dice_coef: 0.8033 - val_dsc: 0.8033 - val_dice_loss: 0.1967 - val_iou_coeff: 0.7060 - val_precision: 0.7914 - val_recall: 0.7328\n\nEpoch 00027: val_dice_loss did not improve from 0.17105\nEpoch 28/40\n1912/1912 [==============================] - 225s 118ms/step - loss: 2553.7941 - ACL5: 2553.7941 - binary_crossentropy_plus_jaccard_loss: 0.2807 - dice_coef: 0.8777 - dsc: 0.8741 - dice_loss: 0.1259 - iou_coeff: 0.7807 - precision: 0.8943 - recall: 0.8518 - val_loss: 1676.9481 - val_ACL5: 1676.9481 - val_binary_crossentropy_plus_jaccard_loss: 0.4096 - val_dice_coef: 0.8035 - val_dsc: 0.8035 - val_dice_loss: 0.1965 - val_iou_coeff: 0.7073 - val_precision: 0.7835 - val_recall: 0.7499\n\nEpoch 00028: val_dice_loss did not improve from 0.17105\nEpoch 29/40\n1912/1912 [==============================] - 226s 118ms/step - loss: 2524.3728 - ACL5: 2524.3728 - binary_crossentropy_plus_jaccard_loss: 0.2740 - dice_coef: 0.8773 - dsc: 0.8761 - dice_loss: 0.1239 - iou_coeff: 0.7832 - precision: 0.8997 - recall: 0.8573 - val_loss: 1855.3245 - val_ACL5: 1855.3245 - val_binary_crossentropy_plus_jaccard_loss: 0.4713 - val_dice_coef: 0.7640 - val_dsc: 0.7640 - val_dice_loss: 0.2360 - val_iou_coeff: 0.6681 - val_precision: 0.7568 - val_recall: 0.6761\n\nEpoch 00029: val_dice_loss did not improve from 0.17105\nEpoch 30/40\n1912/1912 [==============================] - 228s 119ms/step - loss: 2613.2389 - ACL5: 2613.2389 - binary_crossentropy_plus_jaccard_loss: 0.2936 - dice_coef: 0.8656 - dsc: 0.8661 - dice_loss: 0.1339 - iou_coeff: 0.7704 - precision: 0.8931 - recall: 0.8439 - val_loss: 1613.4712 - val_ACL5: 1613.4712 - val_binary_crossentropy_plus_jaccard_loss: 0.4001 - val_dice_coef: 0.8042 - val_dsc: 0.8042 - val_dice_loss: 0.1958 - val_iou_coeff: 0.7087 - val_precision: 0.7897 - val_recall: 0.7561\n\nEpoch 00030: val_dice_loss did not improve from 0.17105\nEpoch 31/40\n1912/1912 [==============================] - 226s 118ms/step - loss: 2549.5960 - ACL5: 2549.5960 - binary_crossentropy_plus_jaccard_loss: 0.2865 - dice_coef: 0.8751 - dsc: 0.8727 - dice_loss: 0.1273 - iou_coeff: 0.7793 - precision: 0.8930 - recall: 0.8496 - val_loss: 1876.7024 - val_ACL5: 1876.7024 - val_binary_crossentropy_plus_jaccard_loss: 0.4657 - val_dice_coef: 0.7562 - val_dsc: 0.7562 - val_dice_loss: 0.2438 - val_iou_coeff: 0.6608 - val_precision: 0.7541 - val_recall: 0.7120\n\nEpoch 00031: val_dice_loss did not improve from 0.17105\nEpoch 32/40\n1912/1912 [==============================] - 225s 118ms/step - loss: 2450.4660 - ACL5: 2450.4660 - binary_crossentropy_plus_jaccard_loss: 0.2704 - dice_coef: 0.8833 - dsc: 0.8800 - dice_loss: 0.1200 - iou_coeff: 0.7895 - precision: 0.9029 - recall: 0.8578 - val_loss: 1981.9165 - val_ACL5: 1981.9165 - val_binary_crossentropy_plus_jaccard_loss: 0.4939 - val_dice_coef: 0.7518 - val_dsc: 0.7518 - val_dice_loss: 0.2482 - val_iou_coeff: 0.6523 - val_precision: 0.7480 - val_recall: 0.6964\n\nEpoch 00032: val_dice_loss did not improve from 0.17105\nEpoch 33/40\n1912/1912 [==============================] - 227s 119ms/step - loss: 2448.7892 - ACL5: 2448.7892 - binary_crossentropy_plus_jaccard_loss: 0.2749 - dice_coef: 0.8819 - dsc: 0.8785 - dice_loss: 0.1215 - iou_coeff: 0.7878 - precision: 0.8998 - recall: 0.8574 - val_loss: 1840.7533 - val_ACL5: 1840.7533 - val_binary_crossentropy_plus_jaccard_loss: 0.4516 - val_dice_coef: 0.7867 - val_dsc: 0.7867 - val_dice_loss: 0.2133 - val_iou_coeff: 0.6770 - val_precision: 0.8135 - val_recall: 0.7323\n\nEpoch 00033: val_dice_loss did not improve from 0.17105\nEpoch 34/40\n1912/1912 [==============================] - 227s 119ms/step - loss: 2505.7787 - ACL5: 2505.7787 - binary_crossentropy_plus_jaccard_loss: 0.2817 - dice_coef: 0.8797 - dsc: 0.8763 - dice_loss: 0.1237 - iou_coeff: 0.7851 - precision: 0.8979 - recall: 0.8523 - val_loss: 1756.8800 - val_ACL5: 1756.8800 - val_binary_crossentropy_plus_jaccard_loss: 0.4334 - val_dice_coef: 0.7826 - val_dsc: 0.7826 - val_dice_loss: 0.2174 - val_iou_coeff: 0.6898 - val_precision: 0.7504 - val_recall: 0.7317\n\nEpoch 00034: val_dice_loss did not improve from 0.17105\nEpoch 35/40\n1912/1912 [==============================] - 227s 119ms/step - loss: 2448.1858 - ACL5: 2448.1858 - binary_crossentropy_plus_jaccard_loss: 0.2714 - dice_coef: 0.8838 - dsc: 0.8799 - dice_loss: 0.1201 - iou_coeff: 0.7907 - precision: 0.9008 - recall: 0.8590 - val_loss: 1814.3787 - val_ACL5: 1814.3787 - val_binary_crossentropy_plus_jaccard_loss: 0.4655 - val_dice_coef: 0.7720 - val_dsc: 0.7720 - val_dice_loss: 0.2280 - val_iou_coeff: 0.6721 - val_precision: 0.7794 - val_recall: 0.7133\n\nEpoch 00035: val_dice_loss did not improve from 0.17105\nEpoch 36/40\n1912/1912 [==============================] - 228s 119ms/step - loss: 2400.7821 - ACL5: 2400.7821 - binary_crossentropy_plus_jaccard_loss: 0.2669 - dice_coef: 0.8877 - dsc: 0.8836 - dice_loss: 0.1164 - iou_coeff: 0.7962 - precision: 0.9023 - recall: 0.8621 - val_loss: 1639.8047 - val_ACL5: 1639.8047 - val_binary_crossentropy_plus_jaccard_loss: 0.4250 - val_dice_coef: 0.7965 - val_dsc: 0.7965 - val_dice_loss: 0.2035 - val_iou_coeff: 0.6985 - val_precision: 0.8007 - val_recall: 0.7237\n\nEpoch 00036: val_dice_loss did not improve from 0.17105\nEpoch 37/40\n1912/1912 [==============================] - 227s 119ms/step - loss: 2344.7638 - ACL5: 2344.7638 - binary_crossentropy_plus_jaccard_loss: 0.2604 - dice_coef: 0.8907 - dsc: 0.8869 - dice_loss: 0.1131 - iou_coeff: 0.8003 - precision: 0.9035 - recall: 0.8672 - val_loss: 1877.9464 - val_ACL5: 1877.9464 - val_binary_crossentropy_plus_jaccard_loss: 0.4657 - val_dice_coef: 0.7623 - val_dsc: 0.7623 - val_dice_loss: 0.2377 - val_iou_coeff: 0.6696 - val_precision: 0.7427 - val_recall: 0.7019\n\nEpoch 00037: val_dice_loss did not improve from 0.17105\nEpoch 38/40\n1912/1912 [==============================] - 227s 119ms/step - loss: 2418.4536 - ACL5: 2418.4536 - binary_crossentropy_plus_jaccard_loss: 0.2670 - dice_coef: 0.8845 - dsc: 0.8822 - dice_loss: 0.1178 - iou_coeff: 0.7948 - precision: 0.9026 - recall: 0.8619 - val_loss: 1735.5798 - val_ACL5: 1735.5798 - val_binary_crossentropy_plus_jaccard_loss: 0.4376 - val_dice_coef: 0.7907 - val_dsc: 0.7907 - val_dice_loss: 0.2093 - val_iou_coeff: 0.6945 - val_precision: 0.7634 - val_recall: 0.7277\n\nEpoch 00038: val_dice_loss did not improve from 0.17105\nEpoch 39/40\n1912/1912 [==============================] - 228s 119ms/step - loss: 2363.2732 - ACL5: 2363.2732 - binary_crossentropy_plus_jaccard_loss: 0.2656 - dice_coef: 0.8869 - dsc: 0.8833 - dice_loss: 0.1167 - iou_coeff: 0.7969 - precision: 0.9031 - recall: 0.8623 - val_loss: 1787.5356 - val_ACL5: 1787.5356 - val_binary_crossentropy_plus_jaccard_loss: 0.4560 - val_dice_coef: 0.7747 - val_dsc: 0.7747 - val_dice_loss: 0.2253 - val_iou_coeff: 0.6803 - val_precision: 0.7495 - val_recall: 0.7023\n\nEpoch 00039: val_dice_loss did not improve from 0.17105\nEpoch 40/40\n1912/1912 [==============================] - 227s 119ms/step - loss: 2334.3657 - ACL5: 2334.3657 - binary_crossentropy_plus_jaccard_loss: 0.2591 - dice_coef: 0.8921 - dsc: 0.8888 - dice_loss: 0.1112 - iou_coeff: 0.8039 - precision: 0.9069 - recall: 0.8672 - val_loss: 1883.4247 - val_ACL5: 1883.4247 - val_binary_crossentropy_plus_jaccard_loss: 0.4686 - val_dice_coef: 0.7747 - val_dsc: 0.7747 - val_dice_loss: 0.2253 - val_iou_coeff: 0.6743 - val_precision: 0.7804 - val_recall: 0.6948\n\nEpoch 00040: val_dice_loss did not improve from 0.17105\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}