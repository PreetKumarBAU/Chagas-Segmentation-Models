{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Attention-Residual2Unet_BCE_Jaccard.ipynb",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras==2.4.3"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "id": "PNfpi6Q0jXrM",
        "execution": {
          "iopub.status.busy": "2021-09-15T15:07:20.774736Z",
          "iopub.execute_input": "2021-09-15T15:07:20.775112Z",
          "iopub.status.idle": "2021-09-15T15:07:29.092830Z",
          "shell.execute_reply.started": "2021-09-15T15:07:20.775073Z",
          "shell.execute_reply": "2021-09-15T15:07:29.091772Z"
        },
        "trusted": true,
        "outputId": "e0696dd8-c9da-4fcc-d12e-42b28b679581"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: keras==2.4.3 in /opt/conda/lib/python3.7/site-packages (2.4.3)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras==2.4.3) (1.19.5)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras==2.4.3) (1.7.1)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras==2.4.3) (5.4.1)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras==2.4.3) (2.10.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras==2.4.3) (1.15.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.4.1\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-15T15:07:29.095509Z",
          "iopub.execute_input": "2021-09-15T15:07:29.096061Z",
          "iopub.status.idle": "2021-09-15T15:07:37.733572Z",
          "shell.execute_reply.started": "2021-09-15T15:07:29.095998Z",
          "shell.execute_reply": "2021-09-15T15:07:37.732348Z"
        },
        "trusted": true,
        "id": "MgRVMUj-RX0t",
        "outputId": "96b27bef-2a5c-49ee-cb80-4323aa5e4660"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: tensorflow==2.4.1 in /opt/conda/lib/python3.7/site-packages (2.4.1)\nRequirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.37.0)\nRequirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (3.7.4.3)\nRequirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.1.2)\nRequirement already satisfied: grpcio~=1.32.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.32.0)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (3.17.3)\nRequirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.1.0)\nRequirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.2.0)\nRequirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.12.1)\nRequirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (2.4.0)\nRequirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.3.3)\nRequirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (3.3.0)\nRequirement already satisfied: h5py~=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (2.10.0)\nRequirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.12)\nRequirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.12.0)\nRequirement already satisfied: six~=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.15.0)\nRequirement already satisfied: tensorboard~=2.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (2.6.0)\nRequirement already satisfied: numpy~=1.19.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.19.5)\nRequirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.6.3)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (57.4.0)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.25.1)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.34.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.4)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.5)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.0.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.7.2)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.7)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.4.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.26.6)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2021.5.30)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (4.0.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.5.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Reshape, Permute, Activation, Input, \\\n",
        "    add, multiply\n",
        "from keras.layers import concatenate, core, Dropout\n",
        "from keras.models import Model\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.core import Lambda\n",
        "#import keras.backend as K\n",
        "\n",
        "#%tensorflow_version 1.x\n",
        "import os\n",
        "import keras\n",
        "from keras.callbacks import TensorBoard\n",
        "import tensorflow as tf\n",
        "#import keras.backend.tensorflow_backend as K\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import CSVLogger"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-15T15:07:37.735414Z",
          "iopub.execute_input": "2021-09-15T15:07:37.735692Z",
          "iopub.status.idle": "2021-09-15T15:07:37.750746Z",
          "shell.execute_reply.started": "2021-09-15T15:07:37.735649Z",
          "shell.execute_reply": "2021-09-15T15:07:37.749776Z"
        },
        "trusted": true,
        "id": "a9beUET_RX0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2"
      ],
      "metadata": {
        "id": "2a8AfzPOjXrQ",
        "execution": {
          "iopub.status.busy": "2021-09-15T15:07:37.754339Z",
          "iopub.execute_input": "2021-09-15T15:07:37.755145Z",
          "iopub.status.idle": "2021-09-15T15:07:37.764467Z",
          "shell.execute_reply.started": "2021-09-15T15:07:37.755089Z",
          "shell.execute_reply": "2021-09-15T15:07:37.763390Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "import numpy as np\n",
        "import os\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import cv2\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "BackGround = [255, 255, 255]\n",
        "road = [0, 0, 0]\n",
        "# COLOR_DICT = np.array([BackGround, road])\n",
        "one = [128, 128, 128]\n",
        "two = [128, 0, 0]\n",
        "three = [192, 192, 128]\n",
        "four = [255, 69, 0]\n",
        "five = [128, 64, 128]\n",
        "six = [60, 40, 222]\n",
        "seven = [128, 128, 0]\n",
        "eight = [192, 128, 128]\n",
        "nine = [64, 64, 128]\n",
        "ten = [64, 0, 128]\n",
        "eleven = [64, 64, 0]\n",
        "twelve = [0, 128, 192]\n",
        "COLOR_DICT = np.array([one, two,three,four,five,six,seven,eight,nine,ten,eleven,twelve])\n",
        "\n",
        "\n",
        "class data_preprocess:\n",
        "    def __init__(self, train_path=None, image_folder=None, label_folder=None,\n",
        "                 valid_path=None,valid_image_folder =None,valid_label_folder = None,\n",
        "                 test_path=None, save_path=None,\n",
        "                 img_rows=256, img_cols=256,\n",
        "                 flag_multi_class=False,\n",
        "                 num_classes = 2):\n",
        "        self.img_rows = img_rows\n",
        "        self.img_cols = img_cols\n",
        "        self.train_path = train_path\n",
        "        self.image_folder = image_folder\n",
        "        self.label_folder = label_folder\n",
        "        self.valid_path = valid_path\n",
        "        self.valid_image_folder = valid_image_folder\n",
        "        self.valid_label_folder = valid_label_folder\n",
        "        self.test_path = test_path\n",
        "        self.save_path = save_path\n",
        "        self.data_gen_args = dict(rotation_range=20,\n",
        "                                  width_shift_range=0.002,\n",
        "                                  shear_range=0.03,\n",
        "                                  zoom_range=0.005,\n",
        "                                  vertical_flip=True,\n",
        "                                  horizontal_flip=True,\n",
        "                                  fill_mode='nearest')\n",
        "        self.image_color_mode = \"rgb\"\n",
        "        self.label_color_mode = \"grayscale\"\n",
        "\n",
        "        self.flag_multi_class = flag_multi_class\n",
        "        self.num_class = num_classes\n",
        "        self.target_size = (256, 256)\n",
        "        self.img_type = 'png'\n",
        "\n",
        "    def adjustData(self, img, label):\n",
        "        if (self.flag_multi_class):\n",
        "            img = img / 255.\n",
        "            label = label[:, :, :, 0] if (len(label.shape) == 4) else label[:, :, 0]\n",
        "            new_label = np.zeros(label.shape + (self.num_class,))\n",
        "            for i in range(self.num_class):\n",
        "                new_label[label == i, i] = 1\n",
        "            label = new_label\n",
        "        elif (np.max(img) > 1):\n",
        "            #img = img / 255.\n",
        "            #label = label / 255.\n",
        "            #label[label >= 0.5] = 1\n",
        "            #label[label < 0.5] = 0\n",
        "            img2 =np.asarray(img)\n",
        "            label2 =np.asarray(label)\n",
        "            img2 =img2.astype('float32')\n",
        "            label2 =label2.astype('float32')\n",
        "            img2 /= 255.0\n",
        "            label2 /= 255.0\n",
        "            label2[label2 >= 0.5] = 1\n",
        "            label2[label2 < 0.5] = 0\n",
        "        return (img2, label2)\n",
        "\n",
        "    def trainGenerator(self, batch_size, image_save_prefix=\"image\", label_save_prefix=\"label\",\n",
        "                       save_to_dir=None, seed=7):\n",
        "        '''\n",
        "        can generate image and label at the same time\n",
        "        use the same seed for image_datagen and label_datagen to ensure the transformation for image and label is the same\n",
        "        if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
        "        '''\n",
        "        image_datagen = ImageDataGenerator(**self.data_gen_args)\n",
        "        label_datagen = ImageDataGenerator(**self.data_gen_args)\n",
        "        image_generator = image_datagen.flow_from_directory(\n",
        "            self.train_path,\n",
        "            classes=[self.image_folder],\n",
        "            class_mode=None,\n",
        "            color_mode=self.image_color_mode,\n",
        "            target_size=self.target_size,\n",
        "            batch_size=batch_size,\n",
        "            save_to_dir=save_to_dir,\n",
        "            save_prefix=image_save_prefix,\n",
        "            seed=seed)\n",
        "        label_generator = label_datagen.flow_from_directory(\n",
        "            self.train_path,\n",
        "            classes=[self.label_folder],\n",
        "            class_mode=None,\n",
        "            color_mode=self.label_color_mode,\n",
        "            target_size=self.target_size,\n",
        "            batch_size=batch_size,\n",
        "            save_to_dir=save_to_dir,\n",
        "            save_prefix=label_save_prefix,\n",
        "            seed=seed)\n",
        "        train_generator = zip(image_generator, label_generator)\n",
        "        for (img, label) in train_generator:\n",
        "            img, label = self.adjustData(img, label)\n",
        "            yield (img, label)\n",
        "\n",
        "    def testGenerator(self):\n",
        "        filenames = os.listdir(self.test_path)\n",
        "        for filename in filenames:\n",
        "            img = io.imread(os.path.join(self.test_path, filename), as_gray=False)\n",
        "            img = img / 255.\n",
        "            img = trans.resize(img, self.target_size, mode='constant')\n",
        "            img = np.reshape(img, img.shape + (1,)) if (not self.flag_multi_class) else img\n",
        "            img = np.reshape(img, (1,) + img.shape)\n",
        "            yield img\n",
        "\n",
        "    def validLoad(self, batch_size,seed=7):\n",
        "        image_datagen = ImageDataGenerator(rescale=0)\n",
        "        label_datagen = ImageDataGenerator(rescale=0)\n",
        "        image_generator = image_datagen.flow_from_directory(\n",
        "            self.valid_path,\n",
        "            classes=[self.valid_image_folder],\n",
        "            class_mode=None,\n",
        "            color_mode=self.image_color_mode,\n",
        "            target_size=self.target_size,\n",
        "            batch_size=batch_size,\n",
        "            seed=seed)\n",
        "        label_generator = label_datagen.flow_from_directory(\n",
        "            self.valid_path,\n",
        "            classes=[self.valid_label_folder],\n",
        "            class_mode=None,\n",
        "            color_mode=self.label_color_mode,\n",
        "            target_size=self.target_size,\n",
        "            batch_size=batch_size,\n",
        "            seed=seed)\n",
        "        train_generator = zip(image_generator, label_generator)\n",
        "        for (img, label) in train_generator:\n",
        "            img, label = self.adjustData(img, label)\n",
        "            yield (img, label)\n",
        "        # return imgs,labels\n",
        "\n",
        "    def saveResult(self, npyfile, size, name,threshold=80):\n",
        "        for i, item in enumerate(npyfile):\n",
        "            img = item\n",
        "            img_std = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
        "            if self.flag_multi_class:\n",
        "                for row in range(len(img)):\n",
        "                    for col in range(len(img[row])):\n",
        "                        num = np.argmax(img[row][col])\n",
        "                        img_std[row][col] = COLOR_DICT[num]\n",
        "            else:\n",
        "                for k in range(len(img)):\n",
        "                    for j in range(len(img[k])):\n",
        "                        num = img[k][j]\n",
        "                        if num < (threshold/255.0):\n",
        "                            img_std[k][j] = road\n",
        "                        else:\n",
        "                            img_std[k][j] = BackGround\n",
        "            img_std = cv2.resize(img_std, size, interpolation=cv2.INTER_CUBIC)\n",
        "            cv2.imwrite(os.path.join(self.save_path, (\"%s_predict.\" + self.img_type) % (name)), img_std)"
      ],
      "metadata": {
        "id": "iTf8lIwLjXrS",
        "execution": {
          "iopub.status.busy": "2021-09-15T15:07:37.766666Z",
          "iopub.execute_input": "2021-09-15T15:07:37.767120Z",
          "iopub.status.idle": "2021-09-15T15:07:37.814173Z",
          "shell.execute_reply.started": "2021-09-15T15:07:37.767050Z",
          "shell.execute_reply": "2021-09-15T15:07:37.812871Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####  Metrics\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.losses import binary_crossentropy\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "def dice_coeff(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return score\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dice_coeff(y_true, y_pred)\n",
        "    return loss\n",
        "def iou_coeff(y_true, y_pred):\n",
        "    smooth=1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    union=K.sum(y_true_f) + K.sum(y_pred_f)-intersection\n",
        "    mvalue=(intersection+smooth)/(union+smooth)\n",
        "    return mvalue\n",
        "def precision(y_true, y_pred):\n",
        "    \"\"\"Precision metric.\n",
        "\n",
        "    Only computes a batch-wise average of precision.\n",
        "\n",
        "    Computes the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "def ACL5(y_true, y_pred): \n",
        "\n",
        "\t#y_pred = K.cast(y_pred, dtype = 'float64')\n",
        "\n",
        "\tprint(K.int_shape(y_pred))\n",
        "\n",
        "\tx = y_pred[:,1:,:,:] - y_pred[:,:-1,:,:] # horizontal and vertical directions \n",
        "\ty = y_pred[:,:,1:,:] - y_pred[:,:,:-1,:]\n",
        "\n",
        "\tdelta_x = x[:,1:,:-2,:]**2\n",
        "\tdelta_y = y[:,:-2,1:,:]**2\n",
        "\tdelta_u = K.abs(delta_x + delta_y) \n",
        "\n",
        "\tepsilon = 0.00000001 # where is a parameter to avoid square root is zero in practice.\n",
        "\tw = 1####\n",
        "\tlenth = w * K.sum(K.sqrt(delta_u + epsilon)) # equ.(11) in the paper\n",
        "\n",
        "\n",
        "\tC_1 = np.ones((256, 256))\n",
        "\tC_2 = np.zeros((256, 256))\n",
        "\n",
        "\tregion_in = K.abs(K.sum( y_pred[:,:,:,0] * ((y_true[:,:,:,0] - C_1)**2) ) ) # equ.(12) in the paper\n",
        "\tregion_out = K.abs(K.sum( (1-y_pred[:,:,:,0]) * ((y_true[:,:,:,0] - C_2)**2) )) # equ.(12) in the paper\n",
        "\n",
        "\tlambdaP = 5 # lambda parameter could be various.\n",
        "\t\n",
        "\tloss =  lenth + lambdaP * ((region_in) + (region_out)) \n",
        "\n",
        "\treturn loss\n",
        "def ACL5_mod(y_true, y_pred): \n",
        "\n",
        "\t#y_pred = K.cast(y_pred, dtype = 'float64')\n",
        "\n",
        "\tprint(K.int_shape(y_pred))\n",
        "\n",
        "\tx = y_pred[:,1:,:,:] - y_pred[:,:-1,:,:] # horizontal and vertical directions \n",
        "\ty = y_pred[:,:,1:,:] - y_pred[:,:,:-1,:]\n",
        "\n",
        "\tdelta_x = x[:,1:,:-2,:]**2\n",
        "\tdelta_y = y[:,:-2,1:,:]**2\n",
        "\tdelta_u = K.abs(delta_x + delta_y) \n",
        "\n",
        "\tepsilon = 0.00000001 # where is a parameter to avoid square root is zero in practice.\n",
        "\tw = 1####\n",
        "\tlenth = w * K.sum(K.sqrt(delta_u + epsilon)) # equ.(11) in the paper\n",
        "\n",
        "\n",
        "\tC_1 = np.ones((256, 256))\n",
        "\tC_2 = np.zeros((256, 256))\n",
        "\n",
        "\tregion_in = K.abs(K.sum( y_pred[:,:,:,0] * ((y_true[:,:,:,0] - C_1)**2) ) ) # equ.(12) in the paper\n",
        "\tregion_out = K.abs(K.sum( (1-y_pred[:,:,:,0]) * ((y_true[:,:,:,0] - C_2)**2) )) # equ.(12) in the paper\n",
        "\n",
        "\tlambdaP = 5 # lambda parameter could be various.\n",
        "\t\n",
        "\tloss =  lenth + lambdaP * ((region_in) + (region_out*1.4)) \n",
        "\n",
        "\treturn loss"
      ],
      "metadata": {
        "id": "VVdzJaSWjXra",
        "execution": {
          "iopub.status.busy": "2021-09-15T15:07:37.815941Z",
          "iopub.execute_input": "2021-09-15T15:07:37.819539Z",
          "iopub.status.idle": "2021-09-15T15:07:37.852156Z",
          "shell.execute_reply.started": "2021-09-15T15:07:37.819499Z",
          "shell.execute_reply": "2021-09-15T15:07:37.850930Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iwu9rjDFjXrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta = 0.25\n",
        "alpha = 0.25\n",
        "gamma = 2\n",
        "epsilon = 1e-5\n",
        "smooth = 1\n",
        "\n",
        "def tversky_index( y_true, y_pred):\n",
        "    y_true_pos = K.flatten(y_true)\n",
        "    y_pred_pos = K.flatten(y_pred)\n",
        "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
        "    false_neg = K.sum(y_true_pos * (1 - y_pred_pos))\n",
        "    false_pos = K.sum((1 - y_true_pos) * y_pred_pos)\n",
        "    alpha = 0.7\n",
        "    return (true_pos + smooth) / (true_pos + alpha * false_neg + (\n",
        "                1 - alpha) * false_pos + smooth)\n",
        "\n",
        "def tversky_loss( y_true, y_pred):\n",
        "    return 1 - tversky_index(y_true, y_pred)\n",
        "\n",
        "def focal_tversky( y_true, y_pred):\n",
        "    pt_1 = tversky_index(y_true, y_pred)\n",
        "    gamma = 0.75\n",
        "    return K.pow((1 - pt_1), gamma)\n",
        "\n",
        "def dsc(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return score\n",
        "\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "  intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
        "  union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
        "  dice = K.mean((2. * intersection + smooth)/(union + smooth), axis=0)\n",
        "  return dice\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dsc(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "-YuW43lejXrd",
        "execution": {
          "iopub.status.busy": "2021-09-15T15:07:37.853421Z",
          "iopub.execute_input": "2021-09-15T15:07:37.854659Z",
          "iopub.status.idle": "2021-09-15T15:07:37.874472Z",
          "shell.execute_reply.started": "2021-09-15T15:07:37.854627Z",
          "shell.execute_reply": "2021-09-15T15:07:37.873216Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env SM_FRAMEWORK=tf.keras"
      ],
      "metadata": {
        "id": "kr5nP8ItjXre",
        "outputId": "48e77d7c-c144-4f17-e726-e4b36dce7171",
        "execution": {
          "iopub.status.busy": "2021-09-15T15:07:37.877437Z",
          "iopub.execute_input": "2021-09-15T15:07:37.878124Z",
          "iopub.status.idle": "2021-09-15T15:07:37.892515Z",
          "shell.execute_reply.started": "2021-09-15T15:07:37.878082Z",
          "shell.execute_reply": "2021-09-15T15:07:37.889829Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "env: SM_FRAMEWORK=tf.keras\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation_models\n",
        "import segmentation_models\n",
        "from segmentation_models.losses import bce_jaccard_loss"
      ],
      "metadata": {
        "id": "KMTFbTKtjXrf",
        "outputId": "2bd1e0fe-2f4f-479d-e8e6-b255673c5ad3",
        "execution": {
          "iopub.status.busy": "2021-09-15T15:07:37.894839Z",
          "iopub.execute_input": "2021-09-15T15:07:37.895773Z",
          "iopub.status.idle": "2021-09-15T15:07:47.223002Z",
          "shell.execute_reply.started": "2021-09-15T15:07:37.895729Z",
          "shell.execute_reply": "2021-09-15T15:07:47.221668Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: segmentation_models in /opt/conda/lib/python3.7/site-packages (1.0.1)\nRequirement already satisfied: image-classifiers==1.0.0 in /opt/conda/lib/python3.7/site-packages (from segmentation_models) (1.0.0)\nRequirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.7/site-packages (from segmentation_models) (1.0.8)\nRequirement already satisfied: efficientnet==1.0.0 in /opt/conda/lib/python3.7/site-packages (from segmentation_models) (1.0.0)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.0.0->segmentation_models) (0.18.3)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.19.5)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (2.10.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.15.0)\nRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.4.3)\nRequirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (8.3.1)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.1.1)\nRequirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.7.1)\nRequirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.9.0)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2021.8.30)\nRequirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.5)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.7)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.3.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.8.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (0.10.0)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation_models) (5.0.9)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ACL5_bce_jaccard_loss(y_true, y_pred):\n",
        "    loss = ACL5(y_true, y_pred) + bce_jaccard_loss(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def focal_tversky_bce_jaccard_loss(y_true, y_pred):\n",
        "    loss = focal_tversky(y_true, y_pred) + 2*bce_jaccard_loss(y_true, y_pred)\n",
        "    return loss\n",
        "\n"
      ],
      "metadata": {
        "id": "IVcpwi4hjXrg",
        "execution": {
          "iopub.status.busy": "2021-09-15T15:07:47.230570Z",
          "iopub.execute_input": "2021-09-15T15:07:47.230908Z",
          "iopub.status.idle": "2021-09-15T15:07:47.241315Z",
          "shell.execute_reply.started": "2021-09-15T15:07:47.230871Z",
          "shell.execute_reply": "2021-09-15T15:07:47.239701Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "from tensorflow.keras.layers import Conv2D , BatchNormalization , Activation , MaxPool2D , Input , Dropout , ZeroPadding2D , Conv2DTranspose , Concatenate\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras.applications import InceptionResNetV2"
      ],
      "metadata": {
        "id": "eDJ9CtzQjXrh",
        "execution": {
          "iopub.status.busy": "2021-09-15T15:07:47.242936Z",
          "iopub.execute_input": "2021-09-15T15:07:47.243588Z",
          "iopub.status.idle": "2021-09-15T15:07:47.252355Z",
          "shell.execute_reply.started": "2021-09-15T15:07:47.243555Z",
          "shell.execute_reply": "2021-09-15T15:07:47.251170Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention_Residual2Unet"
      ],
      "metadata": {
        "id": "ccYNxPZwjXri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kFchkooujXrk",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "   \n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "\n",
        "#path to images\n",
        "train_path = \"../input/training/training\"\n",
        "image_folder = \"images\"\n",
        "label_folder = \"label\"\n",
        "valid_path =  \"../input/validation/Validation\"\n",
        "valid_image_folder =\"images\"\n",
        "valid_label_folder = \"label\"\n",
        "log_filepath = './log'\n",
        "flag_multi_class = False\n",
        "num_classes = 2\n",
        "dp = data_preprocess(train_path=train_path,image_folder=image_folder,label_folder=label_folder,\n",
        "                     valid_path=valid_path,valid_image_folder=valid_image_folder,valid_label_folder=valid_label_folder,\n",
        "                     flag_multi_class=flag_multi_class,\n",
        "                     num_classes=num_classes)\n",
        "\n",
        "train_data = dp.trainGenerator(batch_size=2)\n",
        "valid_data = dp.validLoad(batch_size=1)\n",
        "test_data = dp.testGenerator()\n",
        "lrate = 7.00E-05 \n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, Dense, Multiply, AveragePooling2D, UpSampling2D\n",
        "\n"
      ],
      "metadata": {
        "id": "z73b0ddqjXrl",
        "execution": {
          "iopub.status.busy": "2021-09-15T15:07:47.253996Z",
          "iopub.execute_input": "2021-09-15T15:07:47.255079Z",
          "iopub.status.idle": "2021-09-15T15:07:47.272088Z",
          "shell.execute_reply.started": "2021-09-15T15:07:47.255038Z",
          "shell.execute_reply": "2021-09-15T15:07:47.270964Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Reshape, Permute, Activation, Input, \\\n",
        "    add, multiply\n",
        "from keras.layers import concatenate, core, Dropout\n",
        "from keras.models import Model\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.core import Lambda\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def up_and_concate(down_layer, layer, data_format='channels_first'):\n",
        "    if data_format == 'channels_first':\n",
        "        in_channel = down_layer.get_shape().as_list()[1]\n",
        "    else:\n",
        "        in_channel = down_layer.get_shape().as_list()[3]\n",
        "\n",
        "    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n",
        "    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n",
        "\n",
        "    if data_format == 'channels_first':\n",
        "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n",
        "    else:\n",
        "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
        "\n",
        "    concate = my_concat([up, layer])\n",
        "\n",
        "    return concate\n",
        "\n",
        "\n",
        "def attention_up_and_concate(down_layer, layer, data_format='channels_first'):\n",
        "    if data_format == 'channels_first':\n",
        "        in_channel = down_layer.get_shape().as_list()[1]\n",
        "    else:\n",
        "        in_channel = down_layer.get_shape().as_list()[3]\n",
        "\n",
        "    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n",
        "    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n",
        "\n",
        "    layer = attention_block_2d(x=layer, g=up, inter_channel=in_channel // 4, data_format=data_format)\n",
        "\n",
        "    if data_format == 'channels_first':\n",
        "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n",
        "    else:\n",
        "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
        "\n",
        "    concate = my_concat([up, layer])\n",
        "    return concate\n",
        "\n",
        "\n",
        "def attention_block_2d(x, g, inter_channel, data_format='channels_first'):\n",
        "    # theta_x(?,g_height,g_width,inter_channel)\n",
        "\n",
        "    theta_x = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(x)\n",
        "\n",
        "    # phi_g(?,g_height,g_width,inter_channel)\n",
        "\n",
        "    phi_g = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(g)\n",
        "\n",
        "    # f(?,g_height,g_width,inter_channel)\n",
        "\n",
        "    f = Activation('relu')(add([theta_x, phi_g]))\n",
        "\n",
        "    # psi_f(?,g_height,g_width,1)\n",
        "\n",
        "    psi_f = Conv2D(1, [1, 1], strides=[1, 1], data_format=data_format)(f)\n",
        "\n",
        "    rate = Activation('sigmoid')(psi_f)\n",
        "\n",
        "    # rate(?,x_height,x_width)\n",
        "\n",
        "    # att_x(?,x_height,x_width,x_channel)\n",
        "\n",
        "    att_x = multiply([x, rate])\n",
        "\n",
        "    return att_x\n",
        "\n",
        "\n",
        "def res_block(input_layer, out_n_filters, batch_normalization=False, kernel_size=[3, 3], stride=[1, 1],\n",
        "\n",
        "              padding='same', data_format='channels_first'):\n",
        "    if data_format == 'channels_first':\n",
        "        input_n_filters = input_layer.get_shape().as_list()[1]\n",
        "    else:\n",
        "        input_n_filters = input_layer.get_shape().as_list()[3]\n",
        "\n",
        "    layer = input_layer\n",
        "    for i in range(2):\n",
        "        layer = Conv2D(out_n_filters // 4, [1, 1], strides=stride, padding=padding, data_format=data_format)(layer)\n",
        "        if batch_normalization:\n",
        "            layer = BatchNormalization()(layer)\n",
        "        layer = Activation('relu')(layer)\n",
        "        layer = Conv2D(out_n_filters // 4, kernel_size, strides=stride, padding=padding, data_format=data_format)(layer)\n",
        "        layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(layer)\n",
        "\n",
        "    if out_n_filters != input_n_filters:\n",
        "        skip_layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(\n",
        "            input_layer)\n",
        "    else:\n",
        "        skip_layer = input_layer\n",
        "    out_layer = add([layer, skip_layer])\n",
        "    return out_layer\n",
        "\n",
        "\n",
        "# Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net)\n",
        "def rec_res_block(input_layer, out_n_filters, batch_normalization=False, kernel_size=[3, 3], stride=[1, 1],\n",
        "\n",
        "                  padding='same', data_format='channels_first'):\n",
        "    if data_format == 'channels_first':\n",
        "        input_n_filters = input_layer.get_shape().as_list()[1]\n",
        "    else:\n",
        "        input_n_filters = input_layer.get_shape().as_list()[3]\n",
        "\n",
        "    if out_n_filters != input_n_filters:\n",
        "        skip_layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(\n",
        "            input_layer)\n",
        "    else:\n",
        "        skip_layer = input_layer\n",
        "\n",
        "    layer = skip_layer\n",
        "    for j in range(2):\n",
        "\n",
        "        for i in range(2):\n",
        "            if i == 0:\n",
        "\n",
        "                layer1 = Conv2D(out_n_filters, kernel_size, strides=stride, padding=padding, data_format=data_format)(\n",
        "                    layer)\n",
        "                if batch_normalization:\n",
        "                    layer1 = BatchNormalization()(layer1)\n",
        "                layer1 = Activation('relu')(layer1)\n",
        "            layer1 = Conv2D(out_n_filters, kernel_size, strides=stride, padding=padding, data_format=data_format)(\n",
        "                add([layer1, layer]))\n",
        "            if batch_normalization:\n",
        "                layer1 = BatchNormalization()(layer1)\n",
        "            layer1 = Activation('relu')(layer1)\n",
        "        layer = layer1\n",
        "\n",
        "    out_layer = add([layer, skip_layer])\n",
        "    return out_layer\n",
        "\n",
        "########################################################################################################\n",
        "# Define the neural network\n",
        "def unet(img_w, img_h, n_label, data_format='channels_first'):\n",
        "    inputs = Input((3, img_w, img_h))\n",
        "    x = inputs\n",
        "    depth = 4\n",
        "    features = 64\n",
        "    skips = []\n",
        "    for i in range(depth):\n",
        "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "        skips.append(x)\n",
        "        x = MaxPooling2D((2, 2), data_format= data_format)(x)\n",
        "        features = features * 2\n",
        "\n",
        "    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "\n",
        "    for i in reversed(range(depth)):\n",
        "        features = features // 2\n",
        "        # attention_up_and_concate(x,[skips[i])\n",
        "        x = UpSampling2D(size=(2, 2), data_format=data_format)(x)\n",
        "        x = concatenate([skips[i], x], axis=1)\n",
        "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "\n",
        "    conv6 = Conv2D(n_label, (1, 1), padding='same', data_format=data_format)(x)\n",
        "    conv7 = core.Activation('sigmoid')(conv6)\n",
        "    model = Model(inputs=inputs, outputs=conv7)\n",
        "\n",
        "    #model.compile(optimizer=Adam(lr=1e-5), loss=[focal_loss()], metrics=['accuracy', dice_coef])\n",
        "    return model\n",
        "\n",
        "\n",
        "########################################################################################################\n",
        "#Attention U-Net\n",
        "def att_unet(img_w, img_h, n_label, data_format='channels_first'):\n",
        "    inputs = Input((3, img_w, img_h))\n",
        "    x = inputs\n",
        "    depth = 4\n",
        "    features = 64\n",
        "    skips = []\n",
        "    for i in range(depth):\n",
        "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "        skips.append(x)\n",
        "        x = MaxPooling2D((2, 2), data_format='channels_first')(x)\n",
        "        features = features * 2\n",
        "\n",
        "    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "\n",
        "    for i in reversed(range(depth)):\n",
        "        features = features // 2\n",
        "        x = attention_up_and_concate(x, skips[i], data_format=data_format)\n",
        "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "\n",
        "    conv6 = Conv2D(n_label, (1, 1), padding='same', data_format=data_format)(x)\n",
        "    conv7 = core.Activation('sigmoid')(conv6)\n",
        "    model = Model(inputs=inputs, outputs=conv7)\n",
        "\n",
        "    #model.compile(optimizer=Adam(lr=1e-5), loss=[focal_loss()], metrics=['accuracy', dice_coef])\n",
        "    return model\n",
        "\n",
        "\n",
        "########################################################################################################\n",
        "#Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net)\n",
        "def r2_unet(img_w, img_h, n_label, data_format='channels_first'):\n",
        "    inputs = Input((3, img_w, img_h))\n",
        "    x = inputs\n",
        "    depth = 4\n",
        "    features = 64\n",
        "    skips = []\n",
        "    for i in range(depth):\n",
        "        x = rec_res_block(x, features, data_format=data_format)\n",
        "        skips.append(x)\n",
        "        x = MaxPooling2D((2, 2), data_format=data_format)(x)\n",
        "\n",
        "        features = features * 2\n",
        "\n",
        "    x = rec_res_block(x, features, data_format=data_format)\n",
        "\n",
        "    for i in reversed(range(depth)):\n",
        "        features = features // 2\n",
        "        x = up_and_concate(x, skips[i], data_format=data_format)\n",
        "        x = rec_res_block(x, features, data_format=data_format)\n",
        "\n",
        "    conv6 = Conv2D(n_label, (1, 1), padding='same', data_format=data_format)(x)\n",
        "    conv7 = core.Activation('sigmoid')(conv6)\n",
        "    model = Model(inputs=inputs, outputs=conv7)\n",
        "    #model.compile(optimizer=Adam(lr=1e-6), loss=[dice_coef_loss], metrics=['accuracy', dice_coef])\n",
        "    return model\n",
        "\n",
        "\n",
        "########################################################################################################\n",
        "#Attention R2U-Net\n",
        "def att_r2_unet(img_w, img_h, n_label, data_format='channels_last'):\n",
        "    inputs = Input((img_w, img_h , 3))\n",
        "    x = inputs\n",
        "    depth = 4\n",
        "    features = 64\n",
        "    skips = []\n",
        "    for i in range(depth):\n",
        "        x = rec_res_block(x, features, data_format=data_format)\n",
        "        skips.append(x)\n",
        "        x = MaxPooling2D((2, 2), data_format=data_format)(x)\n",
        "\n",
        "        features = features * 2\n",
        "\n",
        "    x = rec_res_block(x, features, data_format=data_format)\n",
        "\n",
        "    for i in reversed(range(depth)):\n",
        "        features = features // 2\n",
        "        x = attention_up_and_concate(x, skips[i], data_format=data_format)\n",
        "        x = rec_res_block(x, features, data_format=data_format)\n",
        "        \n",
        "    x = Conv2D( 2 , (3, 3), padding='same', data_format=data_format)(x)\n",
        "    conv6 = Conv2D(n_label, (1, 1), padding='same', data_format=data_format)(x)\n",
        "    conv7 = core.Activation('sigmoid')(conv6)\n",
        "    model = Model(inputs=inputs, outputs=conv7)\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_shape = (256, 256, 3)\n",
        "    model = att_r2_unet(256, 256, 1)\n",
        "    model.summary()\n",
        "    model_checkpoint1 = keras.callbacks.ModelCheckpoint('att_r2_unet.hdf5', monitor='val_dice_loss',verbose=1,mode='min',save_best_only=True)\n",
        "    csv_logger = CSVLogger('trainingRes2Net.log', append=True, separator=';')\n",
        "    model.compile(optimizer=Adam(lr=lrate), loss=bce_jaccard_loss , metrics=[ACL5 ,bce_jaccard_loss , dice_coef , dsc,  dice_loss,iou_coeff,precision,recall])\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-15T15:07:47.274533Z",
          "iopub.execute_input": "2021-09-15T15:07:47.275763Z",
          "iopub.status.idle": "2021-09-15T15:07:48.509569Z",
          "shell.execute_reply.started": "2021-09-15T15:07:47.275719Z",
          "shell.execute_reply": "2021-09-15T15:07:48.505573Z"
        },
        "trusted": true,
        "id": "6u0uEOz9RX07",
        "outputId": "5b22baf7-7bdb-48d0-a104-e8387c87055b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_2 (InputLayer)            [(None, 256, 256, 3) 0                                            \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 256, 256, 64) 256         input_2[0][0]                    \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nactivation_9 (Activation)       (None, 256, 256, 64) 0           conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nadd (Add)                       (None, 256, 256, 64) 0           activation_9[0][0]               \n                                                                 conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 256, 256, 64) 36928       add[0][0]                        \n__________________________________________________________________________________________________\nactivation_10 (Activation)      (None, 256, 256, 64) 0           conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 256, 256, 64) 0           activation_10[0][0]              \n                                                                 conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 256, 256, 64) 36928       add_1[0][0]                      \n__________________________________________________________________________________________________\nactivation_11 (Activation)      (None, 256, 256, 64) 0           conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 256, 256, 64) 36928       activation_11[0][0]              \n__________________________________________________________________________________________________\nactivation_12 (Activation)      (None, 256, 256, 64) 0           conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 256, 256, 64) 0           activation_12[0][0]              \n                                                                 activation_11[0][0]              \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 256, 256, 64) 36928       add_2[0][0]                      \n__________________________________________________________________________________________________\nactivation_13 (Activation)      (None, 256, 256, 64) 0           conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nadd_3 (Add)                     (None, 256, 256, 64) 0           activation_13[0][0]              \n                                                                 activation_11[0][0]              \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 256, 256, 64) 36928       add_3[0][0]                      \n__________________________________________________________________________________________________\nactivation_14 (Activation)      (None, 256, 256, 64) 0           conv2d_16[0][0]                  \n__________________________________________________________________________________________________\nadd_4 (Add)                     (None, 256, 256, 64) 0           activation_14[0][0]              \n                                                                 conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling2d (MaxPooling2D)    (None, 128, 128, 64) 0           add_4[0][0]                      \n__________________________________________________________________________________________________\nconv2d_17 (Conv2D)              (None, 128, 128, 128 8320        max_pooling2d[0][0]              \n__________________________________________________________________________________________________\nconv2d_18 (Conv2D)              (None, 128, 128, 128 147584      conv2d_17[0][0]                  \n__________________________________________________________________________________________________\nactivation_15 (Activation)      (None, 128, 128, 128 0           conv2d_18[0][0]                  \n__________________________________________________________________________________________________\nadd_5 (Add)                     (None, 128, 128, 128 0           activation_15[0][0]              \n                                                                 conv2d_17[0][0]                  \n__________________________________________________________________________________________________\nconv2d_19 (Conv2D)              (None, 128, 128, 128 147584      add_5[0][0]                      \n__________________________________________________________________________________________________\nactivation_16 (Activation)      (None, 128, 128, 128 0           conv2d_19[0][0]                  \n__________________________________________________________________________________________________\nadd_6 (Add)                     (None, 128, 128, 128 0           activation_16[0][0]              \n                                                                 conv2d_17[0][0]                  \n__________________________________________________________________________________________________\nconv2d_20 (Conv2D)              (None, 128, 128, 128 147584      add_6[0][0]                      \n__________________________________________________________________________________________________\nactivation_17 (Activation)      (None, 128, 128, 128 0           conv2d_20[0][0]                  \n__________________________________________________________________________________________________\nconv2d_21 (Conv2D)              (None, 128, 128, 128 147584      activation_17[0][0]              \n__________________________________________________________________________________________________\nactivation_18 (Activation)      (None, 128, 128, 128 0           conv2d_21[0][0]                  \n__________________________________________________________________________________________________\nadd_7 (Add)                     (None, 128, 128, 128 0           activation_18[0][0]              \n                                                                 activation_17[0][0]              \n__________________________________________________________________________________________________\nconv2d_22 (Conv2D)              (None, 128, 128, 128 147584      add_7[0][0]                      \n__________________________________________________________________________________________________\nactivation_19 (Activation)      (None, 128, 128, 128 0           conv2d_22[0][0]                  \n__________________________________________________________________________________________________\nadd_8 (Add)                     (None, 128, 128, 128 0           activation_19[0][0]              \n                                                                 activation_17[0][0]              \n__________________________________________________________________________________________________\nconv2d_23 (Conv2D)              (None, 128, 128, 128 147584      add_8[0][0]                      \n__________________________________________________________________________________________________\nactivation_20 (Activation)      (None, 128, 128, 128 0           conv2d_23[0][0]                  \n__________________________________________________________________________________________________\nadd_9 (Add)                     (None, 128, 128, 128 0           activation_20[0][0]              \n                                                                 conv2d_17[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0           add_9[0][0]                      \n__________________________________________________________________________________________________\nconv2d_24 (Conv2D)              (None, 64, 64, 256)  33024       max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nconv2d_25 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_24[0][0]                  \n__________________________________________________________________________________________________\nactivation_21 (Activation)      (None, 64, 64, 256)  0           conv2d_25[0][0]                  \n__________________________________________________________________________________________________\nadd_10 (Add)                    (None, 64, 64, 256)  0           activation_21[0][0]              \n                                                                 conv2d_24[0][0]                  \n__________________________________________________________________________________________________\nconv2d_26 (Conv2D)              (None, 64, 64, 256)  590080      add_10[0][0]                     \n__________________________________________________________________________________________________\nactivation_22 (Activation)      (None, 64, 64, 256)  0           conv2d_26[0][0]                  \n__________________________________________________________________________________________________\nadd_11 (Add)                    (None, 64, 64, 256)  0           activation_22[0][0]              \n                                                                 conv2d_24[0][0]                  \n__________________________________________________________________________________________________\nconv2d_27 (Conv2D)              (None, 64, 64, 256)  590080      add_11[0][0]                     \n__________________________________________________________________________________________________\nactivation_23 (Activation)      (None, 64, 64, 256)  0           conv2d_27[0][0]                  \n__________________________________________________________________________________________________\nconv2d_28 (Conv2D)              (None, 64, 64, 256)  590080      activation_23[0][0]              \n__________________________________________________________________________________________________\nactivation_24 (Activation)      (None, 64, 64, 256)  0           conv2d_28[0][0]                  \n__________________________________________________________________________________________________\nadd_12 (Add)                    (None, 64, 64, 256)  0           activation_24[0][0]              \n                                                                 activation_23[0][0]              \n__________________________________________________________________________________________________\nconv2d_29 (Conv2D)              (None, 64, 64, 256)  590080      add_12[0][0]                     \n__________________________________________________________________________________________________\nactivation_25 (Activation)      (None, 64, 64, 256)  0           conv2d_29[0][0]                  \n__________________________________________________________________________________________________\nadd_13 (Add)                    (None, 64, 64, 256)  0           activation_25[0][0]              \n                                                                 activation_23[0][0]              \n__________________________________________________________________________________________________\nconv2d_30 (Conv2D)              (None, 64, 64, 256)  590080      add_13[0][0]                     \n__________________________________________________________________________________________________\nactivation_26 (Activation)      (None, 64, 64, 256)  0           conv2d_30[0][0]                  \n__________________________________________________________________________________________________\nadd_14 (Add)                    (None, 64, 64, 256)  0           activation_26[0][0]              \n                                                                 conv2d_24[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0           add_14[0][0]                     \n__________________________________________________________________________________________________\nconv2d_31 (Conv2D)              (None, 32, 32, 512)  131584      max_pooling2d_2[0][0]            \n__________________________________________________________________________________________________\nconv2d_32 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_31[0][0]                  \n__________________________________________________________________________________________________\nactivation_27 (Activation)      (None, 32, 32, 512)  0           conv2d_32[0][0]                  \n__________________________________________________________________________________________________\nadd_15 (Add)                    (None, 32, 32, 512)  0           activation_27[0][0]              \n                                                                 conv2d_31[0][0]                  \n__________________________________________________________________________________________________\nconv2d_33 (Conv2D)              (None, 32, 32, 512)  2359808     add_15[0][0]                     \n__________________________________________________________________________________________________\nactivation_28 (Activation)      (None, 32, 32, 512)  0           conv2d_33[0][0]                  \n__________________________________________________________________________________________________\nadd_16 (Add)                    (None, 32, 32, 512)  0           activation_28[0][0]              \n                                                                 conv2d_31[0][0]                  \n__________________________________________________________________________________________________\nconv2d_34 (Conv2D)              (None, 32, 32, 512)  2359808     add_16[0][0]                     \n__________________________________________________________________________________________________\nactivation_29 (Activation)      (None, 32, 32, 512)  0           conv2d_34[0][0]                  \n__________________________________________________________________________________________________\nconv2d_35 (Conv2D)              (None, 32, 32, 512)  2359808     activation_29[0][0]              \n__________________________________________________________________________________________________\nactivation_30 (Activation)      (None, 32, 32, 512)  0           conv2d_35[0][0]                  \n__________________________________________________________________________________________________\nadd_17 (Add)                    (None, 32, 32, 512)  0           activation_30[0][0]              \n                                                                 activation_29[0][0]              \n__________________________________________________________________________________________________\nconv2d_36 (Conv2D)              (None, 32, 32, 512)  2359808     add_17[0][0]                     \n__________________________________________________________________________________________________\nactivation_31 (Activation)      (None, 32, 32, 512)  0           conv2d_36[0][0]                  \n__________________________________________________________________________________________________\nadd_18 (Add)                    (None, 32, 32, 512)  0           activation_31[0][0]              \n                                                                 activation_29[0][0]              \n__________________________________________________________________________________________________\nconv2d_37 (Conv2D)              (None, 32, 32, 512)  2359808     add_18[0][0]                     \n__________________________________________________________________________________________________\nactivation_32 (Activation)      (None, 32, 32, 512)  0           conv2d_37[0][0]                  \n__________________________________________________________________________________________________\nadd_19 (Add)                    (None, 32, 32, 512)  0           activation_32[0][0]              \n                                                                 conv2d_31[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0           add_19[0][0]                     \n__________________________________________________________________________________________________\nconv2d_38 (Conv2D)              (None, 16, 16, 1024) 525312      max_pooling2d_3[0][0]            \n__________________________________________________________________________________________________\nconv2d_39 (Conv2D)              (None, 16, 16, 1024) 9438208     conv2d_38[0][0]                  \n__________________________________________________________________________________________________\nactivation_33 (Activation)      (None, 16, 16, 1024) 0           conv2d_39[0][0]                  \n__________________________________________________________________________________________________\nadd_20 (Add)                    (None, 16, 16, 1024) 0           activation_33[0][0]              \n                                                                 conv2d_38[0][0]                  \n__________________________________________________________________________________________________\nconv2d_40 (Conv2D)              (None, 16, 16, 1024) 9438208     add_20[0][0]                     \n__________________________________________________________________________________________________\nactivation_34 (Activation)      (None, 16, 16, 1024) 0           conv2d_40[0][0]                  \n__________________________________________________________________________________________________\nadd_21 (Add)                    (None, 16, 16, 1024) 0           activation_34[0][0]              \n                                                                 conv2d_38[0][0]                  \n__________________________________________________________________________________________________\nconv2d_41 (Conv2D)              (None, 16, 16, 1024) 9438208     add_21[0][0]                     \n__________________________________________________________________________________________________\nactivation_35 (Activation)      (None, 16, 16, 1024) 0           conv2d_41[0][0]                  \n__________________________________________________________________________________________________\nconv2d_42 (Conv2D)              (None, 16, 16, 1024) 9438208     activation_35[0][0]              \n__________________________________________________________________________________________________\nactivation_36 (Activation)      (None, 16, 16, 1024) 0           conv2d_42[0][0]                  \n__________________________________________________________________________________________________\nadd_22 (Add)                    (None, 16, 16, 1024) 0           activation_36[0][0]              \n                                                                 activation_35[0][0]              \n__________________________________________________________________________________________________\nconv2d_43 (Conv2D)              (None, 16, 16, 1024) 9438208     add_22[0][0]                     \n__________________________________________________________________________________________________\nactivation_37 (Activation)      (None, 16, 16, 1024) 0           conv2d_43[0][0]                  \n__________________________________________________________________________________________________\nadd_23 (Add)                    (None, 16, 16, 1024) 0           activation_37[0][0]              \n                                                                 activation_35[0][0]              \n__________________________________________________________________________________________________\nconv2d_44 (Conv2D)              (None, 16, 16, 1024) 9438208     add_23[0][0]                     \n__________________________________________________________________________________________________\nactivation_38 (Activation)      (None, 16, 16, 1024) 0           conv2d_44[0][0]                  \n__________________________________________________________________________________________________\nadd_24 (Add)                    (None, 16, 16, 1024) 0           activation_38[0][0]              \n                                                                 conv2d_38[0][0]                  \n__________________________________________________________________________________________________\nup_sampling2d_3 (UpSampling2D)  (None, 32, 32, 1024) 0           add_24[0][0]                     \n__________________________________________________________________________________________________\nconv2d_45 (Conv2D)              (None, 32, 32, 256)  131328      add_19[0][0]                     \n__________________________________________________________________________________________________\nconv2d_46 (Conv2D)              (None, 32, 32, 256)  262400      up_sampling2d_3[0][0]            \n__________________________________________________________________________________________________\nadd_25 (Add)                    (None, 32, 32, 256)  0           conv2d_45[0][0]                  \n                                                                 conv2d_46[0][0]                  \n__________________________________________________________________________________________________\nactivation_39 (Activation)      (None, 32, 32, 256)  0           add_25[0][0]                     \n__________________________________________________________________________________________________\nconv2d_47 (Conv2D)              (None, 32, 32, 1)    257         activation_39[0][0]              \n__________________________________________________________________________________________________\nactivation_40 (Activation)      (None, 32, 32, 1)    0           conv2d_47[0][0]                  \n__________________________________________________________________________________________________\nmultiply (Multiply)             (None, 32, 32, 512)  0           add_19[0][0]                     \n                                                                 activation_40[0][0]              \n__________________________________________________________________________________________________\nlambda (Lambda)                 (None, 32, 32, 1536) 0           up_sampling2d_3[0][0]            \n                                                                 multiply[0][0]                   \n__________________________________________________________________________________________________\nconv2d_48 (Conv2D)              (None, 32, 32, 512)  786944      lambda[0][0]                     \n__________________________________________________________________________________________________\nconv2d_49 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_48[0][0]                  \n__________________________________________________________________________________________________\nactivation_41 (Activation)      (None, 32, 32, 512)  0           conv2d_49[0][0]                  \n__________________________________________________________________________________________________\nadd_26 (Add)                    (None, 32, 32, 512)  0           activation_41[0][0]              \n                                                                 conv2d_48[0][0]                  \n__________________________________________________________________________________________________\nconv2d_50 (Conv2D)              (None, 32, 32, 512)  2359808     add_26[0][0]                     \n__________________________________________________________________________________________________\nactivation_42 (Activation)      (None, 32, 32, 512)  0           conv2d_50[0][0]                  \n__________________________________________________________________________________________________\nadd_27 (Add)                    (None, 32, 32, 512)  0           activation_42[0][0]              \n                                                                 conv2d_48[0][0]                  \n__________________________________________________________________________________________________\nconv2d_51 (Conv2D)              (None, 32, 32, 512)  2359808     add_27[0][0]                     \n__________________________________________________________________________________________________\nactivation_43 (Activation)      (None, 32, 32, 512)  0           conv2d_51[0][0]                  \n__________________________________________________________________________________________________\nconv2d_52 (Conv2D)              (None, 32, 32, 512)  2359808     activation_43[0][0]              \n__________________________________________________________________________________________________\nactivation_44 (Activation)      (None, 32, 32, 512)  0           conv2d_52[0][0]                  \n__________________________________________________________________________________________________\nadd_28 (Add)                    (None, 32, 32, 512)  0           activation_44[0][0]              \n                                                                 activation_43[0][0]              \n__________________________________________________________________________________________________\nconv2d_53 (Conv2D)              (None, 32, 32, 512)  2359808     add_28[0][0]                     \n__________________________________________________________________________________________________\nactivation_45 (Activation)      (None, 32, 32, 512)  0           conv2d_53[0][0]                  \n__________________________________________________________________________________________________\nadd_29 (Add)                    (None, 32, 32, 512)  0           activation_45[0][0]              \n                                                                 activation_43[0][0]              \n__________________________________________________________________________________________________\nconv2d_54 (Conv2D)              (None, 32, 32, 512)  2359808     add_29[0][0]                     \n__________________________________________________________________________________________________\nactivation_46 (Activation)      (None, 32, 32, 512)  0           conv2d_54[0][0]                  \n__________________________________________________________________________________________________\nadd_30 (Add)                    (None, 32, 32, 512)  0           activation_46[0][0]              \n                                                                 conv2d_48[0][0]                  \n__________________________________________________________________________________________________\nup_sampling2d_4 (UpSampling2D)  (None, 64, 64, 512)  0           add_30[0][0]                     \n__________________________________________________________________________________________________\nconv2d_55 (Conv2D)              (None, 64, 64, 128)  32896       add_14[0][0]                     \n__________________________________________________________________________________________________\nconv2d_56 (Conv2D)              (None, 64, 64, 128)  65664       up_sampling2d_4[0][0]            \n__________________________________________________________________________________________________\nadd_31 (Add)                    (None, 64, 64, 128)  0           conv2d_55[0][0]                  \n                                                                 conv2d_56[0][0]                  \n__________________________________________________________________________________________________\nactivation_47 (Activation)      (None, 64, 64, 128)  0           add_31[0][0]                     \n__________________________________________________________________________________________________\nconv2d_57 (Conv2D)              (None, 64, 64, 1)    129         activation_47[0][0]              \n__________________________________________________________________________________________________\nactivation_48 (Activation)      (None, 64, 64, 1)    0           conv2d_57[0][0]                  \n__________________________________________________________________________________________________\nmultiply_1 (Multiply)           (None, 64, 64, 256)  0           add_14[0][0]                     \n                                                                 activation_48[0][0]              \n__________________________________________________________________________________________________\nlambda_1 (Lambda)               (None, 64, 64, 768)  0           up_sampling2d_4[0][0]            \n                                                                 multiply_1[0][0]                 \n__________________________________________________________________________________________________\nconv2d_58 (Conv2D)              (None, 64, 64, 256)  196864      lambda_1[0][0]                   \n__________________________________________________________________________________________________\nconv2d_59 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_58[0][0]                  \n__________________________________________________________________________________________________\nactivation_49 (Activation)      (None, 64, 64, 256)  0           conv2d_59[0][0]                  \n__________________________________________________________________________________________________\nadd_32 (Add)                    (None, 64, 64, 256)  0           activation_49[0][0]              \n                                                                 conv2d_58[0][0]                  \n__________________________________________________________________________________________________\nconv2d_60 (Conv2D)              (None, 64, 64, 256)  590080      add_32[0][0]                     \n__________________________________________________________________________________________________\nactivation_50 (Activation)      (None, 64, 64, 256)  0           conv2d_60[0][0]                  \n__________________________________________________________________________________________________\nadd_33 (Add)                    (None, 64, 64, 256)  0           activation_50[0][0]              \n                                                                 conv2d_58[0][0]                  \n__________________________________________________________________________________________________\nconv2d_61 (Conv2D)              (None, 64, 64, 256)  590080      add_33[0][0]                     \n__________________________________________________________________________________________________\nactivation_51 (Activation)      (None, 64, 64, 256)  0           conv2d_61[0][0]                  \n__________________________________________________________________________________________________\nconv2d_62 (Conv2D)              (None, 64, 64, 256)  590080      activation_51[0][0]              \n__________________________________________________________________________________________________\nactivation_52 (Activation)      (None, 64, 64, 256)  0           conv2d_62[0][0]                  \n__________________________________________________________________________________________________\nadd_34 (Add)                    (None, 64, 64, 256)  0           activation_52[0][0]              \n                                                                 activation_51[0][0]              \n__________________________________________________________________________________________________\nconv2d_63 (Conv2D)              (None, 64, 64, 256)  590080      add_34[0][0]                     \n__________________________________________________________________________________________________\nactivation_53 (Activation)      (None, 64, 64, 256)  0           conv2d_63[0][0]                  \n__________________________________________________________________________________________________\nadd_35 (Add)                    (None, 64, 64, 256)  0           activation_53[0][0]              \n                                                                 activation_51[0][0]              \n__________________________________________________________________________________________________\nconv2d_64 (Conv2D)              (None, 64, 64, 256)  590080      add_35[0][0]                     \n__________________________________________________________________________________________________\nactivation_54 (Activation)      (None, 64, 64, 256)  0           conv2d_64[0][0]                  \n__________________________________________________________________________________________________\nadd_36 (Add)                    (None, 64, 64, 256)  0           activation_54[0][0]              \n                                                                 conv2d_58[0][0]                  \n__________________________________________________________________________________________________\nup_sampling2d_5 (UpSampling2D)  (None, 128, 128, 256 0           add_36[0][0]                     \n__________________________________________________________________________________________________\nconv2d_65 (Conv2D)              (None, 128, 128, 64) 8256        add_9[0][0]                      \n__________________________________________________________________________________________________\nconv2d_66 (Conv2D)              (None, 128, 128, 64) 16448       up_sampling2d_5[0][0]            \n__________________________________________________________________________________________________\nadd_37 (Add)                    (None, 128, 128, 64) 0           conv2d_65[0][0]                  \n                                                                 conv2d_66[0][0]                  \n__________________________________________________________________________________________________\nactivation_55 (Activation)      (None, 128, 128, 64) 0           add_37[0][0]                     \n__________________________________________________________________________________________________\nconv2d_67 (Conv2D)              (None, 128, 128, 1)  65          activation_55[0][0]              \n__________________________________________________________________________________________________\nactivation_56 (Activation)      (None, 128, 128, 1)  0           conv2d_67[0][0]                  \n__________________________________________________________________________________________________\nmultiply_2 (Multiply)           (None, 128, 128, 128 0           add_9[0][0]                      \n                                                                 activation_56[0][0]              \n__________________________________________________________________________________________________\nlambda_2 (Lambda)               (None, 128, 128, 384 0           up_sampling2d_5[0][0]            \n                                                                 multiply_2[0][0]                 \n__________________________________________________________________________________________________\nconv2d_68 (Conv2D)              (None, 128, 128, 128 49280       lambda_2[0][0]                   \n__________________________________________________________________________________________________\nconv2d_69 (Conv2D)              (None, 128, 128, 128 147584      conv2d_68[0][0]                  \n__________________________________________________________________________________________________\nactivation_57 (Activation)      (None, 128, 128, 128 0           conv2d_69[0][0]                  \n__________________________________________________________________________________________________\nadd_38 (Add)                    (None, 128, 128, 128 0           activation_57[0][0]              \n                                                                 conv2d_68[0][0]                  \n__________________________________________________________________________________________________\nconv2d_70 (Conv2D)              (None, 128, 128, 128 147584      add_38[0][0]                     \n__________________________________________________________________________________________________\nactivation_58 (Activation)      (None, 128, 128, 128 0           conv2d_70[0][0]                  \n__________________________________________________________________________________________________\nadd_39 (Add)                    (None, 128, 128, 128 0           activation_58[0][0]              \n                                                                 conv2d_68[0][0]                  \n__________________________________________________________________________________________________\nconv2d_71 (Conv2D)              (None, 128, 128, 128 147584      add_39[0][0]                     \n__________________________________________________________________________________________________\nactivation_59 (Activation)      (None, 128, 128, 128 0           conv2d_71[0][0]                  \n__________________________________________________________________________________________________\nconv2d_72 (Conv2D)              (None, 128, 128, 128 147584      activation_59[0][0]              \n__________________________________________________________________________________________________\nactivation_60 (Activation)      (None, 128, 128, 128 0           conv2d_72[0][0]                  \n__________________________________________________________________________________________________\nadd_40 (Add)                    (None, 128, 128, 128 0           activation_60[0][0]              \n                                                                 activation_59[0][0]              \n__________________________________________________________________________________________________\nconv2d_73 (Conv2D)              (None, 128, 128, 128 147584      add_40[0][0]                     \n__________________________________________________________________________________________________\nactivation_61 (Activation)      (None, 128, 128, 128 0           conv2d_73[0][0]                  \n__________________________________________________________________________________________________\nadd_41 (Add)                    (None, 128, 128, 128 0           activation_61[0][0]              \n                                                                 activation_59[0][0]              \n__________________________________________________________________________________________________\nconv2d_74 (Conv2D)              (None, 128, 128, 128 147584      add_41[0][0]                     \n__________________________________________________________________________________________________\nactivation_62 (Activation)      (None, 128, 128, 128 0           conv2d_74[0][0]                  \n__________________________________________________________________________________________________\nadd_42 (Add)                    (None, 128, 128, 128 0           activation_62[0][0]              \n                                                                 conv2d_68[0][0]                  \n__________________________________________________________________________________________________\nup_sampling2d_6 (UpSampling2D)  (None, 256, 256, 128 0           add_42[0][0]                     \n__________________________________________________________________________________________________\nconv2d_75 (Conv2D)              (None, 256, 256, 32) 2080        add_4[0][0]                      \n__________________________________________________________________________________________________\nconv2d_76 (Conv2D)              (None, 256, 256, 32) 4128        up_sampling2d_6[0][0]            \n__________________________________________________________________________________________________\nadd_43 (Add)                    (None, 256, 256, 32) 0           conv2d_75[0][0]                  \n                                                                 conv2d_76[0][0]                  \n__________________________________________________________________________________________________\nactivation_63 (Activation)      (None, 256, 256, 32) 0           add_43[0][0]                     \n__________________________________________________________________________________________________\nconv2d_77 (Conv2D)              (None, 256, 256, 1)  33          activation_63[0][0]              \n__________________________________________________________________________________________________\nactivation_64 (Activation)      (None, 256, 256, 1)  0           conv2d_77[0][0]                  \n__________________________________________________________________________________________________\nmultiply_3 (Multiply)           (None, 256, 256, 64) 0           add_4[0][0]                      \n                                                                 activation_64[0][0]              \n__________________________________________________________________________________________________\nlambda_3 (Lambda)               (None, 256, 256, 192 0           up_sampling2d_6[0][0]            \n                                                                 multiply_3[0][0]                 \n__________________________________________________________________________________________________\nconv2d_78 (Conv2D)              (None, 256, 256, 64) 12352       lambda_3[0][0]                   \n__________________________________________________________________________________________________\nconv2d_79 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_78[0][0]                  \n__________________________________________________________________________________________________\nactivation_65 (Activation)      (None, 256, 256, 64) 0           conv2d_79[0][0]                  \n__________________________________________________________________________________________________\nadd_44 (Add)                    (None, 256, 256, 64) 0           activation_65[0][0]              \n                                                                 conv2d_78[0][0]                  \n__________________________________________________________________________________________________\nconv2d_80 (Conv2D)              (None, 256, 256, 64) 36928       add_44[0][0]                     \n__________________________________________________________________________________________________\nactivation_66 (Activation)      (None, 256, 256, 64) 0           conv2d_80[0][0]                  \n__________________________________________________________________________________________________\nadd_45 (Add)                    (None, 256, 256, 64) 0           activation_66[0][0]              \n                                                                 conv2d_78[0][0]                  \n__________________________________________________________________________________________________\nconv2d_81 (Conv2D)              (None, 256, 256, 64) 36928       add_45[0][0]                     \n__________________________________________________________________________________________________\nactivation_67 (Activation)      (None, 256, 256, 64) 0           conv2d_81[0][0]                  \n__________________________________________________________________________________________________\nconv2d_82 (Conv2D)              (None, 256, 256, 64) 36928       activation_67[0][0]              \n__________________________________________________________________________________________________\nactivation_68 (Activation)      (None, 256, 256, 64) 0           conv2d_82[0][0]                  \n__________________________________________________________________________________________________\nadd_46 (Add)                    (None, 256, 256, 64) 0           activation_68[0][0]              \n                                                                 activation_67[0][0]              \n__________________________________________________________________________________________________\nconv2d_83 (Conv2D)              (None, 256, 256, 64) 36928       add_46[0][0]                     \n__________________________________________________________________________________________________\nactivation_69 (Activation)      (None, 256, 256, 64) 0           conv2d_83[0][0]                  \n__________________________________________________________________________________________________\nadd_47 (Add)                    (None, 256, 256, 64) 0           activation_69[0][0]              \n                                                                 activation_67[0][0]              \n__________________________________________________________________________________________________\nconv2d_84 (Conv2D)              (None, 256, 256, 64) 36928       add_47[0][0]                     \n__________________________________________________________________________________________________\nactivation_70 (Activation)      (None, 256, 256, 64) 0           conv2d_84[0][0]                  \n__________________________________________________________________________________________________\nadd_48 (Add)                    (None, 256, 256, 64) 0           activation_70[0][0]              \n                                                                 conv2d_78[0][0]                  \n__________________________________________________________________________________________________\nconv2d_85 (Conv2D)              (None, 256, 256, 2)  1154        add_48[0][0]                     \n__________________________________________________________________________________________________\nconv2d_86 (Conv2D)              (None, 256, 256, 1)  3           conv2d_85[0][0]                  \n__________________________________________________________________________________________________\nactivation_71 (Activation)      (None, 256, 256, 1)  0           conv2d_86[0][0]                  \n==================================================================================================\nTotal params: 96,510,825\nTrainable params: 96,510,825\nNon-trainable params: 0\n__________________________________________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(train_data,\n",
        "                              steps_per_epoch=1912,epochs=40,\n",
        "                              validation_steps=207,\n",
        "                              validation_data=valid_data,\n",
        "                              callbacks=[model_checkpoint1,csv_logger])"
      ],
      "metadata": {
        "id": "DJLOnaYejXrm",
        "outputId": "deabad6b-2cf2-449a-8124-ea3bd1e2a072",
        "execution": {
          "iopub.status.busy": "2021-09-15T15:07:48.511350Z",
          "iopub.execute_input": "2021-09-15T15:07:48.514086Z",
          "iopub.status.idle": "2021-09-15T19:34:25.565774Z",
          "shell.execute_reply.started": "2021-09-15T15:07:48.514054Z",
          "shell.execute_reply": "2021-09-15T19:34:25.557618Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Found 600 images belonging to 1 classes.\nFound 600 images belonging to 1 classes.\nEpoch 1/40\n(None, 256, 256, 1)\n(None, 256, 256, 1)\n1912/1912 [==============================] - ETA: 0s - loss: 0.6978 - ACL5: 10928.6839 - binary_crossentropy_plus_jaccard_loss: 0.6978 - dice_coef: 0.4728 - dsc: 0.4918 - dice_loss: 0.5082 - iou_coeff: 0.3658 - precision: 0.5397 - recall: 0.5267Found 200 images belonging to 1 classes.\nFound 200 images belonging to 1 classes.\n(None, 256, 256, 1)\n1912/1912 [==============================] - 406s 209ms/step - loss: 0.6977 - ACL5: 10926.7039 - binary_crossentropy_plus_jaccard_loss: 0.6977 - dice_coef: 0.4728 - dsc: 0.4919 - dice_loss: 0.5081 - iou_coeff: 0.3659 - precision: 0.5398 - recall: 0.5268 - val_loss: 0.5890 - val_ACL5: 2715.2871 - val_binary_crossentropy_plus_jaccard_loss: 0.5890 - val_dice_coef: 0.6046 - val_dsc: 0.6046 - val_dice_loss: 0.3954 - val_iou_coeff: 0.4917 - val_precision: 0.7023 - val_recall: 0.5463\n\nEpoch 00001: val_dice_loss improved from inf to 0.39541, saving model to att_r2_unet.hdf5\nEpoch 2/40\n1912/1912 [==============================] - 398s 208ms/step - loss: 0.4854 - ACL5: 5541.0024 - binary_crossentropy_plus_jaccard_loss: 0.4854 - dice_coef: 0.6700 - dsc: 0.6968 - dice_loss: 0.3032 - iou_coeff: 0.5561 - precision: 0.7346 - recall: 0.7160 - val_loss: 0.5549 - val_ACL5: 2557.3091 - val_binary_crossentropy_plus_jaccard_loss: 0.5549 - val_dice_coef: 0.6197 - val_dsc: 0.6197 - val_dice_loss: 0.3803 - val_iou_coeff: 0.5111 - val_precision: 0.6936 - val_recall: 0.5959\n\nEpoch 00002: val_dice_loss improved from 0.39541 to 0.38025, saving model to att_r2_unet.hdf5\nEpoch 3/40\n1912/1912 [==============================] - 397s 208ms/step - loss: 0.4446 - ACL5: 4849.3197 - binary_crossentropy_plus_jaccard_loss: 0.4446 - dice_coef: 0.6971 - dsc: 0.7274 - dice_loss: 0.2726 - iou_coeff: 0.5918 - precision: 0.7537 - recall: 0.7467 - val_loss: 0.5214 - val_ACL5: 2725.7275 - val_binary_crossentropy_plus_jaccard_loss: 0.5214 - val_dice_coef: 0.6483 - val_dsc: 0.6483 - val_dice_loss: 0.3517 - val_iou_coeff: 0.5343 - val_precision: 0.6554 - val_recall: 0.6741\n\nEpoch 00003: val_dice_loss improved from 0.38025 to 0.35171, saving model to att_r2_unet.hdf5\nEpoch 4/40\n1912/1912 [==============================] - 397s 208ms/step - loss: 0.4078 - ACL5: 4535.5187 - binary_crossentropy_plus_jaccard_loss: 0.4078 - dice_coef: 0.7303 - dsc: 0.7565 - dice_loss: 0.2435 - iou_coeff: 0.6248 - precision: 0.7726 - recall: 0.7795 - val_loss: 0.5943 - val_ACL5: 2611.4604 - val_binary_crossentropy_plus_jaccard_loss: 0.5943 - val_dice_coef: 0.5913 - val_dsc: 0.5913 - val_dice_loss: 0.4087 - val_iou_coeff: 0.5010 - val_precision: 0.6372 - val_recall: 0.5500\n\nEpoch 00004: val_dice_loss did not improve from 0.35171\nEpoch 5/40\n1912/1912 [==============================] - 397s 207ms/step - loss: 0.3918 - ACL5: 4321.6670 - binary_crossentropy_plus_jaccard_loss: 0.3918 - dice_coef: 0.7406 - dsc: 0.7669 - dice_loss: 0.2331 - iou_coeff: 0.6390 - precision: 0.7826 - recall: 0.7887 - val_loss: 0.5240 - val_ACL5: 3077.3445 - val_binary_crossentropy_plus_jaccard_loss: 0.5240 - val_dice_coef: 0.6443 - val_dsc: 0.6443 - val_dice_loss: 0.3557 - val_iou_coeff: 0.5298 - val_precision: 0.6560 - val_recall: 0.6920\n\nEpoch 00005: val_dice_loss did not improve from 0.35171\nEpoch 6/40\n1912/1912 [==============================] - 397s 208ms/step - loss: 0.3873 - ACL5: 4286.5614 - binary_crossentropy_plus_jaccard_loss: 0.3873 - dice_coef: 0.7418 - dsc: 0.7708 - dice_loss: 0.2292 - iou_coeff: 0.6431 - precision: 0.7901 - recall: 0.7890 - val_loss: 0.4509 - val_ACL5: 2231.7085 - val_binary_crossentropy_plus_jaccard_loss: 0.4509 - val_dice_coef: 0.7087 - val_dsc: 0.7087 - val_dice_loss: 0.2913 - val_iou_coeff: 0.6044 - val_precision: 0.7308 - val_recall: 0.7138\n\nEpoch 00006: val_dice_loss improved from 0.35171 to 0.29128, saving model to att_r2_unet.hdf5\nEpoch 7/40\n1912/1912 [==============================] - 397s 208ms/step - loss: 0.3644 - ACL5: 4021.3509 - binary_crossentropy_plus_jaccard_loss: 0.3644 - dice_coef: 0.7584 - dsc: 0.7866 - dice_loss: 0.2134 - iou_coeff: 0.6630 - precision: 0.7989 - recall: 0.8047 - val_loss: 0.5718 - val_ACL5: 2731.8154 - val_binary_crossentropy_plus_jaccard_loss: 0.5718 - val_dice_coef: 0.6099 - val_dsc: 0.6099 - val_dice_loss: 0.3901 - val_iou_coeff: 0.5110 - val_precision: 0.6549 - val_recall: 0.6237\n\nEpoch 00007: val_dice_loss did not improve from 0.29128\nEpoch 8/40\n1912/1912 [==============================] - 397s 208ms/step - loss: 0.3901 - ACL5: 4232.4636 - binary_crossentropy_plus_jaccard_loss: 0.3901 - dice_coef: 0.7329 - dsc: 0.7685 - dice_loss: 0.2315 - iou_coeff: 0.6407 - precision: 0.7954 - recall: 0.7844 - val_loss: 0.4642 - val_ACL5: 2369.1714 - val_binary_crossentropy_plus_jaccard_loss: 0.4642 - val_dice_coef: 0.6934 - val_dsc: 0.6934 - val_dice_loss: 0.3066 - val_iou_coeff: 0.5920 - val_precision: 0.7294 - val_recall: 0.6991\n\nEpoch 00008: val_dice_loss did not improve from 0.29128\nEpoch 9/40\n1912/1912 [==============================] - 401s 210ms/step - loss: 0.3488 - ACL5: 3868.4428 - binary_crossentropy_plus_jaccard_loss: 0.3488 - dice_coef: 0.7692 - dsc: 0.7986 - dice_loss: 0.2014 - iou_coeff: 0.6778 - precision: 0.8047 - recall: 0.8213 - val_loss: 0.5191 - val_ACL5: 2585.4888 - val_binary_crossentropy_plus_jaccard_loss: 0.5191 - val_dice_coef: 0.6648 - val_dsc: 0.6648 - val_dice_loss: 0.3352 - val_iou_coeff: 0.5611 - val_precision: 0.6723 - val_recall: 0.6826\n\nEpoch 00009: val_dice_loss did not improve from 0.29128\nEpoch 10/40\n1912/1912 [==============================] - 401s 210ms/step - loss: 0.3605 - ACL5: 3968.4998 - binary_crossentropy_plus_jaccard_loss: 0.3605 - dice_coef: 0.7605 - dsc: 0.7904 - dice_loss: 0.2096 - iou_coeff: 0.6671 - precision: 0.8010 - recall: 0.8115 - val_loss: 0.5129 - val_ACL5: 2537.3025 - val_binary_crossentropy_plus_jaccard_loss: 0.5129 - val_dice_coef: 0.6568 - val_dsc: 0.6568 - val_dice_loss: 0.3432 - val_iou_coeff: 0.5572 - val_precision: 0.7011 - val_recall: 0.6550\n\nEpoch 00010: val_dice_loss did not improve from 0.29128\nEpoch 11/40\n1912/1912 [==============================] - 402s 210ms/step - loss: 0.3487 - ACL5: 3852.2323 - binary_crossentropy_plus_jaccard_loss: 0.3487 - dice_coef: 0.7706 - dsc: 0.7976 - dice_loss: 0.2024 - iou_coeff: 0.6786 - precision: 0.8096 - recall: 0.8135 - val_loss: 0.4971 - val_ACL5: 2202.6287 - val_binary_crossentropy_plus_jaccard_loss: 0.4971 - val_dice_coef: 0.7054 - val_dsc: 0.7054 - val_dice_loss: 0.2946 - val_iou_coeff: 0.6035 - val_precision: 0.7270 - val_recall: 0.6697\n\nEpoch 00011: val_dice_loss did not improve from 0.29128\nEpoch 12/40\n1912/1912 [==============================] - 400s 209ms/step - loss: 0.3412 - ACL5: 3708.7668 - binary_crossentropy_plus_jaccard_loss: 0.3412 - dice_coef: 0.7722 - dsc: 0.8035 - dice_loss: 0.1965 - iou_coeff: 0.6855 - precision: 0.8174 - recall: 0.8169 - val_loss: 0.4449 - val_ACL5: 2064.7185 - val_binary_crossentropy_plus_jaccard_loss: 0.4449 - val_dice_coef: 0.7004 - val_dsc: 0.7004 - val_dice_loss: 0.2996 - val_iou_coeff: 0.5978 - val_precision: 0.7662 - val_recall: 0.6806\n\nEpoch 00012: val_dice_loss did not improve from 0.29128\nEpoch 13/40\n1912/1912 [==============================] - 399s 209ms/step - loss: 0.3354 - ACL5: 3694.3636 - binary_crossentropy_plus_jaccard_loss: 0.3354 - dice_coef: 0.7783 - dsc: 0.8088 - dice_loss: 0.1912 - iou_coeff: 0.6907 - precision: 0.8179 - recall: 0.8254 - val_loss: 0.4813 - val_ACL5: 2479.4001 - val_binary_crossentropy_plus_jaccard_loss: 0.4813 - val_dice_coef: 0.7010 - val_dsc: 0.7010 - val_dice_loss: 0.2990 - val_iou_coeff: 0.5953 - val_precision: 0.7384 - val_recall: 0.6958\n\nEpoch 00013: val_dice_loss did not improve from 0.29128\nEpoch 14/40\n1912/1912 [==============================] - 399s 209ms/step - loss: 0.3417 - ACL5: 3733.5160 - binary_crossentropy_plus_jaccard_loss: 0.3417 - dice_coef: 0.7753 - dsc: 0.8027 - dice_loss: 0.1973 - iou_coeff: 0.6842 - precision: 0.8138 - recall: 0.8200 - val_loss: 0.4682 - val_ACL5: 2191.7104 - val_binary_crossentropy_plus_jaccard_loss: 0.4682 - val_dice_coef: 0.6984 - val_dsc: 0.6984 - val_dice_loss: 0.3016 - val_iou_coeff: 0.6014 - val_precision: 0.7072 - val_recall: 0.6790\n\nEpoch 00014: val_dice_loss did not improve from 0.29128\nEpoch 15/40\n1912/1912 [==============================] - 399s 209ms/step - loss: 0.3304 - ACL5: 3622.8694 - binary_crossentropy_plus_jaccard_loss: 0.3304 - dice_coef: 0.7804 - dsc: 0.8117 - dice_loss: 0.1883 - iou_coeff: 0.6951 - precision: 0.8224 - recall: 0.8255 - val_loss: 0.5325 - val_ACL5: 2287.2490 - val_binary_crossentropy_plus_jaccard_loss: 0.5325 - val_dice_coef: 0.6593 - val_dsc: 0.6593 - val_dice_loss: 0.3407 - val_iou_coeff: 0.5647 - val_precision: 0.7161 - val_recall: 0.5924\n\nEpoch 00015: val_dice_loss did not improve from 0.29128\nEpoch 16/40\n1912/1912 [==============================] - 400s 209ms/step - loss: 0.3277 - ACL5: 3606.4792 - binary_crossentropy_plus_jaccard_loss: 0.3277 - dice_coef: 0.7839 - dsc: 0.8135 - dice_loss: 0.1865 - iou_coeff: 0.6972 - precision: 0.8223 - recall: 0.8290 - val_loss: 0.3890 - val_ACL5: 2060.3945 - val_binary_crossentropy_plus_jaccard_loss: 0.3890 - val_dice_coef: 0.7566 - val_dsc: 0.7566 - val_dice_loss: 0.2434 - val_iou_coeff: 0.6456 - val_precision: 0.7782 - val_recall: 0.7740\n\nEpoch 00016: val_dice_loss improved from 0.29128 to 0.24341, saving model to att_r2_unet.hdf5\nEpoch 17/40\n1912/1912 [==============================] - 399s 209ms/step - loss: 0.3265 - ACL5: 3609.9138 - binary_crossentropy_plus_jaccard_loss: 0.3265 - dice_coef: 0.7880 - dsc: 0.8145 - dice_loss: 0.1855 - iou_coeff: 0.6988 - precision: 0.8211 - recall: 0.8331 - val_loss: 0.4458 - val_ACL5: 2303.2739 - val_binary_crossentropy_plus_jaccard_loss: 0.4458 - val_dice_coef: 0.7035 - val_dsc: 0.7035 - val_dice_loss: 0.2965 - val_iou_coeff: 0.6030 - val_precision: 0.7345 - val_recall: 0.7043\n\nEpoch 00017: val_dice_loss did not improve from 0.24341\nEpoch 18/40\n1912/1912 [==============================] - 399s 209ms/step - loss: 0.3092 - ACL5: 3394.1478 - binary_crossentropy_plus_jaccard_loss: 0.3092 - dice_coef: 0.7960 - dsc: 0.8273 - dice_loss: 0.1727 - iou_coeff: 0.7143 - precision: 0.8369 - recall: 0.8388 - val_loss: 0.4081 - val_ACL5: 2078.3696 - val_binary_crossentropy_plus_jaccard_loss: 0.4081 - val_dice_coef: 0.7346 - val_dsc: 0.7346 - val_dice_loss: 0.2654 - val_iou_coeff: 0.6305 - val_precision: 0.7555 - val_recall: 0.7349\n\nEpoch 00018: val_dice_loss did not improve from 0.24341\nEpoch 19/40\n1912/1912 [==============================] - 401s 210ms/step - loss: 0.3054 - ACL5: 3328.2813 - binary_crossentropy_plus_jaccard_loss: 0.3054 - dice_coef: 0.8034 - dsc: 0.8285 - dice_loss: 0.1715 - iou_coeff: 0.7178 - precision: 0.8347 - recall: 0.8392 - val_loss: 0.5717 - val_ACL5: 2550.5203 - val_binary_crossentropy_plus_jaccard_loss: 0.5717 - val_dice_coef: 0.6269 - val_dsc: 0.6269 - val_dice_loss: 0.3731 - val_iou_coeff: 0.5324 - val_precision: 0.6772 - val_recall: 0.5929\n\nEpoch 00019: val_dice_loss did not improve from 0.24341\nEpoch 20/40\n1912/1912 [==============================] - 402s 210ms/step - loss: 0.3238 - ACL5: 3507.2230 - binary_crossentropy_plus_jaccard_loss: 0.3238 - dice_coef: 0.7876 - dsc: 0.8153 - dice_loss: 0.1847 - iou_coeff: 0.7017 - precision: 0.8305 - recall: 0.8241 - val_loss: 0.5356 - val_ACL5: 2185.3242 - val_binary_crossentropy_plus_jaccard_loss: 0.5356 - val_dice_coef: 0.6733 - val_dsc: 0.6733 - val_dice_loss: 0.3267 - val_iou_coeff: 0.5778 - val_precision: 0.7381 - val_recall: 0.6155\n\nEpoch 00020: val_dice_loss did not improve from 0.24341\nEpoch 21/40\n1912/1912 [==============================] - 401s 210ms/step - loss: 0.3075 - ACL5: 3356.2638 - binary_crossentropy_plus_jaccard_loss: 0.3075 - dice_coef: 0.7988 - dsc: 0.8271 - dice_loss: 0.1729 - iou_coeff: 0.7162 - precision: 0.8376 - recall: 0.8357 - val_loss: 0.4938 - val_ACL5: 2206.9849 - val_binary_crossentropy_plus_jaccard_loss: 0.4938 - val_dice_coef: 0.7133 - val_dsc: 0.7133 - val_dice_loss: 0.2867 - val_iou_coeff: 0.6155 - val_precision: 0.7275 - val_recall: 0.6916\n\nEpoch 00021: val_dice_loss did not improve from 0.24341\nEpoch 22/40\n1912/1912 [==============================] - 399s 209ms/step - loss: 0.3117 - ACL5: 3433.8784 - binary_crossentropy_plus_jaccard_loss: 0.3117 - dice_coef: 0.7974 - dsc: 0.8248 - dice_loss: 0.1752 - iou_coeff: 0.7125 - precision: 0.8348 - recall: 0.8359 - val_loss: 0.5203 - val_ACL5: 2255.1377 - val_binary_crossentropy_plus_jaccard_loss: 0.5203 - val_dice_coef: 0.6895 - val_dsc: 0.6895 - val_dice_loss: 0.3105 - val_iou_coeff: 0.5930 - val_precision: 0.7027 - val_recall: 0.6778\n\nEpoch 00022: val_dice_loss did not improve from 0.24341\nEpoch 23/40\n1912/1912 [==============================] - 399s 209ms/step - loss: 0.3037 - ACL5: 3336.7005 - binary_crossentropy_plus_jaccard_loss: 0.3037 - dice_coef: 0.8050 - dsc: 0.8297 - dice_loss: 0.1703 - iou_coeff: 0.7192 - precision: 0.8339 - recall: 0.8457 - val_loss: 0.4532 - val_ACL5: 2107.5229 - val_binary_crossentropy_plus_jaccard_loss: 0.4532 - val_dice_coef: 0.7142 - val_dsc: 0.7142 - val_dice_loss: 0.2858 - val_iou_coeff: 0.6170 - val_precision: 0.7424 - val_recall: 0.6871\n\nEpoch 00023: val_dice_loss did not improve from 0.24341\nEpoch 24/40\n1912/1912 [==============================] - 398s 208ms/step - loss: 0.2920 - ACL5: 3224.6570 - binary_crossentropy_plus_jaccard_loss: 0.2920 - dice_coef: 0.8148 - dsc: 0.8384 - dice_loss: 0.1616 - iou_coeff: 0.7307 - precision: 0.8446 - recall: 0.8483 - val_loss: 0.4448 - val_ACL5: 2062.7756 - val_binary_crossentropy_plus_jaccard_loss: 0.4448 - val_dice_coef: 0.7092 - val_dsc: 0.7092 - val_dice_loss: 0.2908 - val_iou_coeff: 0.6165 - val_precision: 0.7246 - val_recall: 0.6990\n\nEpoch 00024: val_dice_loss did not improve from 0.24341\nEpoch 25/40\n1912/1912 [==============================] - 399s 209ms/step - loss: 0.2949 - ACL5: 3192.3975 - binary_crossentropy_plus_jaccard_loss: 0.2949 - dice_coef: 0.8045 - dsc: 0.8351 - dice_loss: 0.1649 - iou_coeff: 0.7276 - precision: 0.8472 - recall: 0.8417 - val_loss: 0.4537 - val_ACL5: 2226.7329 - val_binary_crossentropy_plus_jaccard_loss: 0.4537 - val_dice_coef: 0.7125 - val_dsc: 0.7125 - val_dice_loss: 0.2875 - val_iou_coeff: 0.6138 - val_precision: 0.7130 - val_recall: 0.7296\n\nEpoch 00025: val_dice_loss did not improve from 0.24341\nEpoch 26/40\n1912/1912 [==============================] - 398s 208ms/step - loss: 0.2974 - ACL5: 3283.5128 - binary_crossentropy_plus_jaccard_loss: 0.2974 - dice_coef: 0.8096 - dsc: 0.8349 - dice_loss: 0.1651 - iou_coeff: 0.7255 - precision: 0.8422 - recall: 0.8472 - val_loss: 0.4077 - val_ACL5: 1973.3888 - val_binary_crossentropy_plus_jaccard_loss: 0.4077 - val_dice_coef: 0.7458 - val_dsc: 0.7458 - val_dice_loss: 0.2542 - val_iou_coeff: 0.6413 - val_precision: 0.7710 - val_recall: 0.7373\n\nEpoch 00026: val_dice_loss did not improve from 0.24341\nEpoch 27/40\n1912/1912 [==============================] - 399s 209ms/step - loss: 0.2780 - ACL5: 3028.2772 - binary_crossentropy_plus_jaccard_loss: 0.2780 - dice_coef: 0.8251 - dsc: 0.8480 - dice_loss: 0.1520 - iou_coeff: 0.7429 - precision: 0.8534 - recall: 0.8580 - val_loss: 0.4567 - val_ACL5: 2080.3989 - val_binary_crossentropy_plus_jaccard_loss: 0.4567 - val_dice_coef: 0.7209 - val_dsc: 0.7209 - val_dice_loss: 0.2791 - val_iou_coeff: 0.6229 - val_precision: 0.7605 - val_recall: 0.6977\n\nEpoch 00027: val_dice_loss did not improve from 0.24341\nEpoch 28/40\n1912/1912 [==============================] - 398s 208ms/step - loss: 0.2806 - ACL5: 3081.7202 - binary_crossentropy_plus_jaccard_loss: 0.2806 - dice_coef: 0.8234 - dsc: 0.8443 - dice_loss: 0.1557 - iou_coeff: 0.7403 - precision: 0.8524 - recall: 0.8511 - val_loss: 0.4185 - val_ACL5: 1992.0013 - val_binary_crossentropy_plus_jaccard_loss: 0.4185 - val_dice_coef: 0.7502 - val_dsc: 0.7502 - val_dice_loss: 0.2498 - val_iou_coeff: 0.6503 - val_precision: 0.7527 - val_recall: 0.7373\n\nEpoch 00028: val_dice_loss did not improve from 0.24341\nEpoch 29/40\n1912/1912 [==============================] - 399s 208ms/step - loss: 0.2768 - ACL5: 3065.2593 - binary_crossentropy_plus_jaccard_loss: 0.2768 - dice_coef: 0.8243 - dsc: 0.8491 - dice_loss: 0.1509 - iou_coeff: 0.7442 - precision: 0.8540 - recall: 0.8590 - val_loss: 0.4877 - val_ACL5: 2121.4937 - val_binary_crossentropy_plus_jaccard_loss: 0.4877 - val_dice_coef: 0.7221 - val_dsc: 0.7221 - val_dice_loss: 0.2779 - val_iou_coeff: 0.6190 - val_precision: 0.7485 - val_recall: 0.6937\n\nEpoch 00029: val_dice_loss did not improve from 0.24341\nEpoch 30/40\n1912/1912 [==============================] - 398s 208ms/step - loss: 0.2846 - ACL5: 3099.1471 - binary_crossentropy_plus_jaccard_loss: 0.2846 - dice_coef: 0.8172 - dsc: 0.8431 - dice_loss: 0.1569 - iou_coeff: 0.7379 - precision: 0.8512 - recall: 0.8505 - val_loss: 0.5086 - val_ACL5: 2154.7839 - val_binary_crossentropy_plus_jaccard_loss: 0.5086 - val_dice_coef: 0.6965 - val_dsc: 0.6965 - val_dice_loss: 0.3035 - val_iou_coeff: 0.6024 - val_precision: 0.7122 - val_recall: 0.6827\n\nEpoch 00030: val_dice_loss did not improve from 0.24341\nEpoch 31/40\n1912/1912 [==============================] - 399s 209ms/step - loss: 0.2903 - ACL5: 3179.6053 - binary_crossentropy_plus_jaccard_loss: 0.2903 - dice_coef: 0.8135 - dsc: 0.8385 - dice_loss: 0.1615 - iou_coeff: 0.7323 - precision: 0.8432 - recall: 0.8502 - val_loss: 0.3682 - val_ACL5: 1860.1115 - val_binary_crossentropy_plus_jaccard_loss: 0.3682 - val_dice_coef: 0.7806 - val_dsc: 0.7806 - val_dice_loss: 0.2194 - val_iou_coeff: 0.6778 - val_precision: 0.7774 - val_recall: 0.7769\n\nEpoch 00031: val_dice_loss improved from 0.24341 to 0.21942, saving model to att_r2_unet.hdf5\nEpoch 32/40\n1912/1912 [==============================] - 402s 210ms/step - loss: 0.2707 - ACL5: 2980.0013 - binary_crossentropy_plus_jaccard_loss: 0.2707 - dice_coef: 0.8299 - dsc: 0.8518 - dice_loss: 0.1482 - iou_coeff: 0.7495 - precision: 0.8571 - recall: 0.8598 - val_loss: 0.4146 - val_ACL5: 2269.0107 - val_binary_crossentropy_plus_jaccard_loss: 0.4146 - val_dice_coef: 0.7406 - val_dsc: 0.7406 - val_dice_loss: 0.2594 - val_iou_coeff: 0.6307 - val_precision: 0.7548 - val_recall: 0.7438\n\nEpoch 00032: val_dice_loss did not improve from 0.21942\nEpoch 33/40\n1912/1912 [==============================] - 399s 209ms/step - loss: 0.2791 - ACL5: 3051.3832 - binary_crossentropy_plus_jaccard_loss: 0.2791 - dice_coef: 0.8216 - dsc: 0.8460 - dice_loss: 0.1540 - iou_coeff: 0.7419 - precision: 0.8504 - recall: 0.8573 - val_loss: 0.4725 - val_ACL5: 2094.9961 - val_binary_crossentropy_plus_jaccard_loss: 0.4725 - val_dice_coef: 0.7306 - val_dsc: 0.7306 - val_dice_loss: 0.2694 - val_iou_coeff: 0.6250 - val_precision: 0.7880 - val_recall: 0.7069\n\nEpoch 00033: val_dice_loss did not improve from 0.21942\nEpoch 34/40\n1912/1912 [==============================] - 399s 209ms/step - loss: 0.2830 - ACL5: 3094.6129 - binary_crossentropy_plus_jaccard_loss: 0.2830 - dice_coef: 0.8209 - dsc: 0.8443 - dice_loss: 0.1557 - iou_coeff: 0.7402 - precision: 0.8512 - recall: 0.8494 - val_loss: 0.4137 - val_ACL5: 1971.8860 - val_binary_crossentropy_plus_jaccard_loss: 0.4137 - val_dice_coef: 0.7526 - val_dsc: 0.7526 - val_dice_loss: 0.2474 - val_iou_coeff: 0.6516 - val_precision: 0.7733 - val_recall: 0.7249\n\nEpoch 00034: val_dice_loss did not improve from 0.21942\nEpoch 35/40\n1912/1912 [==============================] - 399s 209ms/step - loss: 0.2834 - ACL5: 3116.2168 - binary_crossentropy_plus_jaccard_loss: 0.2834 - dice_coef: 0.8206 - dsc: 0.8443 - dice_loss: 0.1557 - iou_coeff: 0.7392 - precision: 0.8522 - recall: 0.8507 - val_loss: 0.4684 - val_ACL5: 2061.8958 - val_binary_crossentropy_plus_jaccard_loss: 0.4684 - val_dice_coef: 0.7085 - val_dsc: 0.7085 - val_dice_loss: 0.2915 - val_iou_coeff: 0.6092 - val_precision: 0.7297 - val_recall: 0.7016\n\nEpoch 00035: val_dice_loss did not improve from 0.21942\nEpoch 36/40\n1912/1912 [==============================] - 400s 209ms/step - loss: 0.2710 - ACL5: 2991.7563 - binary_crossentropy_plus_jaccard_loss: 0.2710 - dice_coef: 0.8307 - dsc: 0.8515 - dice_loss: 0.1485 - iou_coeff: 0.7500 - precision: 0.8553 - recall: 0.8594 - val_loss: 0.4036 - val_ACL5: 1872.9216 - val_binary_crossentropy_plus_jaccard_loss: 0.4036 - val_dice_coef: 0.7532 - val_dsc: 0.7532 - val_dice_loss: 0.2468 - val_iou_coeff: 0.6537 - val_precision: 0.7747 - val_recall: 0.7375\n\nEpoch 00036: val_dice_loss did not improve from 0.21942\nEpoch 37/40\n1912/1912 [==============================] - 401s 210ms/step - loss: 0.2591 - ACL5: 2845.2262 - binary_crossentropy_plus_jaccard_loss: 0.2591 - dice_coef: 0.8436 - dsc: 0.8603 - dice_loss: 0.1397 - iou_coeff: 0.7613 - precision: 0.8628 - recall: 0.8671 - val_loss: 0.5441 - val_ACL5: 2124.4602 - val_binary_crossentropy_plus_jaccard_loss: 0.5441 - val_dice_coef: 0.7083 - val_dsc: 0.7083 - val_dice_loss: 0.2917 - val_iou_coeff: 0.6140 - val_precision: 0.7372 - val_recall: 0.6595\n\nEpoch 00037: val_dice_loss did not improve from 0.21942\nEpoch 38/40\n1912/1912 [==============================] - 401s 210ms/step - loss: 0.2764 - ACL5: 3056.8494 - binary_crossentropy_plus_jaccard_loss: 0.2764 - dice_coef: 0.8280 - dsc: 0.8473 - dice_loss: 0.1527 - iou_coeff: 0.7453 - precision: 0.8531 - recall: 0.8559 - val_loss: 0.4043 - val_ACL5: 1897.5811 - val_binary_crossentropy_plus_jaccard_loss: 0.4043 - val_dice_coef: 0.7671 - val_dsc: 0.7671 - val_dice_loss: 0.2329 - val_iou_coeff: 0.6663 - val_precision: 0.7842 - val_recall: 0.7399\n\nEpoch 00038: val_dice_loss did not improve from 0.21942\nEpoch 39/40\n1912/1912 [==============================] - 401s 209ms/step - loss: 0.2735 - ACL5: 3016.6170 - binary_crossentropy_plus_jaccard_loss: 0.2735 - dice_coef: 0.8302 - dsc: 0.8502 - dice_loss: 0.1498 - iou_coeff: 0.7488 - precision: 0.8523 - recall: 0.8596 - val_loss: 0.4734 - val_ACL5: 2037.0823 - val_binary_crossentropy_plus_jaccard_loss: 0.4734 - val_dice_coef: 0.7027 - val_dsc: 0.7027 - val_dice_loss: 0.2973 - val_iou_coeff: 0.6054 - val_precision: 0.7356 - val_recall: 0.6942\n\nEpoch 00039: val_dice_loss did not improve from 0.21942\nEpoch 40/40\n1912/1912 [==============================] - 400s 209ms/step - loss: 0.2691 - ACL5: 2991.8798 - binary_crossentropy_plus_jaccard_loss: 0.2691 - dice_coef: 0.8329 - dsc: 0.8532 - dice_loss: 0.1468 - iou_coeff: 0.7524 - precision: 0.8566 - recall: 0.8610 - val_loss: 0.4059 - val_ACL5: 2030.8043 - val_binary_crossentropy_plus_jaccard_loss: 0.4059 - val_dice_coef: 0.7558 - val_dsc: 0.7558 - val_dice_loss: 0.2442 - val_iou_coeff: 0.6537 - val_precision: 0.7590 - val_recall: 0.7515\n\nEpoch 00040: val_dice_loss did not improve from 0.21942\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZhYu4PezRX0-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}