{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "DeepLabV3Plus_BCEJaccard.ipynb",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras==2.4.3"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "id": "PNfpi6Q0jXrM",
        "execution": {
          "iopub.status.busy": "2021-09-15T11:35:10.617443Z",
          "iopub.execute_input": "2021-09-15T11:35:10.617729Z",
          "iopub.status.idle": "2021-09-15T11:35:20.011762Z",
          "shell.execute_reply.started": "2021-09-15T11:35:10.617701Z",
          "shell.execute_reply": "2021-09-15T11:35:20.010640Z"
        },
        "trusted": true,
        "outputId": "6743c1af-e4af-4c2f-ac29-725454b524fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: keras==2.4.3 in /opt/conda/lib/python3.7/site-packages (2.4.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras==2.4.3) (5.4.1)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras==2.4.3) (1.7.1)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras==2.4.3) (2.10.0)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras==2.4.3) (1.19.5)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras==2.4.3) (1.15.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.4.1\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-15T11:35:20.017087Z",
          "iopub.execute_input": "2021-09-15T11:35:20.017362Z",
          "iopub.status.idle": "2021-09-15T11:35:29.054745Z",
          "shell.execute_reply.started": "2021-09-15T11:35:20.017330Z",
          "shell.execute_reply": "2021-09-15T11:35:29.053373Z"
        },
        "trusted": true,
        "id": "IBFCZDBcSmbj",
        "outputId": "0f367bac-014a-47fc-fe38-472d01039905"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: tensorflow==2.4.1 in /opt/conda/lib/python3.7/site-packages (2.4.1)\nRequirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.37.0)\nRequirement already satisfied: six~=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.15.0)\nRequirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.1.0)\nRequirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.2.0)\nRequirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.1.2)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (3.17.3)\nRequirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.12.0)\nRequirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.3.3)\nRequirement already satisfied: h5py~=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (2.10.0)\nRequirement already satisfied: grpcio~=1.32.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.32.0)\nRequirement already satisfied: tensorboard~=2.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (2.6.0)\nRequirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (3.7.4.3)\nRequirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (2.4.0)\nRequirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.12.1)\nRequirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.6.3)\nRequirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.12)\nRequirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (3.3.0)\nRequirement already satisfied: numpy~=1.19.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.19.5)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.5)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.0)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.25.1)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.0.1)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.34.0)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (57.4.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.4)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.7.2)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.2)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.4.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2021.5.30)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (4.0.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.26.6)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.5.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Reshape, Permute, Activation, Input, \\\n",
        "    add, multiply\n",
        "from keras.layers import concatenate, core, Dropout\n",
        "from keras.models import Model\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.core import Lambda\n",
        "#import keras.backend as K\n",
        "\n",
        "#%tensorflow_version 1.x\n",
        "import os\n",
        "import keras\n",
        "from keras.callbacks import TensorBoard\n",
        "import tensorflow as tf\n",
        "#import keras.backend.tensorflow_backend as K\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import CSVLogger"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-15T11:35:29.056792Z",
          "iopub.execute_input": "2021-09-15T11:35:29.057116Z",
          "iopub.status.idle": "2021-09-15T11:35:29.073463Z",
          "shell.execute_reply.started": "2021-09-15T11:35:29.057077Z",
          "shell.execute_reply": "2021-09-15T11:35:29.072268Z"
        },
        "trusted": true,
        "id": "GBKVBJywSmbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2"
      ],
      "metadata": {
        "id": "2a8AfzPOjXrQ",
        "execution": {
          "iopub.status.busy": "2021-09-15T11:35:29.078797Z",
          "iopub.execute_input": "2021-09-15T11:35:29.079084Z",
          "iopub.status.idle": "2021-09-15T11:35:29.980203Z",
          "shell.execute_reply.started": "2021-09-15T11:35:29.079051Z",
          "shell.execute_reply": "2021-09-15T11:35:29.979052Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "import numpy as np\n",
        "import os\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import cv2\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "BackGround = [255, 255, 255]\n",
        "road = [0, 0, 0]\n",
        "# COLOR_DICT = np.array([BackGround, road])\n",
        "one = [128, 128, 128]\n",
        "two = [128, 0, 0]\n",
        "three = [192, 192, 128]\n",
        "four = [255, 69, 0]\n",
        "five = [128, 64, 128]\n",
        "six = [60, 40, 222]\n",
        "seven = [128, 128, 0]\n",
        "eight = [192, 128, 128]\n",
        "nine = [64, 64, 128]\n",
        "ten = [64, 0, 128]\n",
        "eleven = [64, 64, 0]\n",
        "twelve = [0, 128, 192]\n",
        "COLOR_DICT = np.array([one, two,three,four,five,six,seven,eight,nine,ten,eleven,twelve])\n",
        "\n",
        "\n",
        "class data_preprocess:\n",
        "    def __init__(self, train_path=None, image_folder=None, label_folder=None,\n",
        "                 valid_path=None,valid_image_folder =None,valid_label_folder = None,\n",
        "                 test_path=None, save_path=None,\n",
        "                 img_rows=256, img_cols=256,\n",
        "                 flag_multi_class=False,\n",
        "                 num_classes = 2):\n",
        "        self.img_rows = img_rows\n",
        "        self.img_cols = img_cols\n",
        "        self.train_path = train_path\n",
        "        self.image_folder = image_folder\n",
        "        self.label_folder = label_folder\n",
        "        self.valid_path = valid_path\n",
        "        self.valid_image_folder = valid_image_folder\n",
        "        self.valid_label_folder = valid_label_folder\n",
        "        self.test_path = test_path\n",
        "        self.save_path = save_path\n",
        "        self.data_gen_args = dict(rotation_range=20,\n",
        "                                  width_shift_range=0.002,\n",
        "                                  shear_range=0.03,\n",
        "                                  zoom_range=0.005,\n",
        "                                  vertical_flip=True,\n",
        "                                  horizontal_flip=True,\n",
        "                                  fill_mode='nearest')\n",
        "        self.image_color_mode = \"rgb\"\n",
        "        self.label_color_mode = \"grayscale\"\n",
        "\n",
        "        self.flag_multi_class = flag_multi_class\n",
        "        self.num_class = num_classes\n",
        "        self.target_size = (256, 256)\n",
        "        self.img_type = 'png'\n",
        "\n",
        "    def adjustData(self, img, label):\n",
        "        if (self.flag_multi_class):\n",
        "            img = img / 255.\n",
        "            label = label[:, :, :, 0] if (len(label.shape) == 4) else label[:, :, 0]\n",
        "            new_label = np.zeros(label.shape + (self.num_class,))\n",
        "            for i in range(self.num_class):\n",
        "                new_label[label == i, i] = 1\n",
        "            label = new_label\n",
        "        elif (np.max(img) > 1):\n",
        "            #img = img / 255.\n",
        "            #label = label / 255.\n",
        "            #label[label >= 0.5] = 1\n",
        "            #label[label < 0.5] = 0\n",
        "            img2 =np.asarray(img)\n",
        "            label2 =np.asarray(label)\n",
        "            img2 =img2.astype('float32')\n",
        "            label2 =label2.astype('float32')\n",
        "            img2 /= 255.0\n",
        "            label2 /= 255.0\n",
        "            label2[label2 >= 0.5] = 1\n",
        "            label2[label2 < 0.5] = 0\n",
        "        return (img2, label2)\n",
        "\n",
        "    def trainGenerator(self, batch_size, image_save_prefix=\"image\", label_save_prefix=\"label\",\n",
        "                       save_to_dir=None, seed=7):\n",
        "        '''\n",
        "        can generate image and label at the same time\n",
        "        use the same seed for image_datagen and label_datagen to ensure the transformation for image and label is the same\n",
        "        if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
        "        '''\n",
        "        image_datagen = ImageDataGenerator(**self.data_gen_args)\n",
        "        label_datagen = ImageDataGenerator(**self.data_gen_args)\n",
        "        image_generator = image_datagen.flow_from_directory(\n",
        "            self.train_path,\n",
        "            classes=[self.image_folder],\n",
        "            class_mode=None,\n",
        "            color_mode=self.image_color_mode,\n",
        "            target_size=self.target_size,\n",
        "            batch_size=batch_size,\n",
        "            save_to_dir=save_to_dir,\n",
        "            save_prefix=image_save_prefix,\n",
        "            seed=seed)\n",
        "        label_generator = label_datagen.flow_from_directory(\n",
        "            self.train_path,\n",
        "            classes=[self.label_folder],\n",
        "            class_mode=None,\n",
        "            color_mode=self.label_color_mode,\n",
        "            target_size=self.target_size,\n",
        "            batch_size=batch_size,\n",
        "            save_to_dir=save_to_dir,\n",
        "            save_prefix=label_save_prefix,\n",
        "            seed=seed)\n",
        "        train_generator = zip(image_generator, label_generator)\n",
        "        for (img, label) in train_generator:\n",
        "            img, label = self.adjustData(img, label)\n",
        "            yield (img, label)\n",
        "\n",
        "    def testGenerator(self):\n",
        "        filenames = os.listdir(self.test_path)\n",
        "        for filename in filenames:\n",
        "            img = io.imread(os.path.join(self.test_path, filename), as_gray=False)\n",
        "            img = img / 255.\n",
        "            img = trans.resize(img, self.target_size, mode='constant')\n",
        "            img = np.reshape(img, img.shape + (1,)) if (not self.flag_multi_class) else img\n",
        "            img = np.reshape(img, (1,) + img.shape)\n",
        "            yield img\n",
        "\n",
        "    def validLoad(self, batch_size,seed=7):\n",
        "        image_datagen = ImageDataGenerator(rescale=0)\n",
        "        label_datagen = ImageDataGenerator(rescale=0)\n",
        "        image_generator = image_datagen.flow_from_directory(\n",
        "            self.valid_path,\n",
        "            classes=[self.valid_image_folder],\n",
        "            class_mode=None,\n",
        "            color_mode=self.image_color_mode,\n",
        "            target_size=self.target_size,\n",
        "            batch_size=batch_size,\n",
        "            seed=seed)\n",
        "        label_generator = label_datagen.flow_from_directory(\n",
        "            self.valid_path,\n",
        "            classes=[self.valid_label_folder],\n",
        "            class_mode=None,\n",
        "            color_mode=self.label_color_mode,\n",
        "            target_size=self.target_size,\n",
        "            batch_size=batch_size,\n",
        "            seed=seed)\n",
        "        train_generator = zip(image_generator, label_generator)\n",
        "        for (img, label) in train_generator:\n",
        "            img, label = self.adjustData(img, label)\n",
        "            yield (img, label)\n",
        "        # return imgs,labels\n",
        "\n",
        "    def saveResult(self, npyfile, size, name,threshold=80):\n",
        "        for i, item in enumerate(npyfile):\n",
        "            img = item\n",
        "            img_std = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
        "            if self.flag_multi_class:\n",
        "                for row in range(len(img)):\n",
        "                    for col in range(len(img[row])):\n",
        "                        num = np.argmax(img[row][col])\n",
        "                        img_std[row][col] = COLOR_DICT[num]\n",
        "            else:\n",
        "                for k in range(len(img)):\n",
        "                    for j in range(len(img[k])):\n",
        "                        num = img[k][j]\n",
        "                        if num < (threshold/255.0):\n",
        "                            img_std[k][j] = road\n",
        "                        else:\n",
        "                            img_std[k][j] = BackGround\n",
        "            img_std = cv2.resize(img_std, size, interpolation=cv2.INTER_CUBIC)\n",
        "            cv2.imwrite(os.path.join(self.save_path, (\"%s_predict.\" + self.img_type) % (name)), img_std)"
      ],
      "metadata": {
        "id": "iTf8lIwLjXrS",
        "execution": {
          "iopub.status.busy": "2021-09-15T11:35:29.985021Z",
          "iopub.execute_input": "2021-09-15T11:35:29.985299Z",
          "iopub.status.idle": "2021-09-15T11:35:30.412361Z",
          "shell.execute_reply.started": "2021-09-15T11:35:29.985272Z",
          "shell.execute_reply": "2021-09-15T11:35:30.411248Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####  Metrics\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.losses import binary_crossentropy\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "def dice_coeff(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return score\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dice_coeff(y_true, y_pred)\n",
        "    return loss\n",
        "def iou_coeff(y_true, y_pred):\n",
        "    smooth=1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    union=K.sum(y_true_f) + K.sum(y_pred_f)-intersection\n",
        "    mvalue=(intersection+smooth)/(union+smooth)\n",
        "    return mvalue\n",
        "def precision(y_true, y_pred):\n",
        "    \"\"\"Precision metric.\n",
        "\n",
        "    Only computes a batch-wise average of precision.\n",
        "\n",
        "    Computes the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "def ACL5(y_true, y_pred): \n",
        "\n",
        "\t#y_pred = K.cast(y_pred, dtype = 'float64')\n",
        "\n",
        "\tprint(K.int_shape(y_pred))\n",
        "\n",
        "\tx = y_pred[:,1:,:,:] - y_pred[:,:-1,:,:] # horizontal and vertical directions \n",
        "\ty = y_pred[:,:,1:,:] - y_pred[:,:,:-1,:]\n",
        "\n",
        "\tdelta_x = x[:,1:,:-2,:]**2\n",
        "\tdelta_y = y[:,:-2,1:,:]**2\n",
        "\tdelta_u = K.abs(delta_x + delta_y) \n",
        "\n",
        "\tepsilon = 0.00000001 # where is a parameter to avoid square root is zero in practice.\n",
        "\tw = 1####\n",
        "\tlenth = w * K.sum(K.sqrt(delta_u + epsilon)) # equ.(11) in the paper\n",
        "\n",
        "\n",
        "\tC_1 = np.ones((256, 256))\n",
        "\tC_2 = np.zeros((256, 256))\n",
        "\n",
        "\tregion_in = K.abs(K.sum( y_pred[:,:,:,0] * ((y_true[:,:,:,0] - C_1)**2) ) ) # equ.(12) in the paper\n",
        "\tregion_out = K.abs(K.sum( (1-y_pred[:,:,:,0]) * ((y_true[:,:,:,0] - C_2)**2) )) # equ.(12) in the paper\n",
        "\n",
        "\tlambdaP = 5 # lambda parameter could be various.\n",
        "\t\n",
        "\tloss =  lenth + lambdaP * ((region_in) + (region_out)) \n",
        "\n",
        "\treturn loss\n",
        "def ACL5_mod(y_true, y_pred): \n",
        "\n",
        "\t#y_pred = K.cast(y_pred, dtype = 'float64')\n",
        "\n",
        "\tprint(K.int_shape(y_pred))\n",
        "\n",
        "\tx = y_pred[:,1:,:,:] - y_pred[:,:-1,:,:] # horizontal and vertical directions \n",
        "\ty = y_pred[:,:,1:,:] - y_pred[:,:,:-1,:]\n",
        "\n",
        "\tdelta_x = x[:,1:,:-2,:]**2\n",
        "\tdelta_y = y[:,:-2,1:,:]**2\n",
        "\tdelta_u = K.abs(delta_x + delta_y) \n",
        "\n",
        "\tepsilon = 0.00000001 # where is a parameter to avoid square root is zero in practice.\n",
        "\tw = 1####\n",
        "\tlenth = w * K.sum(K.sqrt(delta_u + epsilon)) # equ.(11) in the paper\n",
        "\n",
        "\n",
        "\tC_1 = np.ones((256, 256))\n",
        "\tC_2 = np.zeros((256, 256))\n",
        "\n",
        "\tregion_in = K.abs(K.sum( y_pred[:,:,:,0] * ((y_true[:,:,:,0] - C_1)**2) ) ) # equ.(12) in the paper\n",
        "\tregion_out = K.abs(K.sum( (1-y_pred[:,:,:,0]) * ((y_true[:,:,:,0] - C_2)**2) )) # equ.(12) in the paper\n",
        "\n",
        "\tlambdaP = 5 # lambda parameter could be various.\n",
        "\t\n",
        "\tloss =  lenth + lambdaP * ((region_in) + (region_out*1.4)) \n",
        "\n",
        "\treturn loss"
      ],
      "metadata": {
        "id": "VVdzJaSWjXra",
        "execution": {
          "iopub.status.busy": "2021-09-15T11:35:30.413831Z",
          "iopub.execute_input": "2021-09-15T11:35:30.414163Z",
          "iopub.status.idle": "2021-09-15T11:35:30.444633Z",
          "shell.execute_reply.started": "2021-09-15T11:35:30.414123Z",
          "shell.execute_reply": "2021-09-15T11:35:30.443392Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iwu9rjDFjXrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta = 0.25\n",
        "alpha = 0.25\n",
        "gamma = 2\n",
        "epsilon = 1e-5\n",
        "smooth = 1\n",
        "\n",
        "def tversky_index( y_true, y_pred):\n",
        "    y_true_pos = K.flatten(y_true)\n",
        "    y_pred_pos = K.flatten(y_pred)\n",
        "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
        "    false_neg = K.sum(y_true_pos * (1 - y_pred_pos))\n",
        "    false_pos = K.sum((1 - y_true_pos) * y_pred_pos)\n",
        "    alpha = 0.7\n",
        "    return (true_pos + smooth) / (true_pos + alpha * false_neg + (\n",
        "                1 - alpha) * false_pos + smooth)\n",
        "\n",
        "def tversky_loss( y_true, y_pred):\n",
        "    return 1 - tversky_index(y_true, y_pred)\n",
        "\n",
        "def focal_tversky( y_true, y_pred):\n",
        "    pt_1 = tversky_index(y_true, y_pred)\n",
        "    gamma = 0.75\n",
        "    return K.pow((1 - pt_1), gamma)\n",
        "\n",
        "def dsc(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return score\n",
        "\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "  intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
        "  union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
        "  dice = K.mean((2. * intersection + smooth)/(union + smooth), axis=0)\n",
        "  return dice\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dsc(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "-YuW43lejXrd",
        "execution": {
          "iopub.status.busy": "2021-09-15T11:35:30.446528Z",
          "iopub.execute_input": "2021-09-15T11:35:30.447161Z",
          "iopub.status.idle": "2021-09-15T11:35:30.468785Z",
          "shell.execute_reply.started": "2021-09-15T11:35:30.447037Z",
          "shell.execute_reply": "2021-09-15T11:35:30.467795Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env SM_FRAMEWORK=tf.keras"
      ],
      "metadata": {
        "id": "kr5nP8ItjXre",
        "outputId": "48e77d7c-c144-4f17-e726-e4b36dce7171",
        "execution": {
          "iopub.status.busy": "2021-09-15T11:35:30.470528Z",
          "iopub.execute_input": "2021-09-15T11:35:30.470974Z",
          "iopub.status.idle": "2021-09-15T11:35:30.486681Z",
          "shell.execute_reply.started": "2021-09-15T11:35:30.470928Z",
          "shell.execute_reply": "2021-09-15T11:35:30.485605Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "env: SM_FRAMEWORK=tf.keras\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation_models\n",
        "import segmentation_models\n",
        "from segmentation_models.losses import bce_jaccard_loss"
      ],
      "metadata": {
        "id": "KMTFbTKtjXrf",
        "outputId": "2bd1e0fe-2f4f-479d-e8e6-b255673c5ad3",
        "execution": {
          "iopub.status.busy": "2021-09-15T11:35:30.488962Z",
          "iopub.execute_input": "2021-09-15T11:35:30.489215Z",
          "iopub.status.idle": "2021-09-15T11:35:42.339297Z",
          "shell.execute_reply.started": "2021-09-15T11:35:30.489188Z",
          "shell.execute_reply": "2021-09-15T11:35:42.337381Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting segmentation_models\n  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\nCollecting image-classifiers==1.0.0\n  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\nCollecting efficientnet==1.0.0\n  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\nCollecting keras-applications<=1.0.8,>=1.0.7\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[K     |████████████████████████████████| 50 kB 1.2 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.0.0->segmentation_models) (0.18.3)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (2.10.0)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.19.5)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.15.0)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2021.8.30)\nRequirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.9.0)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.1.1)\nRequirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.5)\nRequirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (8.3.1)\nRequirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.7.1)\nRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.4.3)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.8.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (0.10.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.7)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation_models) (5.0.9)\nInstalling collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models\nSuccessfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nSegmentation Models: using `tf.keras` framework.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ACL5_bce_jaccard_loss(y_true, y_pred):\n",
        "    loss = ACL5(y_true, y_pred) + bce_jaccard_loss(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def focal_tversky_bce_jaccard_loss(y_true, y_pred):\n",
        "    loss = focal_tversky(y_true, y_pred) + 2*bce_jaccard_loss(y_true, y_pred)\n",
        "    return loss\n",
        "\n"
      ],
      "metadata": {
        "id": "IVcpwi4hjXrg",
        "execution": {
          "iopub.status.busy": "2021-09-15T11:35:42.343849Z",
          "iopub.execute_input": "2021-09-15T11:35:42.344315Z",
          "iopub.status.idle": "2021-09-15T11:35:42.364745Z",
          "shell.execute_reply.started": "2021-09-15T11:35:42.344276Z",
          "shell.execute_reply": "2021-09-15T11:35:42.356916Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "from tensorflow.keras.layers import Conv2D , BatchNormalization , Activation , MaxPool2D , Input , Dropout , ZeroPadding2D , Conv2DTranspose , Concatenate\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras.applications import InceptionResNetV2"
      ],
      "metadata": {
        "id": "eDJ9CtzQjXrh",
        "execution": {
          "iopub.status.busy": "2021-09-15T11:35:42.368754Z",
          "iopub.execute_input": "2021-09-15T11:35:42.369689Z",
          "iopub.status.idle": "2021-09-15T11:35:42.380183Z",
          "shell.execute_reply.started": "2021-09-15T11:35:42.369623Z",
          "shell.execute_reply": "2021-09-15T11:35:42.377629Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DeepLabV3Plus"
      ],
      "metadata": {
        "id": "ccYNxPZwjXri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SU-bbp33jXrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, UpSampling2D\n",
        "from tensorflow.keras.layers import AveragePooling2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "\"\"\" Atrous Spatial Pyramid Pooling \"\"\"\n",
        "def ASPP(inputs):\n",
        "    shape = inputs.shape\n",
        "\n",
        "    y_pool = AveragePooling2D(pool_size=(shape[1], shape[2]), name='average_pooling')(inputs)\n",
        "    y_pool = Conv2D(filters=256, kernel_size=1, padding='same', use_bias=False)(y_pool)\n",
        "    y_pool = BatchNormalization(name=f'bn_1')(y_pool)\n",
        "    y_pool = Activation('relu', name=f'relu_1')(y_pool)\n",
        "    y_pool = UpSampling2D((shape[1], shape[2]), interpolation=\"bilinear\")(y_pool)\n",
        "\n",
        "    y_1 = Conv2D(filters=256, kernel_size=1, dilation_rate=1, padding='same', use_bias=False)(inputs)\n",
        "    y_1 = BatchNormalization()(y_1)\n",
        "    y_1 = Activation('relu')(y_1)\n",
        "\n",
        "    y_6 = Conv2D(filters=256, kernel_size=3, dilation_rate=6, padding='same', use_bias=False)(inputs)\n",
        "    y_6 = BatchNormalization()(y_6)\n",
        "    y_6 = Activation('relu')(y_6)\n",
        "\n",
        "    y_12 = Conv2D(filters=256, kernel_size=3, dilation_rate=12, padding='same', use_bias=False)(inputs)\n",
        "    y_12 = BatchNormalization()(y_12)\n",
        "    y_12 = Activation('relu')(y_12)\n",
        "\n",
        "    y_18 = Conv2D(filters=256, kernel_size=3, dilation_rate=18, padding='same', use_bias=False)(inputs)\n",
        "    y_18 = BatchNormalization()(y_18)\n",
        "    y_18 = Activation('relu')(y_18)\n",
        "\n",
        "    y = Concatenate()([y_pool, y_1, y_6, y_12, y_18])\n",
        "\n",
        "    y = Conv2D(filters=256, kernel_size=1, dilation_rate=1, padding='same', use_bias=False)(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    return y\n",
        "\n",
        "def DeepLabV3Plus(shape):\n",
        "    \"\"\" Inputs \"\"\"\n",
        "    inputs = Input(shape)\n",
        "\n",
        "    \"\"\" Pre-trained ResNet50 \"\"\"\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=inputs)\n",
        "\n",
        "    \"\"\" Pre-trained ResNet50 Output \"\"\"\n",
        "    image_features = base_model.get_layer('conv4_block6_out').output\n",
        "    x_a = ASPP(image_features)\n",
        "    x_a = UpSampling2D((4, 4), interpolation=\"bilinear\")(x_a)\n",
        "\n",
        "    \"\"\" Get low-level features \"\"\"\n",
        "    x_b = base_model.get_layer('conv2_block2_out').output\n",
        "    x_b = Conv2D(filters=48, kernel_size=1, padding='same', use_bias=False)(x_b)\n",
        "    x_b = BatchNormalization()(x_b)\n",
        "    x_b = Activation('relu')(x_b)\n",
        "\n",
        "    x = Concatenate()([x_a, x_b])\n",
        "\n",
        "    x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu',use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu', use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = UpSampling2D((4, 4), interpolation=\"bilinear\")(x)\n",
        "\n",
        "    \"\"\" Outputs \"\"\"\n",
        "    x = Conv2D(2, kernel_size=(3, 3),activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    x = Conv2D(1, (1, 1), name='output_layer')(x)\n",
        "    x = Activation('sigmoid')(x)\n",
        "\n",
        "    \"\"\" Model \"\"\"\n",
        "    model = Model(inputs=inputs, outputs=x)\n",
        "    return model\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "kFchkooujXrk",
        "execution": {
          "iopub.status.busy": "2021-09-15T11:35:42.383945Z",
          "iopub.execute_input": "2021-09-15T11:35:42.385527Z",
          "iopub.status.idle": "2021-09-15T11:35:42.428647Z",
          "shell.execute_reply.started": "2021-09-15T11:35:42.385438Z",
          "shell.execute_reply": "2021-09-15T11:35:42.426972Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "   \n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "\n",
        "#path to images\n",
        "train_path = \"../input/training/training\"\n",
        "image_folder = \"images\"\n",
        "label_folder = \"label\"\n",
        "valid_path =  \"../input/validation/Validation\"\n",
        "valid_image_folder =\"images\"\n",
        "valid_label_folder = \"label\"\n",
        "log_filepath = './log'\n",
        "flag_multi_class = False\n",
        "num_classes = 2\n",
        "dp = data_preprocess(train_path=train_path,image_folder=image_folder,label_folder=label_folder,\n",
        "                     valid_path=valid_path,valid_image_folder=valid_image_folder,valid_label_folder=valid_label_folder,\n",
        "                     flag_multi_class=flag_multi_class,\n",
        "                     num_classes=num_classes)\n",
        "\n",
        "train_data = dp.trainGenerator(batch_size=2)\n",
        "valid_data = dp.validLoad(batch_size=1)\n",
        "test_data = dp.testGenerator()\n",
        "lrate = 7.00E-05 \n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, Dense, Multiply, AveragePooling2D, UpSampling2D\n",
        "if __name__ == \"__main__\":\n",
        "    input_shape = (256, 256, 3)\n",
        "    model = DeepLabV3Plus(input_shape)\n",
        "    model.summary()\n",
        "    model_checkpoint1 = keras.callbacks.ModelCheckpoint('Res2Net.hdf5', monitor='val_dice_loss',verbose=1,mode='min',save_best_only=True)\n",
        "    csv_logger = CSVLogger('trainingRes2Net.log', append=True, separator=';')\n",
        "    model.compile(optimizer=Adam(lr=lrate), loss=bce_jaccard_loss , metrics=[ACL5 ,bce_jaccard_loss , dice_coef , dsc,  dice_loss,iou_coeff,precision,recall])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z73b0ddqjXrl",
        "outputId": "a89c753e-139b-4b08-a496-19df793d5048",
        "execution": {
          "iopub.status.busy": "2021-09-15T11:35:42.431718Z",
          "iopub.execute_input": "2021-09-15T11:35:42.432358Z",
          "iopub.status.idle": "2021-09-15T11:35:50.491194Z",
          "shell.execute_reply.started": "2021-09-15T11:35:42.432296Z",
          "shell.execute_reply": "2021-09-15T11:35:50.487162Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "2021-09-15 11:35:42.526322: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-09-15 11:35:42.532412: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n2021-09-15 11:35:42.600020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-15 11:35:42.601395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\ncoreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n2021-09-15 11:35:42.601561: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-15 11:35:42.650701: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-15 11:35:42.651285: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-15 11:35:42.677049: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-09-15 11:35:42.721260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-09-15 11:35:42.769195: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-09-15 11:35:42.786670: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-09-15 11:35:42.790605: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-09-15 11:35:42.791153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-15 11:35:42.792599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-15 11:35:42.795546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-09-15 11:35:42.797238: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2021-09-15 11:35:42.797767: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-09-15 11:35:42.798384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-15 11:35:42.799609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\ncoreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n2021-09-15 11:35:42.799777: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-15 11:35:42.799980: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-15 11:35:42.800041: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-15 11:35:42.800088: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-09-15 11:35:42.800131: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-09-15 11:35:42.800174: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-09-15 11:35:42.800223: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-09-15 11:35:42.800266: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-09-15 11:35:42.800510: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-15 11:35:42.801848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-15 11:35:42.802859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-09-15 11:35:42.804630: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-15 11:35:45.213543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n2021-09-15 11:35:45.213699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n2021-09-15 11:35:45.213723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n2021-09-15 11:35:45.217940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-15 11:35:45.220522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-15 11:35:45.222864: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-15 11:35:45.224470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94773248/94765736 [==============================] - 1s 0us/step\nModel: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n__________________________________________________________________________________________________\nconv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    \n__________________________________________________________________________________________________\nconv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n__________________________________________________________________________________________________\nconv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n__________________________________________________________________________________________________\nconv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n__________________________________________________________________________________________________\npool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n__________________________________________________________________________________________________\npool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n__________________________________________________________________________________________________\nconv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n__________________________________________________________________________________________________\nconv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n__________________________________________________________________________________________________\nconv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n                                                                 conv2_block1_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n__________________________________________________________________________________________________\nconv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n                                                                 conv2_block2_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n__________________________________________________________________________________________________\nconv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n                                                                 conv2_block3_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n__________________________________________________________________________________________________\nconv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n                                                                 conv3_block1_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n__________________________________________________________________________________________________\nconv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n                                                                 conv3_block2_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n__________________________________________________________________________________________________\nconv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n                                                                 conv3_block3_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n__________________________________________________________________________________________________\nconv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n                                                                 conv3_block4_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n                                                                 conv4_block1_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n                                                                 conv4_block2_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n                                                                 conv4_block3_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n                                                                 conv4_block4_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n                                                                 conv4_block5_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n                                                                 conv4_block6_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n__________________________________________________________________________________________________\naverage_pooling (AveragePooling (None, 1, 1, 1024)   0           conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 1, 1, 256)    262144      average_pooling[0][0]            \n__________________________________________________________________________________________________\nbn_1 (BatchNormalization)       (None, 1, 1, 256)    1024        conv2d[0][0]                     \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 16, 16, 256)  262144      conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 16, 16, 256)  2359296     conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 16, 16, 256)  2359296     conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 16, 16, 256)  2359296     conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nrelu_1 (Activation)             (None, 1, 1, 256)    0           bn_1[0][0]                       \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 16, 16, 256)  1024        conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 16, 16, 256)  1024        conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 16, 16, 256)  1024        conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 16, 16, 256)  1024        conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nup_sampling2d (UpSampling2D)    (None, 16, 16, 256)  0           relu_1[0][0]                     \n__________________________________________________________________________________________________\nactivation (Activation)         (None, 16, 16, 256)  0           batch_normalization[0][0]        \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 16, 16, 256)  0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 16, 16, 256)  0           batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 16, 16, 256)  0           batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 16, 16, 1280) 0           up_sampling2d[0][0]              \n                                                                 activation[0][0]                 \n                                                                 activation_1[0][0]               \n                                                                 activation_2[0][0]               \n                                                                 activation_3[0][0]               \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 16, 16, 256)  327680      concatenate[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 16, 16, 256)  1024        conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 64, 64, 48)   12288       conv2_block2_out[0][0]           \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 16, 16, 256)  0           batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\nbatch_normalization_5 (BatchNor (None, 64, 64, 48)   192         conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nup_sampling2d_1 (UpSampling2D)  (None, 64, 64, 256)  0           activation_4[0][0]               \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 64, 64, 48)   0           batch_normalization_5[0][0]      \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 64, 64, 304)  0           up_sampling2d_1[0][0]            \n                                                                 activation_5[0][0]               \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 64, 64, 256)  700416      concatenate_1[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_6 (BatchNor (None, 64, 64, 256)  1024        conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nactivation_6 (Activation)       (None, 64, 64, 256)  0           batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 64, 64, 256)  589824      activation_6[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_7 (BatchNor (None, 64, 64, 256)  1024        conv2d_8[0][0]                   \n__________________________________________________________________________________________________\nactivation_7 (Activation)       (None, 64, 64, 256)  0           batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\nup_sampling2d_2 (UpSampling2D)  (None, 256, 256, 256 0           activation_7[0][0]               \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 256, 256, 2)  4610        up_sampling2d_2[0][0]            \n__________________________________________________________________________________________________\noutput_layer (Conv2D)           (None, 256, 256, 1)  3           conv2d_9[0][0]                   \n__________________________________________________________________________________________________\nactivation_8 (Activation)       (None, 256, 256, 1)  0           output_layer[0][0]               \n==================================================================================================\nTotal params: 17,834,565\nTrainable params: 17,799,781\nNon-trainable params: 34,784\n__________________________________________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Reshape, Permute, Activation, Input, \\\n",
        "    add, multiply\n",
        "from keras.layers import concatenate, core, Dropout\n",
        "from keras.models import Model\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.core import Lambda\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def up_and_concate(down_layer, layer, data_format='channels_first'):\n",
        "    if data_format == 'channels_first':\n",
        "        in_channel = down_layer.get_shape().as_list()[1]\n",
        "    else:\n",
        "        in_channel = down_layer.get_shape().as_list()[3]\n",
        "\n",
        "    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n",
        "    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n",
        "\n",
        "    if data_format == 'channels_first':\n",
        "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n",
        "    else:\n",
        "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
        "\n",
        "    concate = my_concat([up, layer])\n",
        "\n",
        "    return concate\n",
        "\n",
        "\n",
        "def attention_up_and_concate(down_layer, layer, data_format='channels_first'):\n",
        "    if data_format == 'channels_first':\n",
        "        in_channel = down_layer.get_shape().as_list()[1]\n",
        "    else:\n",
        "        in_channel = down_layer.get_shape().as_list()[3]\n",
        "\n",
        "    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n",
        "    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n",
        "\n",
        "    layer = attention_block_2d(x=layer, g=up, inter_channel=in_channel // 4, data_format=data_format)\n",
        "\n",
        "    if data_format == 'channels_first':\n",
        "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n",
        "    else:\n",
        "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
        "\n",
        "    concate = my_concat([up, layer])\n",
        "    return concate\n",
        "\n",
        "\n",
        "def attention_block_2d(x, g, inter_channel, data_format='channels_first'):\n",
        "    # theta_x(?,g_height,g_width,inter_channel)\n",
        "\n",
        "    theta_x = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(x)\n",
        "\n",
        "    # phi_g(?,g_height,g_width,inter_channel)\n",
        "\n",
        "    phi_g = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(g)\n",
        "\n",
        "    # f(?,g_height,g_width,inter_channel)\n",
        "\n",
        "    f = Activation('relu')(add([theta_x, phi_g]))\n",
        "\n",
        "    # psi_f(?,g_height,g_width,1)\n",
        "\n",
        "    psi_f = Conv2D(1, [1, 1], strides=[1, 1], data_format=data_format)(f)\n",
        "\n",
        "    rate = Activation('sigmoid')(psi_f)\n",
        "\n",
        "    # rate(?,x_height,x_width)\n",
        "\n",
        "    # att_x(?,x_height,x_width,x_channel)\n",
        "\n",
        "    att_x = multiply([x, rate])\n",
        "\n",
        "    return att_x\n",
        "\n",
        "\n",
        "def res_block(input_layer, out_n_filters, batch_normalization=False, kernel_size=[3, 3], stride=[1, 1],\n",
        "\n",
        "              padding='same', data_format='channels_first'):\n",
        "    if data_format == 'channels_first':\n",
        "        input_n_filters = input_layer.get_shape().as_list()[1]\n",
        "    else:\n",
        "        input_n_filters = input_layer.get_shape().as_list()[3]\n",
        "\n",
        "    layer = input_layer\n",
        "    for i in range(2):\n",
        "        layer = Conv2D(out_n_filters // 4, [1, 1], strides=stride, padding=padding, data_format=data_format)(layer)\n",
        "        if batch_normalization:\n",
        "            layer = BatchNormalization()(layer)\n",
        "        layer = Activation('relu')(layer)\n",
        "        layer = Conv2D(out_n_filters // 4, kernel_size, strides=stride, padding=padding, data_format=data_format)(layer)\n",
        "        layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(layer)\n",
        "\n",
        "    if out_n_filters != input_n_filters:\n",
        "        skip_layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(\n",
        "            input_layer)\n",
        "    else:\n",
        "        skip_layer = input_layer\n",
        "    out_layer = add([layer, skip_layer])\n",
        "    return out_layer\n",
        "\n",
        "\n",
        "# Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net)\n",
        "def rec_res_block(input_layer, out_n_filters, batch_normalization=False, kernel_size=[3, 3], stride=[1, 1],\n",
        "\n",
        "                  padding='same', data_format='channels_first'):\n",
        "    if data_format == 'channels_first':\n",
        "        input_n_filters = input_layer.get_shape().as_list()[1]\n",
        "    else:\n",
        "        input_n_filters = input_layer.get_shape().as_list()[3]\n",
        "\n",
        "    if out_n_filters != input_n_filters:\n",
        "        skip_layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(\n",
        "            input_layer)\n",
        "    else:\n",
        "        skip_layer = input_layer\n",
        "\n",
        "    layer = skip_layer\n",
        "    for j in range(2):\n",
        "\n",
        "        for i in range(2):\n",
        "            if i == 0:\n",
        "\n",
        "                layer1 = Conv2D(out_n_filters, kernel_size, strides=stride, padding=padding, data_format=data_format)(\n",
        "                    layer)\n",
        "                if batch_normalization:\n",
        "                    layer1 = BatchNormalization()(layer1)\n",
        "                layer1 = Activation('relu')(layer1)\n",
        "            layer1 = Conv2D(out_n_filters, kernel_size, strides=stride, padding=padding, data_format=data_format)(\n",
        "                add([layer1, layer]))\n",
        "            if batch_normalization:\n",
        "                layer1 = BatchNormalization()(layer1)\n",
        "            layer1 = Activation('relu')(layer1)\n",
        "        layer = layer1\n",
        "\n",
        "    out_layer = add([layer, skip_layer])\n",
        "    return out_layer\n",
        "\n",
        "########################################################################################################\n",
        "# Define the neural network\n",
        "def unet(img_w, img_h, n_label, data_format='channels_first'):\n",
        "    inputs = Input((3, img_w, img_h))\n",
        "    x = inputs\n",
        "    depth = 4\n",
        "    features = 64\n",
        "    skips = []\n",
        "    for i in range(depth):\n",
        "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "        skips.append(x)\n",
        "        x = MaxPooling2D((2, 2), data_format= data_format)(x)\n",
        "        features = features * 2\n",
        "\n",
        "    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "\n",
        "    for i in reversed(range(depth)):\n",
        "        features = features // 2\n",
        "        # attention_up_and_concate(x,[skips[i])\n",
        "        x = UpSampling2D(size=(2, 2), data_format=data_format)(x)\n",
        "        x = concatenate([skips[i], x], axis=1)\n",
        "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "\n",
        "    conv6 = Conv2D(n_label, (1, 1), padding='same', data_format=data_format)(x)\n",
        "    conv7 = core.Activation('sigmoid')(conv6)\n",
        "    model = Model(inputs=inputs, outputs=conv7)\n",
        "\n",
        "    #model.compile(optimizer=Adam(lr=1e-5), loss=[focal_loss()], metrics=['accuracy', dice_coef])\n",
        "    return model\n",
        "\n",
        "\n",
        "########################################################################################################\n",
        "#Attention U-Net\n",
        "def att_unet(img_w, img_h, n_label, data_format='channels_first'):\n",
        "    inputs = Input((3, img_w, img_h))\n",
        "    x = inputs\n",
        "    depth = 4\n",
        "    features = 64\n",
        "    skips = []\n",
        "    for i in range(depth):\n",
        "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "        skips.append(x)\n",
        "        x = MaxPooling2D((2, 2), data_format='channels_first')(x)\n",
        "        features = features * 2\n",
        "\n",
        "    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "\n",
        "    for i in reversed(range(depth)):\n",
        "        features = features // 2\n",
        "        x = attention_up_and_concate(x, skips[i], data_format=data_format)\n",
        "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "\n",
        "    conv6 = Conv2D(n_label, (1, 1), padding='same', data_format=data_format)(x)\n",
        "    conv7 = core.Activation('sigmoid')(conv6)\n",
        "    model = Model(inputs=inputs, outputs=conv7)\n",
        "\n",
        "    #model.compile(optimizer=Adam(lr=1e-5), loss=[focal_loss()], metrics=['accuracy', dice_coef])\n",
        "    return model\n",
        "\n",
        "\n",
        "########################################################################################################\n",
        "#Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net)\n",
        "def r2_unet(img_w, img_h, n_label, data_format='channels_first'):\n",
        "    inputs = Input((3, img_w, img_h))\n",
        "    x = inputs\n",
        "    depth = 4\n",
        "    features = 64\n",
        "    skips = []\n",
        "    for i in range(depth):\n",
        "        x = rec_res_block(x, features, data_format=data_format)\n",
        "        skips.append(x)\n",
        "        x = MaxPooling2D((2, 2), data_format=data_format)(x)\n",
        "\n",
        "        features = features * 2\n",
        "\n",
        "    x = rec_res_block(x, features, data_format=data_format)\n",
        "\n",
        "    for i in reversed(range(depth)):\n",
        "        features = features // 2\n",
        "        x = up_and_concate(x, skips[i], data_format=data_format)\n",
        "        x = rec_res_block(x, features, data_format=data_format)\n",
        "\n",
        "    conv6 = Conv2D(n_label, (1, 1), padding='same', data_format=data_format)(x)\n",
        "    conv7 = core.Activation('sigmoid')(conv6)\n",
        "    model = Model(inputs=inputs, outputs=conv7)\n",
        "    #model.compile(optimizer=Adam(lr=1e-6), loss=[dice_coef_loss], metrics=['accuracy', dice_coef])\n",
        "    return model\n",
        "\n",
        "\n",
        "########################################################################################################\n",
        "#Attention R2U-Net\n",
        "def att_r2_unet(img_w, img_h, n_label, data_format='channels_last'):\n",
        "    inputs = Input((img_w, img_h , 3))\n",
        "    x = inputs\n",
        "    depth = 4\n",
        "    features = 64\n",
        "    skips = []\n",
        "    for i in range(depth):\n",
        "        x = rec_res_block(x, features, data_format=data_format)\n",
        "        skips.append(x)\n",
        "        x = MaxPooling2D((2, 2), data_format=data_format)(x)\n",
        "\n",
        "        features = features * 2\n",
        "\n",
        "    x = rec_res_block(x, features, data_format=data_format)\n",
        "\n",
        "    for i in reversed(range(depth)):\n",
        "        features = features // 2\n",
        "        x = attention_up_and_concate(x, skips[i], data_format=data_format)\n",
        "        x = rec_res_block(x, features, data_format=data_format)\n",
        "        \n",
        "    x = Conv2D( 2 , (3, 3), padding='same', data_format=data_format)(x)\n",
        "    conv6 = Conv2D(n_label, (1, 1), padding='same', data_format=data_format)(x)\n",
        "    conv7 = core.Activation('sigmoid')(conv6)\n",
        "    model = Model(inputs=inputs, outputs=conv7)\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_shape = (256, 256, 3)\n",
        "    model = att_r2_unet(256, 256, 1)\n",
        "    model.summary()\n",
        "    model_checkpoint1 = keras.callbacks.ModelCheckpoint('att_r2_unet.hdf5', monitor='val_dice_loss',verbose=1,mode='min',save_best_only=True)\n",
        "    csv_logger = CSVLogger('trainingRes2Net.log', append=True, separator=';')\n",
        "    model.compile(optimizer=Adam(lr=lrate), loss=ACL5 , metrics=[ACL5 ,bce_jaccard_loss , dice_coef , dsc,  dice_loss,iou_coeff,precision,recall])\n",
        "\n"
      ],
      "metadata": {
        "id": "Axxwhj8_Smb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(train_data,\n",
        "                              steps_per_epoch=1912,epochs=40,\n",
        "                              validation_steps=207,\n",
        "                              validation_data=valid_data,\n",
        "                              callbacks=[model_checkpoint1,csv_logger])"
      ],
      "metadata": {
        "id": "DJLOnaYejXrm",
        "outputId": "deabad6b-2cf2-449a-8124-ea3bd1e2a072",
        "execution": {
          "iopub.status.busy": "2021-09-15T11:35:50.493004Z",
          "iopub.execute_input": "2021-09-15T11:35:50.493484Z",
          "iopub.status.idle": "2021-09-15T13:54:10.680551Z",
          "shell.execute_reply.started": "2021-09-15T11:35:50.493435Z",
          "shell.execute_reply": "2021-09-15T13:54:10.678367Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Found 600 images belonging to 1 classes.\nFound 600 images belonging to 1 classes.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2021-09-15 11:35:51.275096: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n2021-09-15 11:35:51.281037: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1/40\n(None, 256, 256, 1)\n(None, 256, 256, 1)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2021-09-15 11:36:03.102654: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-09-15 11:36:09.058492: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-15 11:36:10.009405: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "1912/1912 [==============================] - ETA: 0s - loss: 0.9963 - ACL5: 113933.4538 - binary_crossentropy_plus_jaccard_loss: 0.9963 - dice_coef: 0.2962 - dsc: 0.3089 - dice_loss: 0.6911 - iou_coeff: 0.2263 - precision: 0.6009 - recall: 0.6968 - ETA: 12s Found 200 images belonging to 1 classes.\nFound 200 images belonging to 1 classes.\n(None, 256, 256, 1)\n1912/1912 [==============================] - 251s 121ms/step - loss: 0.9961 - ACL5: 113896.5064 - binary_crossentropy_plus_jaccard_loss: 0.9961 - dice_coef: 0.2963 - dsc: 0.3090 - dice_loss: 0.6910 - iou_coeff: 0.2264 - precision: 0.6010 - recall: 0.6968 - val_loss: 0.4185 - val_ACL5: 2089.7188 - val_binary_crossentropy_plus_jaccard_loss: 0.4185 - val_dice_coef: 0.7212 - val_dsc: 0.7212 - val_dice_loss: 0.2788 - val_iou_coeff: 0.6064 - val_precision: 0.7586 - val_recall: 0.7311\n\nEpoch 00001: val_dice_loss improved from inf to 0.27877, saving model to Res2Net.hdf5\nEpoch 2/40\n1912/1912 [==============================] - 208s 109ms/step - loss: 0.3477 - ACL5: 3838.9545 - binary_crossentropy_plus_jaccard_loss: 0.3477 - dice_coef: 0.7619 - dsc: 0.8002 - dice_loss: 0.1998 - iou_coeff: 0.6765 - precision: 0.8159 - recall: 0.8170 - val_loss: 0.4236 - val_ACL5: 2015.3877 - val_binary_crossentropy_plus_jaccard_loss: 0.4236 - val_dice_coef: 0.7158 - val_dsc: 0.7158 - val_dice_loss: 0.2842 - val_iou_coeff: 0.6096 - val_precision: 0.7581 - val_recall: 0.6962\n\nEpoch 00002: val_dice_loss did not improve from 0.27877\nEpoch 3/40\n1912/1912 [==============================] - 203s 106ms/step - loss: 0.3278 - ACL5: 3549.6161 - binary_crossentropy_plus_jaccard_loss: 0.3278 - dice_coef: 0.7773 - dsc: 0.8118 - dice_loss: 0.1882 - iou_coeff: 0.6950 - precision: 0.8205 - recall: 0.8259 - val_loss: 0.3861 - val_ACL5: 1852.0809 - val_binary_crossentropy_plus_jaccard_loss: 0.3861 - val_dice_coef: 0.7519 - val_dsc: 0.7519 - val_dice_loss: 0.2481 - val_iou_coeff: 0.6463 - val_precision: 0.7636 - val_recall: 0.7576- dsc: 0.8101 - dice_loss: 0.1899 - iou_coeff: 0.6931 - precision:  - ETA: 38s - loss: 0.3296 - ACL5: 3561.9085 - binary_crossentropy_plus_jaccard_loss: 0.3296 - dice_coef: 0.7750 - dsc: 0.8102 - dice_loss: 0.1898 - iou_co - ETA: 33s - loss: 0.3293 - ACL5: 3559.9407 - binary_crossentropy_plus_jaccard_loss: 0.3293 - dice_coef: 0.7753 - dsc: 0.8105 - dice_loss: 0.1895 - - ETA: 27s - loss: 0.3290 - ACL5: 3557.7451  - ETA: 0s - loss: 0.3278 - ACL5: 3549.7419 - binary_crossentropy_plus_jaccard_loss: 0.3278 - dice_coef: 0.7773 - dsc: 0.8117 - dice_loss: 0.1883 - iou_coeff: 0.6950 - precision: 0.8205 - recall: 0. - ETA: 0s - loss: 0.3278 - ACL5: 3549.6794 - binary_crossentropy_plus_jaccard_loss: 0.3278 - dice_coef: 0.7773 - dsc: 0.8118 - dice_loss: 0.1882 - iou_coeff: 0.6950 - precision: 0.8205 - recall: 0.\n\nEpoch 00003: val_dice_loss improved from 0.27877 to 0.24814, saving model to Res2Net.hdf5\nEpoch 4/40\n1912/1912 [==============================] - 200s 105ms/step - loss: 0.3045 - ACL5: 3327.0161 - binary_crossentropy_plus_jaccard_loss: 0.3045 - dice_coef: 0.8050 - dsc: 0.8301 - dice_loss: 0.1699 - iou_coeff: 0.7168 - precision: 0.8393 - recall: 0.8405 - val_loss: 0.3884 - val_ACL5: 1960.7555 - val_binary_crossentropy_plus_jaccard_loss: 0.3884 - val_dice_coef: 0.7660 - val_dsc: 0.7660 - val_dice_loss: 0.2340 - val_iou_coeff: 0.6561 - val_precision: 0.7794 - val_recall: 0.7558\n\nEpoch 00004: val_dice_loss improved from 0.24814 to 0.23399, saving model to Res2Net.hdf5\nEpoch 5/40\n1912/1912 [==============================] - 208s 109ms/step - loss: 0.3033 - ACL5: 3293.5663 - binary_crossentropy_plus_jaccard_loss: 0.3033 - dice_coef: 0.8062 - dsc: 0.8291 - dice_loss: 0.1709 - iou_coeff: 0.7179 - precision: 0.8380 - recall: 0.8376 - val_loss: 0.4180 - val_ACL5: 2037.9871 - val_binary_crossentropy_plus_jaccard_loss: 0.4180 - val_dice_coef: 0.7312 - val_dsc: 0.7312 - val_dice_loss: 0.2688 - val_iou_coeff: 0.6285 - val_precision: 0.7409 - val_recall: 0.7220\n\nEpoch 00005: val_dice_loss did not improve from 0.23399\nEpoch 6/40\n1912/1912 [==============================] - 200s 105ms/step - loss: 0.2903 - ACL5: 3196.9326 - binary_crossentropy_plus_jaccard_loss: 0.2903 - dice_coef: 0.8212 - dsc: 0.8389 - dice_loss: 0.1611 - iou_coeff: 0.7298 - precision: 0.8444 - recall: 0.8504 - val_loss: 0.4832 - val_ACL5: 2212.0200 - val_binary_crossentropy_plus_jaccard_loss: 0.4832 - val_dice_coef: 0.6657 - val_dsc: 0.6657 - val_dice_loss: 0.3343 - val_iou_coeff: 0.5718 - val_precision: 0.7279 - val_recall: 0.6473\n\nEpoch 00006: val_dice_loss did not improve from 0.23399\nEpoch 7/40\n1912/1912 [==============================] - 206s 108ms/step - loss: 0.2804 - ACL5: 3084.8107 - binary_crossentropy_plus_jaccard_loss: 0.2804 - dice_coef: 0.8282 - dsc: 0.8454 - dice_loss: 0.1546 - iou_coeff: 0.7388 - precision: 0.8515 - recall: 0.8557 - val_loss: 0.4411 - val_ACL5: 2078.1548 - val_binary_crossentropy_plus_jaccard_loss: 0.4411 - val_dice_coef: 0.7051 - val_dsc: 0.7051 - val_dice_loss: 0.2949 - val_iou_coeff: 0.6006 - val_precision: 0.7441 - val_recall: 0.6997\n\nEpoch 00007: val_dice_loss did not improve from 0.23399\nEpoch 8/40\n1912/1912 [==============================] - 207s 108ms/step - loss: 0.2719 - ACL5: 2980.4734 - binary_crossentropy_plus_jaccard_loss: 0.2719 - dice_coef: 0.8374 - dsc: 0.8509 - dice_loss: 0.1491 - iou_coeff: 0.7468 - precision: 0.8551 - recall: 0.8601 - val_loss: 0.3922 - val_ACL5: 1997.3898 - val_binary_crossentropy_plus_jaccard_loss: 0.3922 - val_dice_coef: 0.7521 - val_dsc: 0.7521 - val_dice_loss: 0.2479 - val_iou_coeff: 0.6478 - val_precision: 0.7756 - val_recall: 0.7373inary_crossentropy_plus_jaccard_loss: 0.2715 - d - ETA: 40s - loss: 0.2717 - ACL5: 2974.7414 - binary_crossentropy_plus_jaccard_loss: 0.2717 - dice_coef: 0.8377 - dsc: 0.8\n\nEpoch 00008: val_dice_loss did not improve from 0.23399\nEpoch 9/40\n1912/1912 [==============================] - 213s 111ms/step - loss: 0.2664 - ACL5: 2947.0743 - binary_crossentropy_plus_jaccard_loss: 0.2664 - dice_coef: 0.8434 - dsc: 0.8548 - dice_loss: 0.1452 - iou_coeff: 0.7517 - precision: 0.8581 - recall: 0.8648 - val_loss: 0.4224 - val_ACL5: 1881.5747 - val_binary_crossentropy_plus_jaccard_loss: 0.4224 - val_dice_coef: 0.7271 - val_dsc: 0.7271 - val_dice_loss: 0.2729 - val_iou_coeff: 0.6326 - val_precision: 0.7464 - val_recall: 0.6941ary_crossen - ETA: 12s - loss: 0.2663 - ACL5: 2946.2100 - binary_crossentropy_plus_jaccard_loss: 0.2663 - dice_coef: 0.8434 - dsc: 0.8 - ETA: 6s - loss: 0.2663 - ACL5: 2946.5439 - binary_crossentropy_plus_jaccard_loss: 0.2663 - dice - ETA: 1s - loss: 0.2664 - ACL5: 2946.9661 - binary_crossentropy_plus_jaccard_loss: 0.2664 - dice_coef: 0.8434 - dsc: 0.8548 - dice_loss: 0.1452 - iou_coeff: 0.7517 - precisio\n\nEpoch 00009: val_dice_loss did not improve from 0.23399\nEpoch 10/40\n1912/1912 [==============================] - 206s 108ms/step - loss: 0.2608 - ACL5: 2868.8534 - binary_crossentropy_plus_jaccard_loss: 0.2608 - dice_coef: 0.8479 - dsc: 0.8576 - dice_loss: 0.1424 - iou_coeff: 0.7568 - precision: 0.8607 - recall: 0.8669 - val_loss: 0.3652 - val_ACL5: 1794.9496 - val_binary_crossentropy_plus_jaccard_loss: 0.3652 - val_dice_coef: 0.7877 - val_dsc: 0.7877 - val_dice_loss: 0.2123 - val_iou_coeff: 0.6806 - val_precision: 0.8119 - val_recall: 0.7569dsc: 0 - ETA: 1:07 - loss: 0.2597 - ACL5: 2858.6269 - binary_crossentropy_plus_jaccard_loss: 0.2597 - dice_coef: 0.8494 - dsc: 0.8585  - ETA: 1:03 - loss: 0.2599 - ACL5: 2859.7463 - binary_crossentropy_plus_jaccard_loss: 0.2599 - dice_coef: 0.8492 - dsc: 0.8584 - dice_loss: 0.1416 - iou_coeff: 0.7577 - precision: 0.8610 - re - ETA: 1:02 - loss: 0.2599 - ACL5: 2859.8820 - binary_crossentropy_plus_jacc - ETA: 52s - loss: 0.2601 - ACL5: 2862.4348 - binary_crossentropy_plus_jaccard_loss: 0.2601 - dice_coef: 0.8488 - dsc: 0.8582 - dice_loss: 0.1418 - iou_coeff: 0.7574 - precision: 0.8 - ETA: 50s - loss: 0.2602 - ACL5: 2862.8888 - binary_crossentropy_plus_jaccard_loss: 0.2602 - dice_coef: 0.8487 - dsc: 0.8581 - dice_loss: 0.1419 - iou_coeff: 0.7574 - - ETA: 46s - loss: 0.2603 - A - ETA: 8s - loss: 0.2607 - ACL5: 2868.2050 - binary_crossentropy_plus_jaccard_loss: 0.2607 - dice_coef: 0.8480 - ds - ETA: 3s - loss: 0.2608 - ACL5: 2868.5761 - binary_crossentropy_plus_jaccard_loss: 0.2608 - dice_coef: 0.8479 - dsc: 0.8577 - \n\nEpoch 00010: val_dice_loss improved from 0.23399 to 0.21226, saving model to Res2Net.hdf5\nEpoch 11/40\n1912/1912 [==============================] - 202s 106ms/step - loss: 0.2591 - ACL5: 2842.4650 - binary_crossentropy_plus_jaccard_loss: 0.2591 - dice_coef: 0.8506 - dsc: 0.8582 - dice_loss: 0.1418 - iou_coeff: 0.7587 - precision: 0.8599 - recall: 0.8672 - val_loss: 0.3789 - val_ACL5: 1826.8148 - val_binary_crossentropy_plus_jaccard_loss: 0.3789 - val_dice_coef: 0.7640 - val_dsc: 0.7640 - val_dice_loss: 0.2360 - val_iou_coeff: 0.6624 - val_precision: 0.7914 - val_recall: 0.7526\n\nEpoch 00011: val_dice_loss did not improve from 0.21226\nEpoch 12/40\n1912/1912 [==============================] - 203s 106ms/step - loss: 0.2520 - ACL5: 2762.1062 - binary_crossentropy_plus_jaccard_loss: 0.2520 - dice_coef: 0.8602 - dsc: 0.8652 - dice_loss: 0.1348 - iou_coeff: 0.7680 - precision: 0.8650 - recall: 0.8702 - val_loss: 0.4897 - val_ACL5: 2079.3098 - val_binary_crossentropy_plus_jaccard_loss: 0.4897 - val_dice_coef: 0.6867 - val_dsc: 0.6867 - val_dice_loss: 0.3133 - val_iou_coeff: 0.5904 - val_precision: 0.7062 - val_recall: 0.6481- binary_crossentropy_plus_jaccard_loss: 0.2523 - dice_coef: 0.8600 - dsc: 0.8650 - dice_loss: 0.1350 - iou_coeff: 0.7678 - precision: 0.8648 - recall: 0.87 - ETA: 13s - loss: 0.2523 - ACL5: 2764.2007 - binary_crossentropy_plus_jaccard_loss: 0.2523 - dice_coef: 0.8600 - dsc: 0.8650 - dice_loss: 0 - ETA: 8s - loss: 0.2521 - AC\n\nEpoch 00012: val_dice_loss did not improve from 0.21226\nEpoch 13/40\n1912/1912 [==============================] - 205s 107ms/step - loss: 0.2493 - ACL5: 2767.5127 - binary_crossentropy_plus_jaccard_loss: 0.2493 - dice_coef: 0.8557 - dsc: 0.8656 - dice_loss: 0.1344 - iou_coeff: 0.7678 - precision: 0.8692 - recall: 0.8736 - val_loss: 0.3650 - val_ACL5: 1868.4056 - val_binary_crossentropy_plus_jaccard_loss: 0.3650 - val_dice_coef: 0.8023 - val_dsc: 0.8023 - val_dice_loss: 0.1977 - val_iou_coeff: 0.6930 - val_precision: 0.8134 - val_recall: 0.7609inary_crossentropy_plus_jaccard_loss: 0.2500 - dice_coef: 0.8551 - dsc: 0.8651 - dice_loss: 0.1349 - iou_coeff: 0.7671 - precision: 0.8690 - r - ETA: 31s - loss: 0.2500 - ACL5: 2772.9909 - binary_crossentropy_plus_jaccard_loss: 0.2500 - dice_coef: 0.8552 - dsc: 0.8651 - dice_loss: 0.1349 - iou_coeff: 0.7671 - precision: 0.8690 - reca - ETA: 30s - loss: 0.2499 - ACL5: 2772.8176 - binary_crossentropy_plus_jaccard_loss: 0.2499 - dice_coef: 0.8552 - dsc: 0.8651 - dice_loss: 0.1349 - iou_coeff: 0.7671 - precision: 0.8690 - recall: - ETA: 29s - loss: 0.2499 - ACL5: 2772.6958 - binary_crossentropy_plus_jaccard_loss: 0.2499 - dice_coef: 0.8552 - dsc: 0.8651 - dice_loss: 0.1349 - iou_coe - ETA: 24s - loss: 0.2498 - ACL5: 2771.8486 - binary_crossentropy_plus_jaccard_loss: 0.2498 - dice_coef: 0.8553 - dsc: 0.8652 - dice_loss: 0.1348 - iou_coeff: 0.7672 - precision: 0.8 - ETA: 22s - loss: 0.2498 - ACL5: 2771.4526 - binary_crossentropy_plus_jaccard_loss: 0.2498 - dice_coef: 0.8553 - dsc: 0.8652 - dice_loss: 0.1348 - iou_coeff: 0.7673 - precision: 0.8690 - recall:  - ETA: 21s - loss: 0.2498 - ACL5: 2771.3329 - binary_crossentropy_plus_jaccard_loss: 0.2498 - dice_coef: 0.8553 - dsc: 0.8652 - dice_loss: 0.1348 - iou_coeff: 0.7673 - precisio - ETA: 3s - loss: 0.2494 - ACL5: 2768.1916 - binary_crossentropy_plus_jaccard_loss: 0.2494 - dice_coef: 0.8556 - dsc: 0.8655 \n\nEpoch 00013: val_dice_loss improved from 0.21226 to 0.19773, saving model to Res2Net.hdf5\nEpoch 14/40\n1912/1912 [==============================] - 203s 106ms/step - loss: 0.2459 - ACL5: 2702.9467 - binary_crossentropy_plus_jaccard_loss: 0.2459 - dice_coef: 0.8655 - dsc: 0.8663 - dice_loss: 0.1337 - iou_coeff: 0.7706 - precision: 0.8681 - recall: 0.8752 - val_loss: 0.3791 - val_ACL5: 1710.3116 - val_binary_crossentropy_plus_jaccard_loss: 0.3791 - val_dice_coef: 0.7819 - val_dsc: 0.7819 - val_dice_loss: 0.2181 - val_iou_coeff: 0.6810 - val_precision: 0.7827 - val_recall: 0.7445\n\nEpoch 00014: val_dice_loss did not improve from 0.19773\nEpoch 15/40\n1912/1912 [==============================] - 201s 105ms/step - loss: 0.2331 - ACL5: 2599.1044 - binary_crossentropy_plus_jaccard_loss: 0.2331 - dice_coef: 0.8739 - dsc: 0.8758 - dice_loss: 0.1242 - iou_coeff: 0.7834 - precision: 0.8755 - recall: 0.8835 - val_loss: 0.4431 - val_ACL5: 1975.3680 - val_binary_crossentropy_plus_jaccard_loss: 0.4431 - val_dice_coef: 0.7289 - val_dsc: 0.7289 - val_dice_loss: 0.2711 - val_iou_coeff: 0.6281 - val_precision: 0.7415 - val_recall: 0.6867\n\nEpoch 00015: val_dice_loss did not improve from 0.19773\nEpoch 16/40\n1912/1912 [==============================] - 205s 107ms/step - loss: 0.2289 - ACL5: 2560.6113 - binary_crossentropy_plus_jaccard_loss: 0.2289 - dice_coef: 0.8764 - dsc: 0.8786 - dice_loss: 0.1214 - iou_coeff: 0.7872 - precision: 0.8786 - recall: 0.8862 - val_loss: 0.3637 - val_ACL5: 1794.5024 - val_binary_crossentropy_plus_jaccard_loss: 0.3637 - val_dice_coef: 0.7927 - val_dsc: 0.7927 - val_dice_loss: 0.2073 - val_iou_coeff: 0.6865 - val_precision: 0.7947 - val_recall: 0.7758nary_crossentropy_plus_jaccard_loss: 0.2289 - dice_coef: 0.8764 - dsc: 0.8786 - dice_loss: 0.1214 - iou_coeff: 0.7872 - precision: 0.8786 - recall: 0. - ETA: 1s - loss: 0.2289 - ACL5: 2560.4844 - binary_crossentropy_plus_jaccard_loss: 0.2289 - dice_coef: 0.8764 - dsc: 0.8786 - dice_loss: 0.1214 - iou_coeff: 0.7872 - precision:\n\nEpoch 00016: val_dice_loss did not improve from 0.19773\nEpoch 17/40\n1912/1912 [==============================] - 205s 107ms/step - loss: 0.2274 - ACL5: 2536.1608 - binary_crossentropy_plus_jaccard_loss: 0.2274 - dice_coef: 0.8776 - dsc: 0.8799 - dice_loss: 0.1201 - iou_coeff: 0.7896 - precision: 0.8775 - recall: 0.8869 - val_loss: 0.4288 - val_ACL5: 1956.5070 - val_binary_crossentropy_plus_jaccard_loss: 0.4288 - val_dice_coef: 0.7559 - val_dsc: 0.7559 - val_dice_loss: 0.2441 - val_iou_coeff: 0.6547 - val_precision: 0.7615 - val_recall: 0.7004- precision: 0.8768 - r - ETA: 53s - loss: 0.2281 - ACL5: 2540.8731 - binary_crossentropy_plus_jaccard_loss: 0.2281 - dice_coef: 0.8772 - dsc: 0.8798 - dice_loss: 0.1202 - iou_coeff: 0.7894 - precision: 0.8768 - recall: 0.886 - ETA: 52s - loss: 0.2281 - ACL5: 2540.8604 - binary_crossentropy_plus_jaccard_loss: 0.2281 - dice_coef: 0.8772 - dsc: 0.8798 - dice_loss: 0.1202 - iou_coeff: 0.7894 - precision: 0. - ETA: 50s - loss: 0.2281 - ACL5: 2540.5912 - binary_crossentropy_plus_jaccard_loss: 0.2281 - dice_coef: 0.8773 - dsc: 0.8798 - dice_loss: 0.1202  - ETA: 44s - loss: 0.2280 - ACL5: 2539.7936 - binary_crossentropy_plus_jaccard_loss: 0.2280 - dice_coef: 0.8773 - dsc: 0.8798 - dice_loss: 0.1202 - iou_coeff:  - ETA: 40s - loss: 0.2279 - ACL5: 2539.3410 - binary_crossentropy_plus_jaccard_loss: 0.2279 - dice_coef: 0.8773 - dsc: 0.8798 - dice_loss: 0.1202 - iou_coeff: 0.7894 - precision: 0. - ETA: 38s - loss: 0.2279 - ACL5: 2539.1384 - binary_crossentropy_plus_jaccard_loss: 0.2279 - dice_coef: 0. - ETA: 28s - loss: 0.2277 - ACL5: 2538.4265 - binary_crossentropy_plus_jaccard_loss: 0.2277 - dice_coef: 0.8774 - dsc: 0.8799 - dic - ETA: 20s - loss: 0.2276 - ACL5: 2537.8941 - binary_crossentropy_plus_jaccard_loss: 0.2276 - dice_coef: 0\n\nEpoch 00017: val_dice_loss did not improve from 0.19773\nEpoch 18/40\n1912/1912 [==============================] - 206s 108ms/step - loss: 0.2163 - ACL5: 2438.4006 - binary_crossentropy_plus_jaccard_loss: 0.2163 - dice_coef: 0.8851 - dsc: 0.8861 - dice_loss: 0.1139 - iou_coeff: 0.7984 - precision: 0.8865 - recall: 0.8933 - val_loss: 0.4913 - val_ACL5: 2059.4500 - val_binary_crossentropy_plus_jaccard_loss: 0.4913 - val_dice_coef: 0.6847 - val_dsc: 0.6847 - val_dice_loss: 0.3153 - val_iou_coeff: 0.5855 - val_precision: 0.7395 - val_recall: 0.6306ice_loss: 0.1138 - iou_coeff: 0.7985 - precision: 0.8867  - ETA: 38s - loss: 0.2162 - ACL5: 2438.9471 - binary_crossentropy_plus_jaccard_loss: 0.2162 - dice_coef: 0.8852 - dsc: 0.8862 - dice_loss: 0.1138 - iou_coeff: 0.7985 - prec - ETA: 35s - loss: 0.2161 - ACL5:  - ETA: 18s - loss: 0.2162 - ACL5: 2438.1444 - binary_crossentropy_plus_jaccard_loss: 0.2162 - dice_coef: 0.8852 - dsc: 0.8862 - dice_loss: 0.1138 - iou_coeff: 0.7985 - - ETA: 14s - loss: 0.2162 - ACL5: 2438.1497 - binary_crossentropy_plus_jaccard_loss: 0.2162 - dice_coef: 0.8851 - dsc: 0.8862 - dice_loss: 0.1138 - iou_coeff: 0.7985 - precision: 0.8866 - recall:  - ETA: 13s - loss: 0.2162 - ACL5: 2438.1506 - binary_crossentropy_plus - ETA: 4s - loss: 0.2163 - ACL5: 2438.2196 - binary_crossentropy_plus_jaccard_loss: 0.2163 - dice_coef:\n\nEpoch 00018: val_dice_loss did not improve from 0.19773\nEpoch 19/40\n1912/1912 [==============================] - 206s 108ms/step - loss: 0.2217 - ACL5: 2446.0696 - binary_crossentropy_plus_jaccard_loss: 0.2217 - dice_coef: 0.8786 - dsc: 0.8809 - dice_loss: 0.1191 - iou_coeff: 0.7930 - precision: 0.8829 - recall: 0.8871 - val_loss: 0.4049 - val_ACL5: 2015.1295 - val_binary_crossentropy_plus_jaccard_loss: 0.4049 - val_dice_coef: 0.7663 - val_dsc: 0.7663 - val_dice_loss: 0.2337 - val_iou_coeff: 0.6653 - val_precision: 0.7713 - val_recall: 0.7369 0.8808 - dice_loss: 0.1192 - iou_coeff: 0.7928 - precision: 0. - ETA: 13s - loss: 0.2219 - ACL5: 2447.1197 - binary_crossentropy_pl - ETA: 4s - loss: 0.2218 - ACL5: 2446.4853 - binary_crossentropy_plus_jaccard_loss: 0.2218 - dice_coef: 0.8785 - dsc: 0.8 - ETA: 0s - loss: 0.2217 - ACL5: 2446.1243 - binary_crossentropy_plus_jaccard_loss: 0.2217 - dice_coef: 0.8786 - dsc: 0.8809 - dice_loss: 0.1191 - iou_coeff: 0.7930 - precision: 0.8829 - re\n\nEpoch 00019: val_dice_loss did not improve from 0.19773\nEpoch 20/40\n1912/1912 [==============================] - 204s 107ms/step - loss: 0.2143 - ACL5: 2396.1412 - binary_crossentropy_plus_jaccard_loss: 0.2143 - dice_coef: 0.8861 - dsc: 0.8869 - dice_loss: 0.1131 - iou_coeff: 0.8011 - precision: 0.8851 - recall: 0.8936 - val_loss: 0.4224 - val_ACL5: 1868.4220 - val_binary_crossentropy_plus_jaccard_loss: 0.4224 - val_dice_coef: 0.7553 - val_dsc: 0.7553 - val_dice_loss: 0.2447 - val_iou_coeff: 0.6565 - val_precision: 0.7456 - val_recall: 0.7100\n\nEpoch 00020: val_dice_loss did not improve from 0.19773\nEpoch 21/40\n1912/1912 [==============================] - 205s 107ms/step - loss: 0.2087 - ACL5: 2338.6406 - binary_crossentropy_plus_jaccard_loss: 0.2087 - dice_coef: 0.8926 - dsc: 0.8913 - dice_loss: 0.1087 - iou_coeff: 0.8078 - precision: 0.8889 - recall: 0.8951 - val_loss: 0.4042 - val_ACL5: 1870.9088 - val_binary_crossentropy_plus_jaccard_loss: 0.4042 - val_dice_coef: 0.7679 - val_dsc: 0.7679 - val_dice_loss: 0.2321 - val_iou_coeff: 0.6612 - val_precision: 0.7825 - val_recall: 0.7359nary_crossentropy_plus_jaccard_loss: 0.2030 - dice_coef: 0.8988 - dsc: 0.8966 - dice_loss: 0.1034 - iou_coeff: 0.8156 - precision: 0.8939 - recall: 0.89 - ETA: 3:01 - loss: 0.2031 - ACL5: 2315.9754 - binary_crossentropy_plus_jaccard_loss: 0.2031 - dice_coef: 0.8988 - dsc: 0.8966 - dice_loss: 0.1034 - iou_coeff: 0.8156 - precision: - ETA: 2:59 - loss: 0.2037 - ACL5: 2316.1831 - binary_crossentropy_plus_jaccard_loss: 0.2037 - dice_coef: 0.8986 - dsc: 0.8963 - dice_loss: 0.1037 - iou_coeff: 0.8151 - precision: 0.8934 - recall: 0. - ETA: 2:59 - loss: 0.2038 - ACL5: 2316.3096 - binary_crossentropy_plus_jaccard_loss: 0.2038 - dice_coef: 0.8986 - dsc: 0.8962 - dice - ETA: 2:43 - loss: 0.2080 - ACL5: 2325.8740 - binary_crossentropy_plus_jaccard_loss: 0.2080 - dice_coef: 0.8963 - dsc: 0.8932 - dice_loss: 0.1068 - iou_coeff: 0 - ETA: 2:41 - loss: 0.20 - ETA: 51s - loss: 0.2091 - ACL5: 2339.7474 - binary_ - ETA: 1s - loss: 0.2087 - ACL5: 2338.6962 - binary_crossentropy_plus_jaccard_loss: 0.2087 - dice_coef: 0.8926 - dsc: 0.8913 - dice_loss: 0.1087 - iou_coeff: 0.8078 - precision: - ETA: 0s - loss: 0.2087 - ACL5: 2338.6573 - binary_crossentropy_plus_jaccard_loss: 0.2087 - dice_coef: 0.8926 - dsc: 0.8913 - dice_loss: 0.1087 - iou_coeff: 0.8078 - precision: 0.8889 - recall\n\nEpoch 00021: val_dice_loss did not improve from 0.19773\nEpoch 22/40\n1912/1912 [==============================] - 201s 105ms/step - loss: 0.2001 - ACL5: 2284.7405 - binary_crossentropy_plus_jaccard_loss: 0.2001 - dice_coef: 0.8960 - dsc: 0.8965 - dice_loss: 0.1035 - iou_coeff: 0.8146 - precision: 0.8948 - recall: 0.9022 - val_loss: 0.3996 - val_ACL5: 1920.2719 - val_binary_crossentropy_plus_jaccard_loss: 0.3996 - val_dice_coef: 0.7633 - val_dsc: 0.7633 - val_dice_loss: 0.2367 - val_iou_coeff: 0.6605 - val_precision: 0.7477 - val_recall: 0.7593283.9659 - binary_crossentropy_plus_jaccard_loss: 0.1996 - dice_coef: 0.8964 - dsc: 0.8968 - dice_loss: 0.1032 - iou_coeff: 0.8150 - p - ETA: 20s - loss: 0.1997 - ACL5: 2284.1566 - binary_crossentropy_plus_jaccard_loss: 0.1997 - dice_coef: 0.8963 - dsc: 0.8967 - dice_loss: 0.1033 - iou_coeff: 0.8149 - precision: 0.895 - ETA: 3s - loss: 0.2000 - ACL5: 2284.6507 - binary_crossentropy_plus_jaccard_loss: 0.2000 - dice_coef: 0.8960 - dsc: 0.896\n\nEpoch 00022: val_dice_loss did not improve from 0.19773\nEpoch 23/40\n1912/1912 [==============================] - 204s 107ms/step - loss: 0.1983 - ACL5: 2237.1923 - binary_crossentropy_plus_jaccard_loss: 0.1983 - dice_coef: 0.8984 - dsc: 0.8966 - dice_loss: 0.1034 - iou_coeff: 0.8157 - precision: 0.8952 - recall: 0.9024 - val_loss: 0.4307 - val_ACL5: 1936.3049 - val_binary_crossentropy_plus_jaccard_loss: 0.4307 - val_dice_coef: 0.7522 - val_dsc: 0.7522 - val_dice_loss: 0.2478 - val_iou_coeff: 0.6542 - val_precision: 0.7555 - val_recall: 0.7043 ETA: 7s - loss: 0.1984 - ACL5: 2237.6716 - binary_crossentropy_plus_jaccard_loss: 0.1984 - dice_coef: 0.8984 - dsc: 0.8965 - dice_loss: 0.1034 - iou_coeff: 0.8 - ETA: 5s - loss: 0.1984 - ACL5: 2237.5687 - binary_crossentropy_plus_jaccard_loss: 0.1984 - \n\nEpoch 00023: val_dice_loss did not improve from 0.19773\nEpoch 24/40\n1912/1912 [==============================] - 202s 106ms/step - loss: 0.1951 - ACL5: 2225.2056 - binary_crossentropy_plus_jaccard_loss: 0.1951 - dice_coef: 0.8992 - dsc: 0.8982 - dice_loss: 0.1018 - iou_coeff: 0.8186 - precision: 0.8966 - recall: 0.9046 - val_loss: 0.3962 - val_ACL5: 1799.0713 - val_binary_crossentropy_plus_jaccard_loss: 0.3962 - val_dice_coef: 0.7807 - val_dsc: 0.7807 - val_dice_loss: 0.2193 - val_iou_coeff: 0.6808 - val_precision: 0.7873 - val_recall: 0.7332\n\nEpoch 00024: val_dice_loss did not improve from 0.19773\nEpoch 25/40\n1912/1912 [==============================] - 213s 112ms/step - loss: 0.1887 - ACL5: 2139.9508 - binary_crossentropy_plus_jaccard_loss: 0.1887 - dice_coef: 0.9055 - dsc: 0.9037 - dice_loss: 0.0963 - iou_coeff: 0.8261 - precision: 0.9011 - recall: 0.9072 - val_loss: 0.4156 - val_ACL5: 1838.7926 - val_binary_crossentropy_plus_jaccard_loss: 0.4156 - val_dice_coef: 0.7599 - val_dsc: 0.7599 - val_dice_loss: 0.2401 - val_iou_coeff: 0.6555 - val_precision: 0.7989 - val_recall: 0.6946\n\nEpoch 00025: val_dice_loss did not improve from 0.19773\nEpoch 26/40\n1912/1912 [==============================] - 206s 108ms/step - loss: 0.1862 - ACL5: 2137.0516 - binary_crossentropy_plus_jaccard_loss: 0.1862 - dice_coef: 0.9048 - dsc: 0.9041 - dice_loss: 0.0959 - iou_coeff: 0.8270 - precision: 0.9031 - recall: 0.9092 - val_loss: 0.3903 - val_ACL5: 1861.8148 - val_binary_crossentropy_plus_jaccard_loss: 0.3903 - val_dice_coef: 0.7757 - val_dsc: 0.7757 - val_dice_loss: 0.2243 - val_iou_coeff: 0.6706 - val_precision: 0.7891 - val_recall: 0.7457A: 22s - loss: 0.1865 - ACL5: 2139.6284 - binary_crossentropy_plus_jaccard_loss: 0.1865 -\n\nEpoch 00026: val_dice_loss did not improve from 0.19773\nEpoch 27/40\n1912/1912 [==============================] - 214s 112ms/step - loss: 0.1837 - ACL5: 2098.1076 - binary_crossentropy_plus_jaccard_loss: 0.1837 - dice_coef: 0.9050 - dsc: 0.9052 - dice_loss: 0.0948 - iou_coeff: 0.8286 - precision: 0.9045 - recall: 0.9113 - val_loss: 0.4123 - val_ACL5: 1826.9065 - val_binary_crossentropy_plus_jaccard_loss: 0.4123 - val_dice_coef: 0.7622 - val_dsc: 0.7622 - val_dice_loss: 0.2378 - val_iou_coeff: 0.6590 - val_precision: 0.7909 - val_recall: 0.7063\n\nEpoch 00027: val_dice_loss did not improve from 0.19773\nEpoch 28/40\n1912/1912 [==============================] - 209s 109ms/step - loss: 0.1781 - ACL5: 2035.3166 - binary_crossentropy_plus_jaccard_loss: 0.1781 - dice_coef: 0.9108 - dsc: 0.9104 - dice_loss: 0.0896 - iou_coeff: 0.8370 - precision: 0.9078 - recall: 0.9111 - val_loss: 0.4083 - val_ACL5: 1919.7065 - val_binary_crossentropy_plus_jaccard_loss: 0.4083 - val_dice_coef: 0.7577 - val_dsc: 0.7577 - val_dice_loss: 0.2423 - val_iou_coeff: 0.6559 - val_precision: 0.7566 - val_recall: 0.7541 - ETA: 1:09 - loss: 0.1782 - ACL5: 2032.8507 - binary_crossentropy_plus_jaccard_loss: 0.1782 - dice_coef: 0.9110 - dsc: 0.9107 - dice_loss: 0.0893 - iou_coeff: 0.8375 - precision: 0.9077 - recall: 0. - ETA: 1:08 - loss: 0.1782 - ACL5: 2032.8605 - binary_crossentropy_plus_jaccard_loss: 0.1782 - dice_coef: 0.9110 - dsc: 0.9107 - dice_loss: 0.0893 - iou_coeff: 0.8375 - precision: 0.9077 - recall: 0. - ETA: 1:08 - loss: 0.1782 - ACL5: 2032.8689 - binary_crossentropy_plus_jaccard_loss: 0.1782 - dice_coef: 0.9110 - dsc: 0.9107 - dice_loss: 0 - ETA: 1:05 - loss: 0.1782 - ACL5: 2033.0087 - binary_crossentropy_plus_jaccard_loss: 0.1782 - dice_coef: 0  - ETA: 39s - loss: 0.1781 - ACL5: 2033.8971 - binary_crossentropy_plus_jaccard_loss: 0.1781 - dice_coef: 0.9110 - dsc: 0.9105 - dice_loss: 0.0895 - iou_coeff: 0.8372 - prec - ETA: 36s - loss: 0.1781 - ACL5: 2034.0348 - binary_crossentropy_plus_jaccard_loss: 0.1781 - dice - ETA: 25s - loss: 0.1781 - ACL5: 2034.6752 - binary_crossentropy_plus_jaccard_loss: 0.1781 - dice_coef: 0.9110 - dsc: 0.9105 - dice_loss: 0.0895 - iou_coeff: 0.8371 - precision: 0.907 - ETA: 5s - loss: 0.1781 - ACL5: 2035.1977 - binary_crossentropy_plus_jaccard_loss: 0.178\n\nEpoch 00028: val_dice_loss did not improve from 0.19773\nEpoch 29/40\n1912/1912 [==============================] - 208s 109ms/step - loss: 0.1757 - ACL5: 2047.6377 - binary_crossentropy_plus_jaccard_loss: 0.1757 - dice_coef: 0.9083 - dsc: 0.9100 - dice_loss: 0.0900 - iou_coeff: 0.8360 - precision: 0.9103 - recall: 0.9150 - val_loss: 0.4303 - val_ACL5: 1895.6816 - val_binary_crossentropy_plus_jaccard_loss: 0.4303 - val_dice_coef: 0.7562 - val_dsc: 0.7562 - val_dice_loss: 0.2438 - val_iou_coeff: 0.6558 - val_precision: 0.7704 - val_recall: 0.6974ETA: 57s - loss: 0.1753 - ACL5: 2046.8665 - binary_crossentropy_plus_jaccard_loss: 0.1753 - dice_coef: 0.9085 - dsc: 0.9101 - dice_loss: 0.0899 - iou_coeff: 0.8361  - ETA: 53s - loss: 0.1754 - ACL5: 2046.8696 - binary_crossentropy_plus_jaccard_loss: 0.1754 - dice_coef: 0.9085 - dsc: 0.9101 - dice_loss: 0.0899 - io - ETA: 48s - loss: 0.1754 - ACL5: 2046.9125 - binary_crossentropy_plus_jaccard_loss: 0.1754 - dice_coef: 0.9084 - dsc: 0.9101 - dice_loss: 0.089 - ETA: 42s - loss: 0.1754 - ACL5: 2047.0273 - binary_crossentropy_plus_jaccard_loss: 0.1754 - dice_coef: 0.9084 - dsc: 0.9101 - dice_loss: 0.0899 - io - ETA: 36s - loss: 0.1755 - ACL5: 2047.2783 - binary_crossentropy_plus_jaccard_loss: 0.1755 - dice_coef: 0.9084 - dsc: 0.9100 - dice_loss: 0.0900 - iou_coeff: 0.8361 - precision: 0.9105 - recall: 0.91 - ETA: 36s - loss: 0.1755 - ACL5: 2047.2897 - binary_crossentropy_plus_jaccard_loss: 0.1755 - dice_coef: 0.9084 - dsc: 0.9100 - dice_loss: 0.0900 - iou - ETA: 31s - loss: 0.1755 - ACL5: 2047.4989 - binary_crossentropy_plus_jaccard - ETA: 18s - loss: 0.1756 - ACL5: 2047.7651 - binary_crossentropy_plus_jaccard_loss: 0.1756 - dice_coef: 0.9083 - dsc: 0.9100 - dice_loss: 0.0900 - iou_coeff: 0.8360 - precision: 0.9104 - recall: 0.915 - ETA: 18s - loss: 0.1756 - ACL5: 2047.7671 - binary_crossentropy_plus_jaccard_loss: 0.1756 - dice_coef: 0.9083 - dsc: 0.9100 - dice_lo - \n\nEpoch 00029: val_dice_loss did not improve from 0.19773\nEpoch 30/40\n1912/1912 [==============================] - 210s 110ms/step - loss: 0.1736 - ACL5: 1984.4264 - binary_crossentropy_plus_jaccard_loss: 0.1736 - dice_coef: 0.9137 - dsc: 0.9117 - dice_loss: 0.0883 - iou_coeff: 0.8395 - precision: 0.9101 - recall: 0.9147 - val_loss: 0.3906 - val_ACL5: 1818.9354 - val_binary_crossentropy_plus_jaccard_loss: 0.3906 - val_dice_coef: 0.7733 - val_dsc: 0.7733 - val_dice_loss: 0.2267 - val_iou_coeff: 0.6708 - val_precision: 0.7973 - val_recall: 0.73644 - ACL5: 1978.6443 - binary_crossentropy_plus_jaccard_loss: 0.1734 - dice_coef: 0.9141 - dsc: 0.9118 - dice_loss: 0.0882  - ETA: 52s - loss: 0.1735 - ACL5: 1979.8973 - binary_crossentropy_plus_jacc - ETA: 2s - loss: 0.1735 - ACL5: 1984.1790 - binary_crossentropy_plus_jaccard_loss: 0.1735 - dice_coef: 0.9137 - dsc: 0.9118 - dice_loss: 0.0882 - io\n\nEpoch 00030: val_dice_loss did not improve from 0.19773\nEpoch 31/40\n1912/1912 [==============================] - 206s 108ms/step - loss: 0.1742 - ACL5: 1982.7547 - binary_crossentropy_plus_jaccard_loss: 0.1742 - dice_coef: 0.9131 - dsc: 0.9123 - dice_loss: 0.0877 - iou_coeff: 0.8411 - precision: 0.9082 - recall: 0.9133 - val_loss: 0.4117 - val_ACL5: 1898.0197 - val_binary_crossentropy_plus_jaccard_loss: 0.4117 - val_dice_coef: 0.7632 - val_dsc: 0.7632 - val_dice_loss: 0.2368 - val_iou_coeff: 0.6597 - val_precision: 0.7788 - val_recall: 0.7230- binary_crossentropy_plus_jaccard - ETA: 1:35 - loss: 0.1764 - ACL5: 1993.8530 - binary_crossentropy_plus_ - E\n\nEpoch 00031: val_dice_loss did not improve from 0.19773\nEpoch 32/40\n1912/1912 [==============================] - 207s 108ms/step - loss: 0.1661 - ACL5: 1931.1087 - binary_crossentropy_plus_jaccard_loss: 0.1661 - dice_coef: 0.9156 - dsc: 0.9150 - dice_loss: 0.0850 - iou_coeff: 0.8452 - precision: 0.9149 - recall: 0.9188 - val_loss: 0.4049 - val_ACL5: 1895.1697 - val_binary_crossentropy_plus_jaccard_loss: 0.4049 - val_dice_coef: 0.7728 - val_dsc: 0.7728 - val_dice_loss: 0.2272 - val_iou_coeff: 0.6635 - val_precision: 0.8027 - val_recall: 0.71661917.5198 - binary_crossentropy_plus_jaccard_loss: 0.1652 - dice_coef: 0.9154 - dsc: 0.9153 - dice_loss: 0.0847 - iou_coeff: 0.8462 - precision: 0.9154 - recall: 0.91 - ETA: 2:27 - loss: 0.1652 - ACL5: 1917.5263 - binary_crossentropy_plus_jaccard_loss: 0.1 - ETA: 2:21 - loss: 0.1653 - ACL5: 1918.5380 - binary_crossentropy_plus_jaccard_loss: 0.1653 - dice_coef: 0.9155 - dsc: 0.9153 - dice_loss: 0.0847 - iou_coeff: 0.8461 - precision: 0.9154 -  - ETA: 2:21 - loss: 0.1 - ETA: 2:01 - loss: 0.1654 - ACL5: 1921.8979 - binary_crossentropy_plus_jaccard_loss: - ETA: 1:11 - loss: 0.1655 - ACL5: 1925.2707 - binary_crossentropy_plus_jaccard_loss: 0.1655 - dice_coef: 0.9157 - dsc: 0.9152 - dice_loss: 0.0848 - iou_coeff: 0.8456 - prec - ETA: 1:10 - loss: 0.1655 - ACL5: 1925.3259 - binary_crossentropy_plus_jaccard_loss: 0.1655 - dice_coef: 0.9157 - dsc: 0.9152 - dice - ETA: 1:06 - loss: 0.1656 - ACL5: 1925.4908 - binary_crossentropy_plus_jaccard_loss: 0.1656 - dice_coef: 0.9157 - dsc: 0.9152 - dice_loss: 0.0848 - iou_coeff: 0.8456 - precision: 0.9153 - recall:  - ETA: 1:06 - loss: 0.1656 - ACL5: 1925.5079 - binary_crossentropy_plus_jaccard_loss: 0.1656 - dice_coef: 0.9157  - ETA: 1:01 - loss: 0.1656 - ACL5: 1925.7714 - binary_crossentropy_plus_jaccard_loss: 0.1656 - dice_coef: 0.9157 - dsc: 0.9152 - dice - ETA: 56s - loss: 0.1656 - ACL5: 1926.1369 - binary_crossentropy_plus_jaccard_loss: 0.1656 - dice_coef: 0.9157 - dsc: 0.9152 - dice_lo - ETA: 49s - loss: 0.1657 - ACL5: 1926.8123 - binary_crossentropy_plus_jaccard_loss: 0.1657 - dice_coef: 0.9157 - - ETA: 39s - loss: 0.1658 - ACL5: 1927.7633 - binary_crossentropy_plus_jaccard_loss: 0.1658 - dice_coef: 0.9157 - dsc: 0.9151 - dice_loss: 0.0849 - iou_coeff: 0.8454 - precision: 0.9151 - recall: 0.91 - ETA: 39s - loss: 0.1658 - ACL5: 1927.7812 - binary_crossentropy_plus_jaccard_loss: 0.1658 - dice_coef: 0.9157 - dsc: 0.9151 - dice_loss: 0.0849 - iou_coeff: 0.8454 - preci - ETA: 36s - loss: 0.1658 - ACL5: 1928.0277 - binary_crossentropy_plus_jaccard_loss: 0.1658 - dice_coef: 0.915 - ETA: 26s - loss: 0.1659 - ACL5: 1928.5205 - binary_crossentropy_plus_jaccard_ - ETA: 13s - loss: 0.1659 - ACL5: 1929.3821 - binary_crossentropy_plus_jaccard_loss: 0.1659 - dice_coef: 0.9157 - dsc: 0.9150 - dice_loss: 0.0850 - iou_coeff: 0 - ETA: 9s - loss: 0.1660 - ACL5: 1929.8688 - binary_crossentropy_plus_jaccard_loss: 0.1660 - dice_coef: 0.9156 - dsc: 0.9150 - dice_loss: 0.0850  - ETA: 6s - loss: 0.1660 - ACL5: 1930.2194 - binary_crossentropy_plus\n\nEpoch 00032: val_dice_loss did not improve from 0.19773\nEpoch 33/40\n1912/1912 [==============================] - 207s 108ms/step - loss: 0.1660 - ACL5: 1915.5870 - binary_crossentropy_plus_jaccard_loss: 0.1660 - dice_coef: 0.9155 - dsc: 0.9158 - dice_loss: 0.0842 - iou_coeff: 0.8463 - precision: 0.9151 - recall: 0.9179 - val_loss: 0.3809 - val_ACL5: 1917.4745 - val_binary_crossentropy_plus_jaccard_loss: 0.3809 - val_dice_coef: 0.7899 - val_dsc: 0.7899 - val_dice_loss: 0.2101 - val_iou_coeff: 0.6802 - val_precision: 0.7839 - val_recall: 0.780456 - loss: 0.1661 - ACL5: 1911.3744 - bina - ETA: 1:38 - loss: 0.1663 - ACL5: 1915.323 - ETA: 1:29 - loss: 0.1662 - ACL5: 1916.1345 - binary_crossentropy_plus_jaccard_loss: 0.1662 - dice_coe - ETA: 1:24 - loss: 0.1662 - ACL5: 1916.5287 - binary_crossentropy_plus_jaccard_loss: 0.1662 - dice_coef: 0.9148 - dsc: 0.915 - ETA: 1:09 - loss: 0.1660 - ACL5: 1916.8816 - binary_crossentropy_plus_jaccard_loss: 0.1660 - dice_coef: 0.9149 - dsc: 0.9155 - dice_loss: 0 - ETA: 1:06 - loss: 0.1660 - ACL5: 1916.8136 - binary_crossentropy_plus_jaccard_loss: 0.1660 - dice_coef: 0.9149 - dsc: 0.9155 - di - ETA: 1:02 - loss: 0.1660 - ACL5: 1916.8535 - binary_crossentropy_plus_jaccard_loss: 0.1660 - dice_coef: 0.9150 - dsc: 0.9155 - dice_loss: 0.0845 - iou_coeff: 0.8457 - precision: - ETA: 1:01 - loss: 0.1660 - ACL5: 1916.8602 - binary_crossentropy_plus_jaccard_loss - ETA: 50s - loss: 0.1660 - ACL5: 1916.6417 - binary_crossentropy_plus_jaccard_loss: 0.1660 - dice_coef: 0.9151 - dsc: 0.9156 - dice_loss: 0.0844 - iou_coeff: 0.8458 - precision: 0.9156 - recall: 0.91 - ETA: 49s - - ETA: 30s - loss: 0.1660 - ACL5: 1916.4555 - binary_crossentropy_plus_jaccard_loss: 0.1660 - dice_coef: 0.9153 - dsc: 0.9157 - dice_loss: 0.0843 - iou_coeff: 0.8460 - precision: 0.9153 - ETA: 28s - loss: 0.1660 - ACL5: 1916.4423 - binary_crossentropy_plus_jaccard_loss: 0.1660 - dice_coef: 0.9153 - dsc: 0.9157 - dice_loss: 0.0843 - iou_coeff: 0 - ETA: 23s - loss: 0.1660 - ACL5: 1916.3370 - binary_crossentropy_plus_jaccard_loss: 0.1660 - dice_coef: 0.9153 - dsc: 0.9157 - dice_loss: 0.0843 - iou_c - ETA: 18s - loss: 0.1660 - ACL5: 1916.1865 - binary_crossentropy_plus_jaccard_loss: 0.1660 - dice_coef: 0.9154 - dsc: 0.9157 - dice_loss: 0.0843 - iou_coef - ETA: 13s - loss: 0.1660 - ACL5: 1916.0279 - binary_crossentropy_plus_jaccard_loss: 0.1660 - dice_coef: 0.91 - ETA: 7s - loss: 0.1660 - ACL5: 1915.8132 - binary_crossentropy_\n\nEpoch 00033: val_dice_loss did not improve from 0.19773\nEpoch 34/40\n1912/1912 [==============================] - 207s 108ms/step - loss: 0.1633 - ACL5: 1886.3205 - binary_crossentropy_plus_jaccard_loss: 0.1633 - dice_coef: 0.9202 - dsc: 0.9190 - dice_loss: 0.0810 - iou_coeff: 0.8516 - precision: 0.9151 - recall: 0.9185 - val_loss: 0.3992 - val_ACL5: 1845.8904 - val_binary_crossentropy_plus_jaccard_loss: 0.3992 - val_dice_coef: 0.7715 - val_dsc: 0.7715 - val_dice_loss: 0.2285 - val_iou_coeff: 0.6677 - val_precision: 0.7798 - val_recall: 0.7286292 - binary_crossentropy_plus_jaccard_loss: 0 - ETA: 32s - loss: 0.1630 - ACL5: 1886.3754 - binary_c - ETA: 2s - loss: 0.1633 - ACL5: 1886.3738 - binary_crossentropy_plus_jaccard_loss: 0.1633 - dice_coef: 0.9202 - dsc: 0.9191 - dice_loss: 0.080\n\nEpoch 00034: val_dice_loss did not improve from 0.19773\nEpoch 35/40\n1912/1912 [==============================] - 208s 109ms/step - loss: 0.1608 - ACL5: 1878.5501 - binary_crossentropy_plus_jaccard_loss: 0.1608 - dice_coef: 0.9198 - dsc: 0.9191 - dice_loss: 0.0809 - iou_coeff: 0.8520 - precision: 0.9173 - recall: 0.9204 - val_loss: 0.3959 - val_ACL5: 1805.5261 - val_binary_crossentropy_plus_jaccard_loss: 0.3959 - val_dice_coef: 0.7832 - val_dsc: 0.7832 - val_dice_loss: 0.2168 - val_iou_coeff: 0.6780 - val_precision: 0.7899 - val_recall: 0.7358 0.1641 - ACL5: 1909.5127 - binary_crossentropy_plus_jaccard_loss: 0.1641 - dice_coef: 0.9198 - dsc: 0.9184 - dice_loss: 0.0816 - io - ETA: 2:42 - loss: 0.1641 - ACL5: 1909.2586 - binary_crossentropy_plus_jaccard_loss: 0.1641 - dice_coef: 0.9198 - dsc: 0.9184 - dice_loss: 0.0816  - ETA: 2:40 - loss: 0.1641 - ACL5: 1908.0538 - binary_crossentropy_plus_jaccard_loss: 0.1641 - dice_coef: 0.9197 - dsc: - ETA: 2:37 - loss: 0.1641 - ACL5: 1905.9281 - binary_crossentropy_plus_jaccard_los - ETA: 2:30 - ETA: 1:58 - loss: 0.1 - ETA: 1:48 - loss: 0.1623 - ACL5: 1888.7849 - binary - ETA: 1:40 - loss: 0.1621 - ACL5: 1887.0424 - binary_crossentropy_plus_jaccard_loss: 0.1621 - dice_coef: 0.9194 - dsc: 0.9191 - dice_loss: 0.0809  - ETA: 1:37 - loss: 0.1620 - ACL5: 1886.5079 - binary_crossentropy_plus_jaccard_loss: 0.1620 - dice_coef: 0.9194 - dsc: 0.9191 - dice_loss: 0.0809 - iou_coeff: 0.8519 - pr - ETA: 1:35 - loss: 0.1619 - ACL5: 1886.2463 - binary_crossentropy_plus_jaccard_loss: 0.1619 - dice_coef: 0.9195 - dsc: 0.9191 - dice_loss: 0.0809 - iou_coeff: 0.851 - ETA: 1:23 - loss: 0.1617 - ACL5: 1884.8522 - binary_crossentropy_plus_jaccard_loss: 0.1617 - dice_coef: 0.9195 - dsc: 0.9192 - dice_loss: 0.0808 - iou_coeff: 0.8520 - precision: - ETA: 1:22 - loss: 0.1616 - ACL5: 1884.7047 - binary_crossentropy_plus_jaccard_loss: 0.1616 - dice_coef: 0.9195 -  - ETA: 1:06 - loss: 0.1614 - ACL5: 1882.6955 - binary_crossentropy_plus_jaccard_loss: - ETA: 1:00 - loss: 0.1613 - ACL5: 1882.1069 - binary_crossentropy_plus_jaccard_loss: 0.1613 -  - ETA: 28s - loss: 0.1610 - ACL5: 1879.8816 - binary_crossentropy_plus_jaccard_loss: 0.1610 - dice_coef: 0.9197 - dsc: 0.9192 - dice_loss: 0.0808 - iou_coeff: 0.8520 - precision: 0.9171 - re - ETA: 27s - loss: 0.1610 - ACL5: 1879.7976 - binary_crossentropy_plus_jaccard_loss: 0.1610 - dice_coef: 0.9197 - dsc: 0.9192 - dice_loss: 0.0808 - iou_coeff: 0.8520 - precision: 0.917 - ETA: 25s - loss: 0.1610 - ACL5: 1879.6816 - binary_crossentropy_plus_jaccard_lo - ETA: 12s - loss: 0.1609 - ACL5: 1879.1010 - binary_crossentropy_plus_jaccard_loss: 0.1609 - dice_coef: 0.9197 - dsc: 0.9191 - dice_loss: 0.0809 - io - ETA: 8s - loss: 0.1608 - ACL5: 1878.9526 - binary_crossentropy_plus_jaccard_los - ETA: 2s - loss: 0.1608 - ACL5: 1878.6490 - binary_crossentropy_plus_jaccard_loss: 0.1608 - dice_coef: 0.9197 - dsc: 0.9191 - dice_loss: 0.0809 - iou_coef\n\nEpoch 00035: val_dice_loss did not improve from 0.19773\nEpoch 36/40\n1912/1912 [==============================] - 209s 110ms/step - loss: 0.1609 - ACL5: 1873.7432 - binary_crossentropy_plus_jaccard_loss: 0.1609 - dice_coef: 0.9204 - dsc: 0.9192 - dice_loss: 0.0808 - iou_coeff: 0.8526 - precision: 0.9160 - recall: 0.9202 - val_loss: 0.4165 - val_ACL5: 1821.1405 - val_binary_crossentropy_plus_jaccard_loss: 0.4165 - val_dice_coef: 0.7606 - val_dsc: 0.7606 - val_dice_loss: 0.2394 - val_iou_coeff: 0.6588 - val_precision: 0.7836 - val_recall: 0.704857 - loss: 0.1611 - ACL5: 2016.0372 - binary_crossentropy_plus - ETA: 2:43 - loss: 0.1616 - ACL5: 1949.6936 - binary_crossentropy_plus_jaccard_loss: 0.1616 - dice_coef: 0.917 - ETA: 2:27 - loss: 0.1618 - ACL5: 1927.2836 - binary_crossentropy_plus_jaccard_loss: 0.1618 - dice_coef: 0.9182 - dsc: 0.9182 - dice_loss: 0.0818 - iou_coeff: 0.8510 -  - ETA: 2:25 - loss: 0.1617 - ACL5: 1925.4839 - binary_crossentropy_plus_jaccard_loss: 0.1617 - dice_coef: 0.9183 - dsc: 0.9182 - dice_loss: 0.0818 - iou_coeff: 0.8510 - precision: 0 - ETA: 2:24 - loss: 0.1617 - ACL5: 1924.3394 - binary_crossentropy_plus_jaccard_loss: 0.1617 - dice_coef: 0.9183 - dsc: 0.9182 - dice_loss: 0.0818 - iou_coeff: 0.8 - ETA: 2:00 - loss: 0.1617 - ACL5: 1907.0501 - binary_crossentropy_plus_jaccard_loss: 0.1617 - dice_coef: 0.9190 - dsc: 0.9185 - dice_loss: 0.0815 - iou_coeff: 0.8515 - prec - ETA: 1:58 - loss: 0.1617 - ACL5: 1905.9322 - binary_crossentropy_plus_jaccard_loss: 0.1617 - dice_coef: 0.9191 - dsc: 0.9185 - dice_loss: 0.0815 - iou_coef - ETA: 1:56 - loss: 0.1616 - ACL5: 1904.4328 - binary_crossentropy_plus_jaccard_loss: 0.1616 - dice_coef: 0.9191 - dsc: 0.9186 - dice_loss: 0.0814 - iou_coeff: 0.8516 - precision: 0.9157 - re - ETA: 1:56 - loss: 0.1616 - ACL5: 1904.1038 - binary_crossentropy_plus_jaccard_loss: 0.1616 - dice_coef: 0.9192 - dsc: 0.9186 - dice_loss: - ETA: 1:09 - loss: 0.1614 - ACL5: 1886.7221 - binary_crossentropy_plus_jaccard_loss: 0.1614 - dice_coef: 0.9199 - dsc: 0.9189 - dice_loss: 0.0811 -  - ETA: 1:06 - loss: 0.1614 - ACL5: 1886.0815 - binary_crossentropy_plus_jaccard_loss: 0.1614 - dice_coef: 0.9199 - dsc: 0.9189 - dice_loss: 0.0811 - iou_coeff: 0.8522  - ETA: 1:04 - loss: 0.1613 - ACL5: 1885.6605 - binary_crossentropy_plus_jaccard_loss: 0.1613 - dice_coef: - ETA: 59s - loss: 0.1613 - ACL5: 1884.3154 - binary_crossentropy_plus_jaccard_loss: 0.1613 - dice_coef: 0.9200 - dsc: 0.9189 - dice_loss: 0.0811 - iou_coeff: 0.8522 - precision: 0.9158 - recall: 0.92 - ETA: 59s - loss: 0.1613 - ACL5: 1884.2602 - binary_crossentropy_plus_jaccard_loss: 0.1613 - dice_coef: 0.9200 - dsc: 0.9189 - dice_loss: 0.0811 - iou_coeff: 0.8522 - precision: 0.9158 - ETA: 35s - loss: 0.1612 - ACL5: 1879.5232 - binary_crossentropy_plus_jaccard_loss: 0.1612 - dice_coef: 0.9202 - dsc: 0.9190 - dice_loss: 0.0810 - iou_coeff: 0.8524 - precision: 0.9158 - ETA: 34s - loss: 0.1612 - ACL5: 1879.1774 - binary_crossentropy_plus_jaccard_loss: 0.1612 - dice_coef: 0.9202 - dsc: 0.9190 - dice_loss: 0.0810 - iou_coeff: - ETA: 29s - loss: 0.1612 - ACL5: 1878.3217 - binary_crossentropy_plus_jaccard_loss: 0.1612 - dice_coef: 0.9202 - dsc: 0.9191 - dice_loss: 0.0809 -  - ETA: 23s - loss: 0.1611 - ACL5: 1877.3266 - binary_crossentropy_plus_jaccard_loss: 0.1611 - - ETA: 12s - loss: 0.1610 - ACL5: 1875.4940  - ETA: 2s - loss: 0.1609 - ACL5: 1874.1085 - binary_crossentropy_plus_jaccard_loss: 0.1609 - dice_coef: 0.9204 - dsc: 0.9192 - dice_loss: 0.0808 - io\n\nEpoch 00036: val_dice_loss did not improve from 0.19773\nEpoch 37/40\n1912/1912 [==============================] - 208s 109ms/step - loss: 0.1566 - ACL5: 1832.0160 - binary_crossentropy_plus_jaccard_loss: 0.1566 - dice_coef: 0.9223 - dsc: 0.9208 - dice_loss: 0.0792 - iou_coeff: 0.8554 - precision: 0.9204 - recall: 0.9216 - val_loss: 0.4138 - val_ACL5: 1864.8799 - val_binary_crossentropy_plus_jaccard_loss: 0.4138 - val_dice_coef: 0.7771 - val_dsc: 0.7771 - val_dice_loss: 0.2229 - val_iou_coeff: 0.6776 - val_precision: 0.7893 - val_recall: 0.7181 ETA: 2:15 - l - ETA: 2:05 - loss: 0.1557  - ETA: 1:56 - loss: 0.1559 - ACL5: 1831.9310 - binary_crossentropy_plus_jaccard_loss: 0.1559 - dice_coef: 0.9225 - dsc: 0.9212 - dice_loss: 0.0788 - iou_coeff: 0.8555 - precision: 0.9219 - reca - ETA: 1:55 - loss: 0.1559 - ACL5: 1831.9493 - binary_crossentropy_plus_jaccard_loss: 0.1559 - dice_coef: 0.9225 - dsc: 0.921 - ETA: 1:52 - loss: 0.1560 - ACL5: 1831.9111 - binary_crossentropy_plus_jaccard_loss: 0.1560 - dice_coef: 0.9225 - dsc: 0.9212 - dice_loss: - ETA: 1:48 - loss: 0.1560 - ACL5: 1831.8024 - binary_crossentropy_plus_jaccard_loss: 0.1560 - dice_coef: 0.9225 - dsc: 0.9211 - dice_loss: 0.0789 -  - ETA: 1:34 - loss: 0.1563 - ACL5: 1832.1615 - binary_crossentropy_plus_jaccard_loss: 0.1563 - dice_coef: 0.9224  - ETA: 1:29 - loss: 0.1564 - ACL5: 1832.3332 - binary_crossentropy_plus_jaccard_loss: 0.1564 - dice_coef: 0.9223 - dsc: 0.9209 - dice_loss: 0.0791 - iou_coeff: 0.855 - ETA: 1:27 - loss: 0.1564 - ACL5: 1832.4392 - binary_crossentropy_plus_jaccard_loss: 0.1564 - dice_coef: 0.9223 - ds - ETA: 1:23 - loss: 0.1565 - ACL5: 1832.5586 - binary_crossentropy_plus_jaccard - ETA: 1:06 - loss: 0.1566 - ACL5: 1832.9272 - binary_crossentropy_plus_jaccard_loss: 0.1566 - dice_coef: 0.9223 - dsc: 0.9208 - dice_loss: 0.0792 - iou_coeff: 0.8552 - precis - ETA: 1:04 - loss: 0.1566 - ACL5: 1832.9541 - binary_crossentropy_plus_jaccard_loss: 0.1566 - dice_coef: - ETA: 37s - loss: 0.1567 - ACL5: 1833.1301 - binary_crossentropy_plus_jaccard_loss: 0.1567 - dice_coef: 0.9222 - dsc: 0.9207 - dice_loss: 0.0793 - iou_coeff: 0.8552 - prec - ETA: 34s - loss: 0.1567 - ACL5: 1833.1275 - binary_crossentropy_plus_ - ETA: 4s - loss: 0.1566 - ACL5: 1832.1757 - binary_crossentropy_plus_jaccard_loss: 0.1566 - dice_coef: 0.9223 - dsc:\n\nEpoch 00037: val_dice_loss did not improve from 0.19773\nEpoch 38/40\n1912/1912 [==============================] - 207s 109ms/step - loss: 0.1543 - ACL5: 1826.2135 - binary_crossentropy_plus_jaccard_loss: 0.1543 - dice_coef: 0.9241 - dsc: 0.9224 - dice_loss: 0.0776 - iou_coeff: 0.8576 - precision: 0.9210 - recall: 0.9241 - val_loss: 0.3701 - val_ACL5: 1769.0735 - val_binary_crossentropy_plus_jaccard_loss: 0.3701 - val_dice_coef: 0.8025 - val_dsc: 0.8025 - val_dice_loss: 0.1975 - val_iou_coeff: 0.6953 - val_precision: 0.7961 - val_recall: 0.7708 - loss: 0.1570 - ACL5: 1867.1979 - binary_crossentropy_plus_jaccard_loss: 0.1570 - dice_coef: 0.9233 - dsc: 0.921 - ETA: 2:21 - loss: 0.1559 - ACL5: 1854.6678 - binary_crossentropy_plus_jaccard_loss: 0.1559 - dice_coef: 0.9237 - dsc: 0.9217 - dice_loss: 0.0783 - iou_coeff: 0.8560 - precision: 0.9211 - recall: 0. - ETA: 2:21 - loss: 0.1558 - ACL5: 1854.6208 - binary_crossentropy_plus_jaccard_loss: 0.1558 -  - ETA: 2:16 - loss: 0.1558 - ACL5: 1853.7454 - binary_crossentropy_plus_jaccard_loss: 0.1 - ETA: 1:38 - loss: 0.1553 - ACL5: 1841.7772 - binary_crossentropy_plus_jaccard_loss: 0.1553 - dice_coef: 0.9236 - dsc: 0.9219 - dice_loss: 0.0781 - iou_coeff: 0.8566 - precision: 0.9208  - ETA: 1:37 - loss: 0.1553 - ACL5: 1841.5423 - binary_crossentropy_plus_jaccard_loss: 0.1553 - dice_coef: 0.9236 - dsc: 0.921 - ETA: 1:33 - loss: 0.1552 - ACL5: 1840.5192 - binary_crossentropy_plus_jaccard_loss: 0.1552 - dice_coef: 0.9237 - dsc: 0.9219 - dice_loss: 0 - ETA: 1:29 - loss: 0.1552 - ACL5: 1839.8444 - binary_crossentropy_plus_jaccard_l - ETA: 1:23 - loss: 0.1551 - ACL5: 1838.5751 - binary_crossentropy_plus_jaccard_loss: 0.1551 - dice_coef: 0.9237 - dsc: 0.9220 - dice_loss: 0.0780 - iou_coeff: 0.8568 - precision: 0.9208 - reca - ETA: 1:23 - loss: 0.1551 - ACL5: 1838.4696 - binary_crossentropy_plus_jaccard_loss: 0.1551 - dice_coef: 0.9237 - dsc: 0.9220 - dice_loss: 0.0780 - iou_coeff: 0.8568 - precision: 0.9208 - recall: 0. - ETA: 1:23 - loss: 0.1551 - ACL5: 1838.4267 - binary_crossentropy_plus_jaccard_loss: 0.1551 - dice_coef: 0.9237 - dsc: 0.9220 - dice_loss: 0.0780 - iou_coeff: 0.856 - ETA: 1:21 - loss: 0.1551 - ACL5: 1838.0191 - binary_crossentropy_plus_jaccard_loss: 0.1551 - dice_coef: 0.9238 - dsc: 0.9220 - dice_loss: 0.0780 - iou_coeff: 0.8568 - precision: 0.9208 - recall: 0. - ETA: 1:20 - loss: 0.1551 - ACL5: 1837.9746 - binary_crossentropy_plus - ETA: 1:13 - loss: 0.1549 - ACL5: 1836.4939 - binary_crossentropy_plus_jaccard_loss: 0.1549 - dice_coef: - ETA: 1:08 - loss: 0.1549 - ACL5: 1835.3604 - binary_crossentropy_plus_jaccard_loss: 0.1549 - dice_coef: 0.9238 - dsc: 0.9221 - dice_loss: - ETA: 1:05 - loss: 0.1548 - ACL5: 1834.6548 - binary_crossentropy_plus_jaccard_loss: 0.1548 - dice_coef: 0.9239 - dsc: 0.9221 - dice_loss: 0.0779 - iou_coeff: 0.8570 - pr - ETA: 1:03 - loss: 0.1548 - ACL5: 1834.3384 - binary_crossentropy_plus_jaccard_loss: 0.1548 - dice_coef: 0.9239 - dsc: 0.9222 - dice_loss: 0.0778 - iou_coeff: 0.8571 - precision: 0 - ETA: 1:02 - loss: 0.1548 - ACL5: 1834.1141 - binary_crossentropy_plus_jaccard_loss: 0.1548 - dice_coef: 0.9239 - dsc: 0.9222 - dice_loss: 0.0 - ETA: 58s - loss: 0.1547 - ACL5: 1833.4211 - binary_crossentropy_plus_jaccard_loss: 0.1547 - dice_coef: 0.9239 - dsc: 0.9222 - dice_loss: 0.0778 - iou_coeff: 0.8571 - preci - ETA: 55s - loss: 0.1547 - ACL5: 1832.9380 - binary_crossentropy_plus_jaccard_loss: 0.1547 - dice_coef: 0.9239 - dsc: 0.9222 - dice_loss: 0.0778 - iou_coeff: 0.8572 - precision: 0.9209 - recall: 0 - ETA: 54s - loss: 0.1547 - ACL5: 1832.8490 - binary_crossentropy_plus_jaccard_loss: 0.1547 - dice_coef: 0.9239 - dsc: 0.9222 - dice_loss: 0.0778 - iou_coeff: 0.8572 - precision: 0.9209 - recall:  - ETA: 54s - loss: 0.1547 - ACL5: 1832.7440 - binary_crossentropy_plus_jaccard_loss: 0.1547 - dice_coef: 0.9239 - dsc: 0.9222 - dice_loss: 0.0778 - iou_coeff: 0.8572 - precision: 0. - ETA: 51s - loss: 0.1547 - ACL5: 1832.3998 - binary_crossentropy_plus_jaccard_loss: 0.1547 - dice_coef: 0.9 - ETA: 41s - loss: 0.1545 - ACL5: 1830.7293 - binary_crossentropy_plus_jaccard_loss: 0.1545 - dice_coef: 0.9240 - dsc: 0.9223 - dice_loss: - ETA: 35s - loss: 0.1545 - ACL5: 1829.7926 - binary_crossentropy_plus_jaccard_loss: 0.1545 - dice_coef: - ETA: 24s - loss: 0.1544 - ACL5: 1828.5342 - binary_crossentropy_plus_jaccard_loss: 0.1544 - dice_coef: 0.9240 - dsc: 0.9223 - dice_loss: 0.0777 - iou_coeff: 0.8574 - precision:  - ETA: 22s - loss: 0.1544 - ACL5: 1828.2539 - binary_crossentropy_plus_jaccard_loss: 0.1544 - - ETA: 10s - loss: 0.1543 - ACL5: 1827.1783 - binary - ETA: 2s - loss: 0.1543 - ACL5: 1826.4623 - binary_crossentropy_plus_jaccard_loss: 0.1543 - dice_coef: 0.9241 - dsc: 0.9224 - dice_loss: 0.0776 - iou_\n\nEpoch 00038: val_dice_loss improved from 0.19773 to 0.19752, saving model to Res2Net.hdf5\nEpoch 39/40\n1912/1912 [==============================] - 208s 109ms/step - loss: 0.1527 - ACL5: 1787.6822 - binary_crossentropy_plus_jaccard_loss: 0.1527 - dice_coef: 0.9257 - dsc: 0.9234 - dice_loss: 0.0766 - iou_coeff: 0.8603 - precision: 0.9201 - recall: 0.9238 - val_loss: 0.4074 - val_ACL5: 1777.9757 - val_binary_crossentropy_plus_jaccard_loss: 0.4074 - val_dice_coef: 0.7753 - val_dsc: 0.7753 - val_dice_loss: 0.2247 - val_iou_coeff: 0.6725 - val_precision: 0.7771 - val_recall: 0.7201tropy_plus_jaccard_loss: 0.1533 - dice_coef: 0.9251 - dsc: 0.9225 - dice_loss: 0.0775 - iou_coeff: 0.8595 -  - ETA: 55s - loss: 0.1530 - ACL5: 1788.5134 - binary_crossentropy_p - ETA: 40s - loss: 0.1528 - ACL5: 1788.0453 - binary_crossentropy_plus_jaccard_loss: 0.1528 - dice_coef: 0.9255 - dsc: 0.9231 - dice_loss: 0.0769 - iou_coeff: 0.8600 - precisi - ETA: 16s - loss: 0.1527 - ACL5: 1787.2946 - binary_crossentropy_plus_jaccard_loss: 0.1527 - dice_coef: 0.9257 - dsc: 0.9233 - dice_loss: 0.0767 - io - ETA: 11s - loss: 0.1527 - ACL5: 1787.4231 - binary_crossentropy_plus_jaccard_loss: 0.1527 - dice_coef: 0.9257 - dsc: 0.9234 - dice_loss: 0.0766 - iou_coeff: 0.8603 - precision: 0.9200 - recall: - ETA: 10s - loss: 0.1527 - ACL5: 1787.4404 - bin - ETA: 2s - loss: 0.1527 - ACL5: 1787.6527 - binary_crossentropy_plus_jaccard_loss: 0.1527 - dice_coef: 0.9257 - dsc: 0.9234 - dice_loss: 0.0766 - iou_coeff: 0.8603 - precision: - ETA: 0s - loss: 0.1527 - ACL5: 1787.6720 - binary_crossentropy_plus_jaccard_loss: 0.1527 - dice_coef: 0.9257 - dsc: 0.9234 - dice_loss: 0.0766 - iou_coeff: 0.8603 - precision: 0.9\n\nEpoch 00039: val_dice_loss did not improve from 0.19752\nEpoch 40/40\n1912/1912 [==============================] - 208s 109ms/step - loss: 0.1518 - ACL5: 1792.2868 - binary_crossentropy_plus_jaccard_loss: 0.1518 - dice_coef: 0.9259 - dsc: 0.9247 - dice_loss: 0.0753 - iou_coeff: 0.8613 - precision: 0.9223 - recall: 0.9243 - val_loss: 0.3944 - val_ACL5: 1893.1499 - val_binary_crossentropy_plus_jaccard_loss: 0.3944 - val_dice_coef: 0.7776 - val_dsc: 0.7776 - val_dice_loss: 0.2224 - val_iou_coeff: 0.6748 - val_precision: 0.7765 - val_recall: 0.7499plus_jaccard_loss: 0.1445 - dice_coef: 0.9256 - dsc: 0.9274 - dice_l - ETA: 3:03 - loss: 0.1518 - ACL5: 1894.1284 - binary_crossentropy_plus_jaccard_loss: 0.1518 - dice_coef: 0.9239 - dsc: 0.9242 - dice_loss: 0.0758 - iou_coeff: 0.8609 - precision: 0.9255 -  - ETA: 2:55 - loss: 0.1550 - ACL5: 1855.0804 - binary_crossentropy_plus_jaccard_loss: 0.1550 - dice_coef: 0.9238 - dsc: 0.9226 - dice_loss: 0.0774 - iou_coeff: 0.8589 - precision: 0 - ETA: 2:54 - loss: 0.1550 - ACL5: 1852.9184 - binary_crossentropy_plus_jaccard_loss: 0.1550 - dice_coef: 0.9238 - dsc: 0.9226 - dice - ETA: 2:52 - loss: 0.1552 - ACL5: 1849.9706 - binary_crossentropy_plus_jaccard_loss: 0.1552 - di - ETA: 2:46 - loss: 0.1551 - ACL5: 1844.5657 - binary_crossentropy_plus_jaccard_loss: 0.1551 - dice_coef: 0.9238 - dsc: 0.9225 - dice_los - ETA: 2:47 - loss: 0.1551 - ACL5: 1840.8060 - binary_crossentropy_plus_jaccard_loss: 0.1551 - dice_coef: 0.9239 - dsc: 0.9226 - dice_loss: 0.0774 - iou_coeff: 0.8585 - precision: 0.9211 - re - ETA: 2:47 - loss: 0.1551 - ACL5: 1840.2775 - binary_crossentropy_plus_jaccard_loss: 0.1551 - dice_coef: 0.9239 - dsc: 0.9226 - dice_loss: 0.0774 - iou_coeff: 0.8585 - precision: 0.9211 - recall:  - ETA: 2:46 - loss: 0.1551 - ACL5: 1839.9934 - binary_crossentropy_plus_jaccard_loss: 0.1551 - dice_coef: 0.9239 - dsc: 0.9226 - dice_loss: 0.0774 - iou_coeff: 0.8585 - pr - ETA: 2:44 - loss: 0.1551 - ACL5: 1838.3804 - binary_crossentropy_plus_jaccard_loss: 0.1551 - dice_coef: 0.9239 - dsc: 0.9226 - dice_loss: 0.0774 - iou_coeff: 0.8586 -  - ETA: 2:32 - loss: 0.1546 - ACL5: 1830.0207 - binary_crossentropy_plus_jaccard_loss: 0.1 - ETA: 2:26 - loss: 0.1545 - ACL5: 1827.4042 - binary_crossen - ETA: 2:08 - loss: 0.1544 - ACL5: 1818.9080 - binary_crossentropy_plus_jaccard_loss: 0.1544 - dice_coef: 0.924 - ETA:  - ETA: 1:53 - loss: 0.1541 - ACL5: 1812.8530 - binary_crossentropy_plus_jaccard_loss: 0.1541 - dice_coef: 0.9250 - dsc: 0.9236 - dice_loss: 0.0764 - iou_coeff: 0.8597 -  - ETA: 1:51 - loss: 0.1541 - ACL5: 1812.3597 - binary_crossentropy_plus_jaccard_loss: 0.1541 - di - ETA: 1:45 - loss: 0.1540 - ACL5: 1811.0576 - binary_c - ETA: 1:38 - loss: 0.1539 - ACL5: 1809.0970 - binary_crossentropy_plus_jaccard_loss: 0.1539 - dice_coef: 0.9251 - dsc: 0 - ETA: 1:34 - loss: 0.1538 - ACL5: 1807.9790 - bina - ETA: 1:26 - loss: 0.1536 - ACL5: 1805.9729 - binary_crossentropy_pl - ETA: 1:08 - loss: 0.1532 - ACL5: 1802.2816 - binary_crossentropy_plus_jaccard_loss: 0.1532 - dice_coef: 0.9254 - dsc: 0.9242 - dice_loss: 0.0758 - iou_coeff: 0.8605 - precision: 0.9 - ETA: 1:07 - loss: 0.1532 - ACL5: 1802.0993 - binary_crossentropy_plus_jaccard_loss: 0.1532 - dice_coef: 0.9 - ETA: 1:02 - loss: 0 - ETA: 45s - loss: 0.1527 - ACL5: 1798.3916 - binary_crossentropy_plus_jaccard_loss: 0.1527 - dice_coef: 0.9256 - dsc: 0.9244 - dice_lo - ETA: 38s - loss: 0.1525 - ACL5: 1797.3875 - binary_crossentropy_p - ETA: 24s - loss: 0.1522 - ACL5: 1795.4435 - binary_crossentropy_plus_jaccard_loss: 0.1522 - dice_coef: 0.9258 - dsc: 0.9246 - dice_loss: 0.0754 - iou_coeff: 0.8611 - precision: 0.9220 - recal - ETA: 23s - loss: 0.1522 - ACL5: 1795.3149 - binary_crossentropy_plus_jaccard_loss: 0.1522 - dice_coef: 0.9258 - dsc: 0.9246 - dice_loss: 0.0754 - iou_c - ETA: 18s - loss: 0.1521 - ACL5: 1794.6403 - binary_crossentropy_plus_jaccard_loss: 0.1521 - dice_coef: 0.9258 - dsc: 0.9246 - dice_loss: 0.0754 - iou_coeff: 0.8611 - precision: 0.92 - ETA: 16s - loss: 0.1521 - ACL5: 1794.3633 - binary_crossentropy_plus_jaccard_ - ETA: 6s - loss: 0.1519 - ACL5: 1793.1147 - binary_crossentropy_plus_jaccard_loss: 0.1519 - dice_coef: 0.9259 - dsc: 0.9247 - dice_loss: 0.0753 - iou_coeff: 0.8613 - precision: 0.9222 -  - ETA: 5s - loss: 0.1519 - ACL5: 1793.0271 - binary_crossentropy_plus_jaccard_loss: 0\n\nEpoch 00040: val_dice_loss did not improve from 0.19752\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5-Fkaj2HSmb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cSUhfR1ySmb5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}